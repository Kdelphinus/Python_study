{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Natural Language Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Intro\n",
    "1. Bag-of-Words\n",
    "2. Topic Modeling\n",
    "3. Word Embedding\n",
    "4. RNNs with Attention\n",
    "5. Preprocessing\n",
    "6. Transformer\n",
    "7. Tokenization\n",
    "8. Byte-Pair Encoding\n",
    "9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.1 NLP란?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP(Natural Language Processing)란 자연어를 컴퓨터와 같은 기계를 이용해서 묘사하도록 연구하는 인공지능 분야입니다. 이는 다시 NLU(Natural Language Understanding)과 NLG(Natural Language Generation)으로 나뉩니다. \n",
    "\n",
    "NLU는 문장이나 문단이 주어졌을 때, 이를 이해하고 질의응답이 가능하도록 만드는 분야입니다. NLG는 자동 번역 등 자연스럽게 말이 이어지도록 생성하는 과정입니다. 현재 NLU는 어느 정도 연구가 진행되었다고 여겨지고 NLG에 대한 연구가 더 활발하게 이루어지고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.2 NLP Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP를 사용하는 분야는 많이 있습니다. 이를 하나씩 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Text Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam detection, sentiment analysis 등 받은 자연어들로 분류하는 분야입니다. 스팸 메일을 분류하거나 평점을 가지고 긍부정을 나누는 등에 사용됩니다. \n",
    "\n",
    "![text_classification](_image/text_classification.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) QA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA(Question Answering)는 말 그대로 질문과 context(위키 등 웹페이지들)가 input으로 주어졌을 때, output으로 답을 내보내는 것입니다. 대표적으로 search engine 등이 있습니다. 밑에서 구글을 보면 질문에 대해 위키에 답을 진하게 표현한 것을 볼 수 있습니다.\n",
    "\n",
    "![QA](_image/QA.PNG)\n",
    "\n",
    "이때 답을 찾는 방법은 크게 세 가지가 있습니다.\n",
    "\n",
    "1. Context 내에서 뽑아냄(위 이미지가 그 예시)\n",
    "2. 직접 문장을 생성하여 출력\n",
    "3. 객관식(Multi-Choice)를 사용하여 출력\n",
    "\n",
    "2번 같은 경우는 context가 주어지지 않고 질문만 주어지는 common sense reasoning입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Macine Translation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation은 기존 언어(source language)를 번역할 언어(target language)로 바꿔주는 것입니다. 현재 연구, 실무 분야에서 가장 활발하게 진행되고 있습니다. 파파고, 구글 번역 등이 그 예시입니다.\n",
    "\n",
    "1. pair 사용(같은 의미, 다른 언어의 쌍)\n",
    "2. unsupervised learning(pair가 없이 학습)\n",
    "\n",
    "학습 방법은 위에 두 가지 방법이 있습니다. pair는 직관적이지만 하나하나 학습 데이터를 만들기 어렵고 데이터가 너무 커집니다. 그래서 최근 비지도 학습을 이용한 학습이 새로운 방법으로 나오고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatbot은 자연어가 input으로 주어졌을 때, 대화가 이어지도록 output이 이어서 주어지는 프로그램입니다. 대화가 계속 이어지기 때문에 맥락을 잘 보는 것이 필요합니다. 그렇기에 직전 한 문장만 input으로 받지 않고 어느 정도 문단을 같이 가져옵니다. input을 template와 generation 중 어떤 것으로 받을지 선택할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Personal Assistant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal Assistant는 빅스비, 시리와 같이 특정 요청을 수행하는 것들을 말합니다. 아직은 노래 요청, 날씨 등 제한적인 사용만 가능하지만 점차 개발되어지고 있습니다. 음성으로 작동하기 때문에 특정 음성(하이 빅스비, 시리야 등)을 들어야 음성 모드로 들어가게 만들어서 여러 소음에 작동하지 않도록 하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Text Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization은 말그대로 글들을 요약해주는 것입니다. 예를 들어 뉴스가 있다면 제목과 내용을 보고 요약해주는 것을 말합니다. \n",
    "\n",
    "![text_summarization](_image/text_summarization.PNG)\n",
    "\n",
    "요약하는 방식은 extractive와 generative로 나뉩니다. extractive는 주어진 내용들을 통해 요약을 해주는 반면 generative는 본문에 없는 말로도 요약할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.3 NLP 연구 필드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP 분야는 ACL, EMNLP, NAACL 등 유력한 컨퍼런스들이 있습니다. (AI는 급변하는 분야이기에 저널을 잘 보지 않습니다.) 이를 더욱 세분화하여 분야를 나눌 수 있습니다.\n",
    "\n",
    "#### **Low-level parsing**\n",
    "- Tokenization, stemming(과거형이나 미래형을 기본형으로 바꾸는 것)\n",
    "\n",
    "#### **Word and pharse level**\n",
    "- Named entity recognition(NER), part-of-speech(POS) tagging, noun-phrase chunking, dependency parsing, coreference resolution $\\Rightarrow$ (언어학자가 만든 체계가 컴퓨터에게는 도움이 되지 않음이 확인되면서 연구가 사그라듬)\n",
    "- Semantic relation extraction\n",
    "\n",
    "#### **Sentence level**\n",
    "- Sentiment analysis, machine translation\n",
    "\n",
    "#### **Multi-sentence and paragraph level**\n",
    "- Entailment prediction, question answering, dialog systems, summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외에도 text mining, information retrieval 등이 있습니다.(PDF 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Bag-of-Words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding이란 단어들을 embedding이란 과정을 거쳐 컴퓨터가 이해할 수 있는 숫자로 바꾸는 과정을 말합니다. 이러면 단어들은 벡터가 되는데 이 벡터를 embedding vector라고 합니다.\n",
    "\n",
    "|구분|Bag-of_Words|언어 모델|분포 가정|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|내용|어떤 단어가 많이 쓰였는가|단어가 어떤 순서로 쓰였는가|어떤 단어가 같이 쓰였는가|\n",
    "|대표 통계량|TF-IDF|-|PMI|\n",
    "|대표 모델|Deep Averaging Network|ELMO, GPT|Word2Vec|\n",
    "\n",
    "단어를 임베딩하여 나오는 벡터들은 어떤 가정을 따르냐에 따라서 위와 같이 구분됩니다. 이를 더 자세히 살펴보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 백 오브 워즈 가정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백 오브 워즈는 저자의 의도가 단어 사용 여부나 그 빈도에서 드러난다고 보는 과정입니다. 그렇기에 단어의 순서는 고려대상이 아닙니다. 순서에 상관없이 하나의 가방에 단어들을 모두 넣고 빈도수를 확인하는 것입니다. 이때 대표적으로 TF-IDF가 사용됩니다. \n",
    "\n",
    "#### **TF-IDF(Term Frequency-Inverse Document Frequency)**\n",
    "어떤 단어의 주제 예측 능력이 강할수록 가중치가 커지고 반대의 경우 작아집니다. w는 단어, N은 문서의 개수, TF(Term Frequency)는 단락에서의 빈도, DF(Document Frequency)는 문서에서의 빈도입니다. \n",
    "\n",
    "$$TF - IDF(w) = TF(w) \\times log(\\frac{N}{DF(w)})$$\n",
    "\n",
    "그렇기에 문서 전체에서 빈도가 높은 조사들은 가중치가 줄어들고 특정 문장에서 빈번하게 나오는 단어들은 가중치가 증가합니다. 이에 대해 뒤에서 더 자세히 알아보겠습니다.\n",
    "\n",
    "\n",
    "#### **Deep Averaging Network(lyyer et al. 2015)**\n",
    "문장에 속한 단어의 임베딩의 평균을 구해 문장의 임베딩을 만드는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 언어 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 등장 순서를 학습해 주어진 단어 시퀀스가 얼마나 자연스러운지 확률을 부여하는 방법입니다. 백 오브 워즈와 달리 등장 순서에 영향을 받기에 '나는 밥을 먹었다'와 '나는 먹었다 밥을'을 다른 문장으로 해석합니다. \n",
    "\n",
    "$$P(w_i) \\Rightarrow P(w_i|w_{i-1}, w_{i-2}, \\cdots, w_0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 분포 가정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 의미를 주변 문맥을 통해 유추하는 방법입니다. 가까운 단어들을 통해 의미를 유추합니다.\n",
    "\n",
    "#### **PMI(Pointwise Mutual Information)**\n",
    "두 단어 A, B가 얼마나 자주 같이 등장하는지 정보를 수치화하여 유추합니다.\n",
    "\n",
    "$$ PMI(A, B) = log \\frac{P(A, B)}{P(A) \\times P(B)}$$\n",
    "\n",
    "#### **Word2Vec**\n",
    "특정 단어 주변의 문맥, 즉 분포 정보를 함축하며 벡터로 만들어 사용하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Bag-of-Words Representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW는 문법과 어순은 무시하지만 다중성을 유지하면서 단어의 가방에 단어들을 집어넣습니다. 그리고 이를 고유한 단어의 vocabulary를 만들거나 각 단어들을 one-hot vector로 만들어 사용하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 Naïve Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve Bayes Classifier은 Bayes' theorem을 이용하여 간단한 분류를 하는 classifier입니다. \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\; (\\text{Bayes'\\, theorem})$$\n",
    "\n",
    "이제 이를 이용해 Naïve Bayes Classifier을 유추해보겠습니다. 각 document d는 class c를 가지고 있습니다. P(c|d)가 d가 c에 속할 확률입니다. Bayes' theorem을 적용하면 아래와 같은 식이 나옵니다.\n",
    "\n",
    "$$P(c|d) = \\frac{P(d|c)P(c)}{P(d)}$$\n",
    "\n",
    "근데 여기서 분모는 항상 같기 때문에 분모를 제거해도 괜찮습니다. 그렇기에 아래와 같은 식이 나옵니다.\n",
    "\n",
    "$$P(c|d) = P(d|c)P(c)$$\n",
    "\n",
    "$d$는 $words w_1, w_2, \\cdots, w_n$로 이루어져 있습니다. 그렇기에 위의 식은 다시 쓰면 다음과 같습니다.\n",
    "\n",
    "$$P(d|c)P(c) = P(w_1, w_2, \\cdots, w_n|c)P(c)$$\n",
    "\n",
    "이때 우리가 관심이 있는 것은 $P(c|d) = P(c|w_1, w_2, \\cdots, w_n)$이다. 이제 여기에 chain rule까지 적용하면 다음과 같이 나옵니다. 이때 확률에 관한 chain rule은 다음과 같습니다.\n",
    "\n",
    "$$\\begin{aligned} P(X_4, X_3, X_2, X_1) &= P(X_4|X_3, X_2, x_1) \\cdot P(X_3, X_2, X_1) \\\\\n",
    "&= P(X_4|X_3, X_2, X_1) \\cdot P(X_3|X_2, X_1) \\cdot P(X_2, X_1) \\\\\n",
    "&= P(X_4|X_3, X_2, X_1) \\cdot P(X_3|X_2, X_1) \\cdot P(X_2|X_1) \\cdot P(X_1) \\end{aligned}$$\n",
    "\n",
    "$$P(c|d) = P(d|c)P(c) = P(c) \\prod_{w_i \\in W} P(w_i|c)$$\n",
    "\n",
    "예시를 통해 알아보겠습니다. 밑에처럼 주어진 document와 word, class가 있습니다.\n",
    "\n",
    "||No.|Document($d$)|Class($c$)|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Training|1|me free lottery|Spam|\n",
    "||2|free get free you|Spam|\n",
    "||3|you free scholarship|Inbox|\n",
    "||4|free to contact me|Inbox|\n",
    "||5|you won award|Inbox|\n",
    "||6|you ticket loterry|Spam|\n",
    "|<span style=\"color:skyblue\">Test</span>|<span style=\"color:skyblue\">7</span>|<span style=\"color:skyblue\">you free loterry</span>|<span style=\"color:skyblue\">?</span>|\n",
    "\n",
    "위와 같이 샘플이 주어져 있고 7번의 문장이 spam인지 아닌지 확인해야 합니다. 우리가 구한 식을 이용하여 식을 세워보겠습니다.\n",
    "\n",
    "$$P(c_{spam}|d_7) = P(c_{spam})P(w_{you}|c_{spam})P(w_{free}|c_{spam})P(w_{lottery}|c_{spam})$$\n",
    "$$P(c_{Inbox}|d_7) = P(c_{Inbox})P(w_{you}|c_{Inbox})P(w_{free}|c_{Inbox})P(w_{lottery}|c_{Inbox})$$\n",
    "\n",
    "만약 $P(c_{spam}|d_7) > P(c_{inbox}|d_7)$이면 스팸이고 $P(c_{spam}|d_7) < P(c_{inbox}|d_7)$이면 inbox로 분류될 것이다. 각 단어의 개수와 클래스 개수를 통해 결과를 보면 다음과 같습니다. \n",
    "\n",
    "![spam_result](_image/spam_result.PNG)\n",
    "\n",
    "이제 결과를 통해 종합적으로 계산하면 다음과 같습니다.\n",
    "\n",
    "$$P(c_{spam}|d_7) \n",
    "= P(c_{spam})P(w_{you}|c_{spam})P(w_{free}|c_{spam})P(w_{lottery}|c_{spam})\n",
    "= \\frac{1}{2} \\times \\frac{2}{10} \\times \\frac{3}{10} \\times \\frac{2}{10} = \\frac{6}{1000}$$\n",
    "$$P(c_{Inbox}|d_7) \n",
    "= P(c_{Inbox})P(w_{you}|c_{Inbox})P(w_{free}|c_{Inbox})P(w_{lottery}|c_{Inbox})\n",
    "= \\frac{1}{2} \\times \\frac{2}{10} \\times \\frac{2}{10} \\times \\frac{0}{10} = 0$$\n",
    "\n",
    "그러므로 7번 문장은 spam입니다.\n",
    "\n",
    "||No.|Document($d$)|Class($c$)|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Training|1|me free lottery|Spam|\n",
    "||2|free get free you|Spam|\n",
    "||3|you free scholarship|Inbox|\n",
    "||4|free to contact me|Inbox|\n",
    "||5|you won award|Inbox|\n",
    "||6|you ticket loterry|Spam|\n",
    "|<span style=\"color:skyblue\">Test</span>|<span style=\"color:skyblue\">7</span>|<span style=\"color:skyblue\">you free loterry</span>|<span style=\"color:red\">Spam</span>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **실습1. Naïve Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 필요한 라이브러리들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# POS(Part of Speech) tagger\n",
    "from konlpy import tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data와 test data를 준비하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# training data. input text와 정답 label (긍정(1), 부정(0))으로 구성\n",
    "data['train'] = [{'text': \"정말 재미있습니다. 추천합니다.\"},\n",
    "                {'text': \"기대했던 것보단 별로였네요.\"},\n",
    "                {'text': \"지루해서 다시 보고 싶다는 생각이 안 드네요.\"},\n",
    "                {'text': \"완전 최고입니다 ! 다시 보고 싶습니다.\"},\n",
    "                {'text': \"연기도 연출도 다 만족스러웠습니다.\"},\n",
    "                {'text': \"연기가 좀 별로였습니다.\"},\n",
    "                {'text': \"연출도 좋았고 배우분들 연기도 최고입니다.\"},\n",
    "                {'text': \"기념일에 방문했는데 연기도 연출도 다 좋았습니다.\"},\n",
    "                {'text': \"전반적으로 지루했습니다. 저는 별로였네요.\"},\n",
    "                {'text': \"CG에 조금 더 신경 썼으면 좋겠습니다.\"}\n",
    "                ]\n",
    "# test data\n",
    "data['test'] = [{'text': \"최고입니다. 또 보고 싶네요.\"},\n",
    "                {'text': \"별로였습니다. 되도록 보지 마세요.\"},\n",
    "                {'text': \"다른 분들께 추천드릴 수 있을 만큼 연출도 연기도 만족했습니다.\"},\n",
    "                {'text': \"연기가 좀 더 개선되었으면 좋겠습니다.\"}\n",
    "                ]\n",
    "\n",
    "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
    "test_labels = [1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy에서 제공하는 [꼬꼬마(Kkma) 형태소 분석기](https://konlpy.org/en/v0.5.2/api/konlpy.tag/#module-konlpy.tag._kkma)를 이용하여 tokenize 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 선언\n",
    "morph_analyzer = tag.Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 함수 정의\n",
    "def tokenization(data, morph_analyzer):\n",
    "    \"\"\"tokenization \n",
    "\n",
    "    Args:\n",
    "        data (list): list of data examples.\n",
    "        morph_analyzer (konlpy.tag._kkma.Kkma): morphological analyzer.\n",
    "\n",
    "    Returns:\n",
    "        tokenized_data (list): list of tokenized data examples.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    \n",
    "    for example in tqdm(data):\n",
    "        tokens = morph_analyzer.morphs(example['text'])\n",
    "        tokenized_data.append(tokens)\n",
    "    \n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenization 함수를 이용한 데이터 tokenization\n",
    "tokenized_data = {}\n",
    "\n",
    "tokenized_data['train'] = tokenization(data['train'], morph_analyzer)\n",
    "tokenized_data['test'] = tokenization(data['test'], morph_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['정말', '재미있', '습니다', '.', '추천', '하', 'ㅂ니다', '.'],\n",
       " ['기대', '하', '었', '더', 'ㄴ', '것', '보다', 'ㄴ', '별', '로', '이', '었', '네요', '.'],\n",
       " ['지루', '하', '어서', '다시', '보', '고', '싶', '다는', '생각', '이', '안', '들', '네요', '.'],\n",
       " ['완전', '최고', '이', 'ㅂ니다', '!', '다시', '보', '고', '싶', '습니다', '.'],\n",
       " ['연기', '도', '연출', '도', '다', '만족', '스럽', '었', '습니다', '.'],\n",
       " ['연기', '가', '좀', '별', '로', '이', '었', '습니다', '.'],\n",
       " ['연출', '도', '좋', '았', '고', '배우', '분', '들', '연기', '도', '최고', '이', 'ㅂ니다', '.'],\n",
       " ['기념일',\n",
       "  '에',\n",
       "  '방문',\n",
       "  '하',\n",
       "  '었',\n",
       "  '는데',\n",
       "  '연기',\n",
       "  '도',\n",
       "  '연출',\n",
       "  '도',\n",
       "  '다',\n",
       "  '좋',\n",
       "  '았',\n",
       "  '습니다',\n",
       "  '.'],\n",
       " ['전반적',\n",
       "  '으로',\n",
       "  '지루',\n",
       "  '하',\n",
       "  '었',\n",
       "  '습니다',\n",
       "  '.',\n",
       "  '저',\n",
       "  '는',\n",
       "  '별',\n",
       "  '로',\n",
       "  '이',\n",
       "  '었',\n",
       "  '네요',\n",
       "  '.'],\n",
       " ['CG', '에', '조금', '더', '신경', '쓰', '었', '으면', '좋', '겠', '습니다', '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized_data 확인\n",
    "tokenized_data['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 tokenization 결과를 이용해서 word to index dictionary를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 55964.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# train data의 tokenization 결과에서 unique token만 남긴 set으로 변환\n",
    "tokens = [token for i in range(len(tokenized_data['train'])) for token in tokenized_data['train'][i]]\n",
    "unique_train_tokens = set(tokens)\n",
    "\n",
    "# Naïve Bayes Classifier의 input에 들어갈 word의 index를 반환해주는 dictionary를 생성\n",
    "word2index = defaultdict() # key: word, value: index of word\n",
    "idx = 0\n",
    "for token in tqdm(unique_train_tokens):\n",
    "    word2index[token] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Naïve Bayes Classifier 모델 클래스를 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def __init__(self, word2index, k=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            word2index (dict): mapping a word to a pre-assigned index.\n",
    "            k (float, optional): constant for smoothing. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        self.k = k # for smoothing\n",
    "        self.word2index = word2index\n",
    "        self.priors = {} # Prior probability for each class, P(c)\n",
    "        self.likelihoods = {} # Likelihood for each token, P(d|c)\n",
    "    \n",
    "    def _set_priors(self, labels):\n",
    "        \"\"\"\n",
    "        Set prior probability for each class, P(c).\n",
    "        Count the number of each class and caculate P(c) for each class.\n",
    "        \"\"\"\n",
    "        # Count the number of each class\n",
    "        class_counts = defaultdict(int)\n",
    "        for label in tqdm(labels):\n",
    "            class_counts[label] += 1\n",
    "        \n",
    "        # For each class, calcuate P(c)\n",
    "        for label, count in class_counts.items():\n",
    "            self.priors[label] = class_counts[label] / len(labels)\n",
    "    \n",
    "    def _set_likelihoods(self, tokens, labels):\n",
    "        \"\"\"\n",
    "        Set likelihood for each token, P(d|c).\n",
    "        First, count the number of each class for each token.\n",
    "        Then, calculate P(d|c) for a given class and token.\n",
    "        \"\"\"\n",
    "        token_dists = {}\n",
    "        number_of_token_for_class = defaultdict(int)\n",
    "        \n",
    "        # Count the number of each class for each token\n",
    "        for i, label in enumerate(tqdm(labels)):\n",
    "            count = 0\n",
    "            for token in tokens[i]:\n",
    "                # 'token in self.word2index'부분은 안 들어가도 되지 않는가?\n",
    "                if token not in token_dists and token in self.word2index:\n",
    "                    token_dists[token] = {0:0, 1:0}\n",
    "                token_dists[token][label] += 1\n",
    "                count += 1\n",
    "            number_of_token_for_class[label] += count\n",
    "\n",
    "        for token, dist in tqdm(token_dists.items()):\n",
    "            if token not in self.likelihoods:\n",
    "                self.likelihoods[token] = {\n",
    "                    0: (token_dists[token][0] + self.k) / (number_of_token_for_class[0] + len(self.word2index) * self.k),\n",
    "                    1: (token_dists[token][1] + self.k) / (number_of_token_for_class[1] + len(self.word2index) * self.k),\n",
    "                }\n",
    "    \n",
    "    def train(self, input_tokens, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tokens (list): list of tokenized train data.\n",
    "            labels (): train labels for each sentence/document.\n",
    "        \"\"\"\n",
    "        self._set_priors(labels)\n",
    "        self._set_likelihoods(input_tokens, labels)\n",
    "    \n",
    "    def inference(self, input_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tokens (list): list of tokenized test data.\n",
    "        \"\"\"\n",
    "        log_prob_0 = 0.0\n",
    "        log_prob_1 = 0.0\n",
    "        \n",
    "        for token in input_tokens:\n",
    "            if token in self.likelihoods:\n",
    "                log_prob_0 += math.log(self.likelihoods[token][0])\n",
    "                log_prob_1 += math.log(self.likelihoods[token][1])\n",
    "        \n",
    "        log_prob_0 += math.log(self.priors[0])\n",
    "        log_prob_1 += math.log(self.priors[1])\n",
    "        \n",
    "        if log_prob_0 >= log_prob_1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 학습 데이터에 대해 문장 분류 모델을 학습시키겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 56258.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# 문장 분류 모델 선언 및 학습\n",
    "classifier = NaiveBayesClassifier(word2index)\n",
    "classifier.train(tokenized_data['train'], train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 test 데이터에 대해 정답값을 예측하고 Accuracy를 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 4164.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test data inference\n",
    "preds = []\n",
    "for test_tokens in tqdm(tokenized_data['test']):\n",
    "    pred = classifier.inference(test_tokens)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy 측정\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Bag-of-Words Encoding of Text Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저번 챕터에서 본 Bag-of-Words를 다시 보겠습니다. \"John likes movies. Mary likes too.\"와 \"John also likes football.\"이란 두 문장이 주어졌을 때 각각 bag-of-words vector는 다음과 같습니다.\n",
    "\n",
    "![4-2-1](_image/4-2-1.PNG)\n",
    "\n",
    "각 단어를 사전으로 만들고 나타난 빈도수를 저장합니다. 그렇기에 행렬은 (키워드 개수) x (document 개수)의 형태로 나타납니다. 이 행렬을 term-document matrix(TDM)이라고 합니다. 순서 정보는 무시되는 단점이 있지만 많이 사용되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 topic은 가상의 document의 백 오브 워즈 벡터입니다. 그리고 백 오브 워즈 벡터의 값들을 정규화하면 합이 1이 되는 확률분포로 나타낼 수 있습니다. 그렇기에 토픽은 키워드들의 확률분포이자 키워드들의 가중치 조합이라고 할 수 있습니다. \n",
    "\n",
    "![4-2-2](_image/4-2-2.PNG)\n",
    "\n",
    "위 그림을 보면 맨 윗줄은 topic이고 밑에 있는 단어들은 그 topic에 속한 단어들입니다. topic의 제목은 프로그램이 자동으로 정해지며 군집에 속한 단어의 개수가 많으면 topic과 관련된 document라고 추측할 수 있습니다. 그리고 이를 바탕으로 document도 topic에 대해 군집을 만들 수 있습니다. \n",
    "\n",
    "밑의 그림은 topic modeling의 전반적 동작을 표현한 것입니다.\n",
    "\n",
    "<img src = \"https://iq.opengenus.org/content/images/2020/01/1_taTOiaCpd_CzGugx_PticQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Topic Modeling Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 동작하는 과정들을 상세히 보겠습니다.\n",
    "\n",
    "먼저 input document들을 bag-of-words vector들로 만듭니다. 이를 열벡터로 합쳐서 단어의 개수 x 문서의 개수 크기의 행렬 $A$를 만듭니다. 그리고 주어진 topic의 개수만큼 열벡터를 임의로 만듭니다. 이를 단어의 개수 x 토픽의 개수 크기의 행렬 $W$라고 하겠습니다. 이제 A를 잘 표현하도록 W에 곱할 행렬 H를 찾습니다. $H$는 토픽의 개수 x 문서의 개수 크기의 행렬일 것입니다. 이를 통해 H를 찾았다면 이제 H를 고정하고 W를 학습합니다. 이를 반복하며 최적의 W와 H를 찾는 것입니다. 이를 통해 행렬 W는 행렬 A가 가진 패턴들 중 빈도가 높은 패턴들로 학습되고 그 패턴들을 topic으로 가져가게 됩니다. \n",
    "\n",
    "이때 loss는 프로베니우스 놈으로 구합니다. \n",
    "\n",
    "$$\\lVert x \\rVert_F = (x_1^F + x_2^F + \\cdots + x_n^F)^{\\frac{1}{f}}$$\n",
    "\n",
    "벡터의 크기를 구할 때 자주 봤던 식입니다. 이를 통해 각 문서별 loss를 구하고 이것이 최소화되도록 H 안에 각 요소들을 바꿔줍니다. 이때 우리는 대체로 F = 2인 2놈을 자주 사용합니다. 이를 식으로 나타내면 다음과 같습니다. 이때 n은 단어의 개수입니다.\n",
    "\n",
    "$$\\underset{W, H \\geq 0}{arg \\; min} \\lVert A - WH \\rVert_2 = (A_1^2 - (W_1 H_1)^2 + \\cdots + A_n^2 - (W_nH_n)^2)^{\\frac{1}{2}}$$\n",
    "\n",
    "이제 구해진 topic을 가지고 document를 분류합니다. 여러 topic들의 선형 결합으로 가장 잘 표현할 수 있는 document의 가중치를 찾고 가중치가 가장 높은 topic으로 분류합니다.\n",
    "\n",
    "밑의 그림은 이를 간단하게 표현한 것입니다.\n",
    "\n",
    "<img src = \"https://iq.opengenus.org/content/images/2020/01/1_2uj6t3gNv76SpHrWf5-z-A.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. 크롤링한 뉴스 데이터로 Topic Modeling하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 직접 크롤링한 뉴스 데이터에 대해서 topic modeling을 해보겠습니다. \n",
    "\n",
    "간단하게 전 과정을 살펴보면 먼저 네이버에서 뉴스 기사를 간단하게 크롤링합니다.  \n",
    "기본적인 전처리 이후, Term-Document Matrix를 만들고 이를 non-negative factorization을 이용해 행렬 분해 하여 topic modeling을 수행합니다.   \n",
    "\n",
    "그 후, t-distributed stochastic neighbor embedding(T-SNE) 기법을 통해 topic별 시각화를 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Crawiling News**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링에 필요한 패키지 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import article\n",
    "from time import sleep, time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 정적 페이지인 네이버 뉴스 신문 기사 웹페이지를 크롤링합니다. 정적 페이지와 HTML에 대해선 [자](https://ko.wikipedia.org/wiki/%EC%A0%95%EC%A0%81_%EC%9B%B9_%ED%8E%98%EC%9D%B4%EC%A7%80)[료](https://opentutorials.org/course/2039)들을 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_news(query: str=None, crawl_num: int=1000, workers: int=4):\n",
    "    \"\"\"crawl_news 뉴스 기사 텍스트가 담긴 list를 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str, optional): 검색어. Defaults to None.\n",
    "        crawl_num (int, optional): 수집할 뉴스 기사의 개수. Defaults to 1000.\n",
    "        workers (int, optional): multi-processing 시, 사용할 thread의 개수. Defaults to 4.\n",
    "    \"\"\"\n",
    "    url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
    "    articleList = []\n",
    "    crawled_url = set()\n",
    "    keyboard_interrupt = False\n",
    "    t = time()\n",
    "    idx = 0\n",
    "    page = 1\n",
    "    \n",
    "    # 서버에 url 요청 결과를 선언\n",
    "    res = requests.get(url.format(query))\n",
    "    sleep(0.5)\n",
    "    # res를 parsing할 parser를 선언\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    with Pool(workers) as p:\n",
    "        while idx < crawl_num:\n",
    "            table = bs.find('ul', {'class': 'list_news'})\n",
    "            li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
    "            area_list = [li.find('div', {'class':'news_area'}) for li in li_list]\n",
    "            a_list = [area.find('a', {'class':'news_tit'}) for area in area_list]\n",
    "            \n",
    "            for n in a_list[:min(len(a_list), crawl_num - idx)]:\n",
    "                articleList.append(n.get('title'))\n",
    "                idx += 1\n",
    "            page += 1\n",
    "            \n",
    "            pages = bs.find('div', {'class':'sc_page_inner'})\n",
    "            next_page_url = [p for p in pages.find_all('a') if p.text == str(page)][0].get('href')\n",
    "            \n",
    "            req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
    "            bs = BeautifulSoup(req.text, 'html.parser')\n",
    "    return articleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '구글'\n",
    "articleList = crawl_news(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"공정위 새해도 '플랫폼 갑질' 겨눈다…구글·카카오·쿠팡 사정권\",\n",
       " '[신간] 구글은 어떻게 디자인하는가',\n",
       " \"구글, 인터넷뉴스서비스사업자 등록할까…여야 '법안 추진' 논의\",\n",
       " '비트코인도 뚫는 ‘무한대 성능’… 구글 “2029년 상업용 출시”',\n",
       " \"구글·카카오 등 플랫폼기업 '갑질' 칼빼든다\",\n",
       " '[CES 2022] MS·구글·아마존·메타도 안 나온다… 韓 독무대 된 세계 최대 IT쇼',\n",
       " '거친 운전에 차멀미가...구글 완전 자율주행차 타보니 [김성민의 실밸 레이더]',\n",
       " \"구글, UDC 스마트폰 특허 출원.. 차기 '픽셀7' 탑재될까?\",\n",
       " '구글 트렌드로 본 경제 키워드…‘블루 이코노미’에 주목하라',\n",
       " \"'적중률 70%' 미라클레터 올해도 10대기술 예측…구글 AR안경·테슬라 로봇\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articleList[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 tagger를 이용해 한글 명사와 알파벳만 추출해서 tdm을 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Okt 형태소 분석기 선언\n",
    "t = Okt()\n",
    "\n",
    "words_list_ = []\n",
    "vocab = Counter()\n",
    "tag_set = set(['Noun', 'Alpha'])\n",
    "stopwords = set(['글자'])\n",
    "\n",
    "for i, article in enumerate(articleList):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # tagger를 이용한 품사 태깅\n",
    "    words = t.pos(article, norm=True, stem=True)\n",
    "    \n",
    "    # 명사와 알파벳 tag를 가지며 철자 길이가 2이상이고 stopwords에 포함되지 않는 단어들로 리스트 생성\n",
    "    words = [w for w, t in words if t in tag_set and len(w) > 1 and w not in stopwords]\n",
    "    \n",
    "    vocab.update(words)\n",
    "    words_list_.append((words, article))\n",
    "    \n",
    "vocab = sorted([w for w, freq in vocab.most_common(10000)])\n",
    "word2id = {w: i for i, w in enumerate(vocab)}\n",
    "words_list = []\n",
    "for words, article in words_list_:\n",
    "    words = [w for w in words if w in word2id]\n",
    "    if len(words) > 10:\n",
    "        words_list.append((words, article))\n",
    "\n",
    "del words_list_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Build document-term matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 document-term matrix를 만들어보겠습니다. 문서 개수 x 단어 개수의 형태를 가집니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "\n",
    "dtm = np.zeros((len(words_list), len(vocab)), dtype=np.float32)\n",
    "for i, (words, article) in enumerate(words_list):\n",
    "    for word in words:\n",
    "        dtm[i, word2id[word]] += 1\n",
    "\n",
    "dtm = TfidfTransformer().fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 document-term matrix를 non-negative factorization(NMF)을 이용해 행렬 분해를 해보겠습니다. \n",
    "\n",
    "이때 NMF는 주어진 행렬 non-negative matrix X를 non-negative matrix W와 H로 행렬 분해하는 알고리즘입니다. 이어지는 코드를 통해 W와 H의 의미에 대해 파악하겠습니다. \n",
    "\n",
    "참고: [Non-negative Matrix Factorization](https://angeloyeo.github.io/2020/10/15/NMF.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative Matrix Factorization\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "K = 5\n",
    "nmf = NMF(n_components=K, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn의 NMF를 이용해 W와 H matrix를 구했습니다. \n",
    "\n",
    "W는 document length x K, H는 K x term length의 차원을 갖고 있습니다.  \n",
    "W 하나의 row는 각각의 feature에 얼만큼의 가중치를 줄 지에 대한 weight입니다.  \n",
    "H 하나의 row는 하나의 feature를 나타냅니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "W = nmf.fit_transform(dtm)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 하나의 Topic(H의 n번째 row)에 접근해서 해당 topic에 대해 값이 가장 높은 20개의 단어를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th topic\n",
      "결제 인앱 강제 금지법 정책 꼼수 애플 시간 겉도 제출 추가 요구 자료 허용 계획 이행 연내 구글 방통위 방지법 \n",
      "1th topic\n",
      "사전 레볼루션 사이트 넷마블 실시 공식 나이 세븐 등록 신작 대작 구글 게임 급등 최소 NFT 론칭 내년 오리진 이상 \n",
      "2th topic\n",
      "삼성 미국 전자 픽셀 모뎀 기관 조사 탑재 처음 마이크로소프트 부회장 영진 확인 동맹 이재용 아마존 시장 구글 사운드 공개 \n",
      "3th topic\n",
      "애플 규제 경쟁 위원장 저승사자 EU 규칙 촉구 플랫폼 시행 구글 공룡 방지 강화 엄격 적용 테크 넷플릭스 방통위 시급 \n",
      "4th topic\n",
      "검색 도전 시장 아마존 클라우드 비즈 확대 과감 위해 글로벌 투자 vs 전쟁 점화 사용자 국내 네이버 테크 구글 메타 \n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(f\"{k}th topic\")\n",
    "    for index in H[k].argsort()[::-1][:20]:\n",
    "        print(vocab[index], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 W에서 하나의 topic (W의 n번째 column)에 접근해서 해당 topic에 대해 값이 가장 높은 3개의 뉴스 기사 제목을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0th topic===\n",
      "겉도는 인앱결제 강제금지법… 구글은 결제정책 꼼수, 애플은 시간끌기\n",
      "겉도는 인앱결제 강제금지법… 구글은 결제정책 꼼수, 애플은 시간끌기\n",
      "구글은 결제정책 꼼수, 애플은 모르쇠… 힘못쓰는 갑질방지법 [인앱결제강제 금지법 시행 100일]\n",
      "\n",
      "===1th topic===\n",
      "넷마블, 기대신작 세븐나이츠 레볼루션...'구글·공식 사이트 사전등록 실시'\n",
      "넷마블, 기대신작 '세븐나이츠 레볼루션' 구글/공식 사이트 사전등록 실시\n",
      "넷마블, 기대작 세븐나이츠 레볼루션 구글·공식 사이트 사전등록 실시\n",
      "\n",
      "===2th topic===\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "\n",
      "===3th topic===\n",
      "'구글‧애플 저승사자' EU경쟁위원장, 빅테크 규제 위한 규칙 시행 촉구\n",
      "'구글‧애플 저승사자' EU경쟁위원장, 빅테크 규제 위한 규칙 시행 촉구\n",
      "구글·애플·넷플릭스 ‘플랫폼 공룡’ 갑질 방지 강화… 방통위, 규제 엄격 적용\n",
      "\n",
      "===4th topic===\n",
      "구글 vs 네이버… 빅테크 ‘검색전쟁’ 재점화 국내시장 1위에 ‘사용자 친화 검색’으로 도전장\n",
      "구글 vs 네이버… 빅테크 ‘검색전쟁’ 재점화 국내시장 1위에 ‘사용자 친화 검색’으로 도전장\n",
      "[글로벌 비즈] 구글 클라우드, 시장 확대 위해 과감한 투자…아마존에 도전장\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(f\"==={k}th topic===\")\n",
    "    for index in W[:, k].argsort()[::-1][:3]:\n",
    "        print(words_list[index][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번째 topic에 대해 가장 높은 가중치를 갖는 제목 5개를 출력하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "이재용 삼성전자 부회장, 미국에서 '뉴삼성' 동맹 확인..마이크로소프트·아마존·구글 경영진 잇따라 만나\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "조사기관 “구글 픽셀6에 삼성전자 5G모뎀 탑재, 미국시장에서 처음\"\n",
      "[더벨][뉴삼성 차세대 리더십]소프트웨어 경쟁력 높인다…구글·MS출신 발탁승진\n"
     ]
    }
   ],
   "source": [
    "for index in W[:, 2].argsort()[::-1][:5]:\n",
    "    print(words_list[index][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 t-SNE를 이용해 topic별 시각화를 진행하겠습니다. \n",
    "\n",
    "t-SNE(t-Stochastic Neighbor Embedding)은 고차원의 벡터를 데이터간 구조적 특징을 유지한 상태로 저차원(2~3차원) 벡터로 축소하는 방법 중 하나입니다. 주로 고차원 데이터의 시각화를 위해 사용됩니다.\n",
    "\n",
    "참고: [lovit: t-SNE](https://lovit.github.io/nlp/representation/2018/09/28/tsne/#:~:text=t%2DSNE%20%EB%8A%94%20%EA%B3%A0%EC%B0%A8%EC%9B%90%EC%9D%98,%EC%9D%98%20%EC%A7%80%EB%8F%84%EB%A1%9C%20%ED%91%9C%ED%98%84%ED%95%A9%EB%8B%88%EB%8B%A4.)\n",
    "\n",
    "참고: [ratsgo: t-SNE](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 63 nearest neighbors...\n",
      "[t-SNE] Indexed 64 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 64 samples in 0.003s...\n",
      "[t-SNE] Computed conditional probabilities for sample 64 / 64\n",
      "[t-SNE] Mean sigma: 0.107609\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.561291\n",
      "[t-SNE] KL divergence after 1000 iterations: -0.062155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# n_components = 차원 수\n",
    "tsne = TSNE(n_components=2, init='pca', verbose=1)\n",
    "\n",
    "# W matrix에 대해 t-sne를 수행합니다.\n",
    "W2d = tsne.fit_transform(W)\n",
    "\n",
    "# 각 뉴스 기사 제목마다 가중치가 가장 높은 topic을 저장합니다.\n",
    "topicIndex = [v.argmax() for v in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1131\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1131\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1131\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"5a684a58-54da-4364-ac07-102665a18197\" data-root-id=\"1132\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n    \n  const docs_json = {\"b4682a68-fa0e-4e7d-8772-58b06cbc8579\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1141\"}],\"center\":[{\"id\":\"1144\"},{\"id\":\"1148\"},{\"id\":\"1181\"}],\"height\":580,\"left\":[{\"id\":\"1145\"}],\"renderers\":[{\"id\":\"1168\"}],\"title\":{\"id\":\"1170\"},\"toolbar\":{\"id\":\"1156\"},\"width\":720,\"x_range\":{\"id\":\"1133\"},\"x_scale\":{\"id\":\"1137\"},\"y_range\":{\"id\":\"1135\"},\"y_scale\":{\"id\":\"1139\"}},\"id\":\"1132\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"label\":{\"field\":\"topic\"},\"renderers\":[{\"id\":\"1168\"}]},\"id\":\"1182\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1163\"}},\"id\":\"1169\",\"type\":\"CDSView\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1173\"},\"group\":null,\"major_label_policy\":{\"id\":\"1174\"},\"ticker\":{\"id\":\"1146\"}},\"id\":\"1145\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"color\":[\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#1f77b4\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#ff7f0e\",\"#ffbb78\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ffbb78\",\"#ffbb78\",\"#aec7e8\",\"#aec7e8\",\"#ffbb78\",\"#2ca02c\",\"#aec7e8\",\"#ffbb78\",\"#2ca02c\",\"#aec7e8\",\"#ff7f0e\",\"#2ca02c\",\"#ffbb78\",\"#aec7e8\",\"#ffbb78\",\"#aec7e8\",\"#ffbb78\",\"#ff7f0e\",\"#ff7f0e\",\"#ff7f0e\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#ffbb78\",\"#2ca02c\",\"#2ca02c\",\"#ff7f0e\",\"#ff7f0e\",\"#ffbb78\",\"#ffbb78\"],\"document\":[\"'\\uc801\\uc911\\ub960 70%' \\ubbf8\\ub77c\\ud074\\ub808\\ud130 \\uc62c\\ud574\\ub3c4 10\\ub300\\uae30\\uc220 \\uc608\\uce21\\u2026\\uad6c\\uae00 AR\\uc548\\uacbd\\u00b7\\ud14c\\uc2ac\\ub77c \\ub85c\\ubd07\",\"\\\"\\uc62c\\ud574 \\uba54\\ud0c0\\ubc84\\uc2a4 \\uacbd\\uc7c1 \\ubcf8\\uaca9\\ud654\\\"...\\uba54\\ud0c0\\uac00 \\uc120\\ub450, \\uc560\\ud50c\\u00b7MS\\u00b7\\uad6c\\uae00\\uc774 \\ucd94\\uaca9\",\"\\uacf5\\uc815\\uc704\\uc6d0\\uc7a5 \\\"\\uad6c\\uae00 \\uc571\\ub9c8\\ucf13\\uc2dc\\uc7a5 \\uacbd\\uc7c1\\uc81c\\ud55c\\ud589\\uc704 \\uc804\\uc6d0\\ud68c\\uc758 \\uc2ec\\uc758 \\uc608\\uc815\\\"\",\"\\ud2f0\\uc564\\ucf00\\uc774\\ud329\\ud1a0\\ub9ac '\\uac80\\uc740\\uc655\\uad00:\\uba54\\uae30\\uc655\\uc758 \\ubd84\\ub178' \\uad6c\\uae00 \\ud50c\\ub808\\uc774 \\uc778\\uae30 \\uc21c\\uc704 1\\uc704 \\ub2ec\\uc131\",\"[\\uae00\\ub85c\\ubc8c \\ube44\\uc988] \\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc, \\uc2dc\\uc7a5 \\ud655\\ub300 \\uc704\\ud574 \\uacfc\\uac10\\ud55c \\ud22c\\uc790\\u2026\\uc544\\ub9c8\\uc874\\uc5d0 \\ub3c4\\uc804\\uc7a5\",\"\\uc560\\ud50c, \\uc5f0\\ub0b4 \\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c\\uae08\\uc9c0\\ubc95 \\uc774\\ud589\\uacc4\\ud68d \\uc81c\\ucd9c\\ud560\\uae4c?\\u2026\\ubc29\\ud1b5\\uc704, \\uad6c\\uae00\\uc5d0\\ub3c4 '\\uc81c3\\uc790 \\uacb0\\uc81c \\ud5c8\\uc6a9' \\ucd94\\uac00\\uc790\\ub8cc \\uc694\\uad6c\",\"\\uad6c\\uae00\\u00b7\\uc560\\ud50c\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4 \\u2018\\ud50c\\ub7ab\\ud3fc \\uacf5\\ub8e1\\u2019 \\uac11\\uc9c8 \\ubc29\\uc9c0 \\uac15\\ud654\\u2026 \\ubc29\\ud1b5\\uc704, \\uaddc\\uc81c \\uc5c4\\uaca9 \\uc801\\uc6a9\",\"[\\uae00\\ub85c\\ubc8c \\ube44\\uc988] \\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc, \\uc2dc\\uc7a5 \\ud655\\ub300 \\uc704\\ud574 \\uacfc\\uac10\\ud55c \\ud22c\\uc790\\u2026\\uc544\\ub9c8\\uc874\\uc5d0 \\ub3c4\\uc804\\uc7a5\",\"\\uc560\\ud50c, \\uc5f0\\ub0b4 \\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c\\uae08\\uc9c0\\ubc95 \\uc774\\ud589\\uacc4\\ud68d \\uc81c\\ucd9c\\ud560\\uae4c?\\u2026\\ubc29\\ud1b5\\uc704, \\uad6c\\uae00\\uc5d0\\ub3c4 '\\uc81c3\\uc790 \\uacb0\\uc81c \\ud5c8\\uc6a9' \\ucd94\\uac00\\uc790\\ub8cc \\uc694\\uad6c\",\"\\uad6c\\uae00\\u00b7\\uc560\\ud50c\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4 \\u2018\\ud50c\\ub7ab\\ud3fc \\uacf5\\ub8e1\\u2019 \\uac11\\uc9c8 \\ubc29\\uc9c0 \\uac15\\ud654\\u2026 \\ubc29\\ud1b5\\uc704, \\uaddc\\uc81c \\uc5c4\\uaca9 \\uc801\\uc6a9\",\"\\uad6c\\uae00 \\uacf5\\uc778 \\uad50\\uc721\\uc804\\ubb38\\uac00 \\uae40\\ub3d9\\uc6d0 \\ub300\\ud45c\\uc758 'Google \\ud65c\\uc6a9\\ubc95' \\ub124\\uc774\\ubc84 \\uc5d1\\uc2a4\\ud37c\\ud2b8 \\uc624\\ud508\",\"\\\"\\uc720\\ud29c\\ube0c\\ub3c4 \\ud1a0\\uc2a4\\ud398\\uc774\\ub85c\\\"\\u2026 \\ud1a0\\uc2a4\\ud398\\uc774\\uba3c\\uce20, \\uad6c\\uae00 \\uc81c\\ud734\\ub85c \\uac04\\ud3b8\\uacb0\\uc81c \\ud655\\uc7a5\",\"\\uc624\\ubbf8\\ud06c\\ub860 \\ud655\\uc0b0\\uc5d0 CES \\ube68\\uac04\\ubd88\\u2026\\ucd5c\\ud0dc\\uc6d0\\u00b7\\uc815\\uc758\\uc120 \\ucd9c\\uc7a5 \\uc7ac\\uac80\\ud1a0, \\uad6c\\uae00\\u00b7\\uba54\\ud0c0\\u00b7MS \\ubd88\\ucc38\",\"LG CNS, \\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988\\uc11c \\ub9ac\\ub4dc \\uc0dd\\uc131\\uacfc \\ubca0\\uc2a4\\ud2b8\\ud300 2\\uac1c\\ubd80\\ubb38 \\uc218\\uc0c1\",\"\\ubbf8\\ub974\\uc758 \\uc804\\uc1242: MOM, \\uad6c\\uae00 \\ub9e4\\ucd9c \\uc21c\\uc704 \\uc0c1\\uc2b9\\uc138, \\uc0c1\\uc704\\uad8c \\uc9c4\\uc785 \\ubc1c\\ud310 \\ub9c8\\ub828\",\"LG CNS, \\u2018\\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988\\u2019 3\\ud68c \\uc5f0\\uc18d \\uc218\\uc0c1\\u2026\\uc720\\uc77c 2\\uac1c\\ubd80\\ubb38 \\uc120\\uc815\",\"\\uc544\\ub9c8\\uc874. \\uba54\\ud0c0. \\ud2b8\\uc704\\ud130 \\uc774\\uc5b4 GM. \\uad6c\\uae00 \\uc6e8\\uc774\\ubaa8\\ub3c4 \\uc624\\ubbf8\\ud06c\\ub860 \\ud655\\uc0b0\\uc73c\\ub85c 'CES 2022' \\ucc38\\uac00 \\ucde8\\uc18c\",\"\\ud574\\ud53c\\uba38\\ub2c8, \\uad6c\\uae00\\uae30\\ud504\\ud2b8\\ucf54\\ub4dc \\uad6c\\ub9e4\\uace0\\uac1d \\ub300\\uc0c1 \\ub9ac\\ub2c8\\uc9c0W \\uc544\\uc774\\ud15c \\uc774\\ubca4\\ud2b8 \\uc9c4\\ud589\",\"\\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\ubaa8\\ub974\\uc1e0\\u2026 \\ud798\\ubabb\\uc4f0\\ub294 \\uac11\\uc9c8\\ubc29\\uc9c0\\ubc95 [\\uc778\\uc571\\uacb0\\uc81c\\uac15\\uc81c \\uae08\\uc9c0\\ubc95 \\uc2dc\\ud589 100\\uc77c]\",\"\\ud1a0\\uc2a4\\ud398\\uc774\\uba3c\\uce20 \\uad6c\\uae00\\uacfc \\ud1a0\\uc2a4\\ud398\\uc774 \\uc81c\\ud734, \\uae40\\ubbfc\\ud45c \\\"\\uac04\\ud3b8\\ud55c \\uacb0\\uc81c\\uacbd\\ud5d8 \\uc9c0\\uc6d0\\\"\",\"\\uac89\\ub3c4\\ub294 \\uc778\\uc571\\uacb0\\uc81c \\uac15\\uc81c\\uae08\\uc9c0\\ubc95\\u2026 \\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\uc2dc\\uac04\\ub04c\\uae30\",\"\\uac89\\ub3c4\\ub294 \\uc778\\uc571\\uacb0\\uc81c \\uac15\\uc81c\\uae08\\uc9c0\\ubc95\\u2026 \\uad6c\\uae00\\uc740 \\uacb0\\uc81c\\uc815\\ucc45 \\uaf3c\\uc218, \\uc560\\ud50c\\uc740 \\uc2dc\\uac04\\ub04c\\uae30\",\"[\\ud2b9\\uc9d5\\uc8fc] FSN, '\\ud2f1\\ud1a1' \\uad6c\\uae00 \\ub204\\ub974\\uace0 \\uc804\\uc138\\uacc41\\uc704 \\uae30\\ub85d\\u2026 \\uc804\\uc138\\uacc4 \\ud2f1\\ud1a1 \\uad11\\uace0\\ub300\\ud589 \\uad8c\\ud55c \\ubd80\\uac01\",\"[\\uc9d1\\uc911\\ucde8\\uc7acM] MS \\uad6c\\uae00 A\\ud559\\uc810, \\ub124\\uc774\\ubc84 \\uce74\\uce74\\uc624 F\\ud559\\uc810\\u2025IT\\uae30\\uc5c5\\ub4e4\\uc758 \\ud0c4\\uc18c \\uc131\\uc801\\ud45c\",\"[\\uae08\\uc77c \\uc0b0\\uc5c5\\uacc4 \\uc8fc\\uc694\\uae30\\uc0ac] \\\"\\uc624\\ubbf8\\ud06c\\ub860 \\ubcc0\\uc774 \\ud655\\uc0b0\\\" \\uad6c\\uae00\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uba54\\ud0c0\\u00b7\\ud2f1\\ud1a1 CES \\ubd88\\ucc38\\u2026 \\\"8K \\uc0dd\\ud0dc\\uacc4 \\ud655\\uc7a5 \\uac00\\uc18d\\ud654\\\" \\uc544\\ub9c8\\uc874, '8K \\ud611\\ud68c' \\ud569\\ub958 \\u5916\",\"[\\ub274\\uc2a4\\ud574\\uc124]\\uc560\\ud50c\\u00b7\\uad6c\\uae00 \\uc790\\uccb4\\ub4f1\\uae09\\ubd84\\ub958 \\ub0a8\\uc6a9...\\uae30\\uc900 \\uc815\\ube44 \\uc2dc\\uae09\",\"[\\ub274\\uc2a4\\ud574\\uc124]\\uc560\\ud50c\\u00b7\\uad6c\\uae00 \\uc790\\uccb4\\ub4f1\\uae09\\ubd84\\ub958 \\ub0a8\\uc6a9...\\uae30\\uc900 \\uc815\\ube44 \\uc2dc\\uae09\",\"LG\\uc804\\uc790, 2022\\ub144\\ud615 \\uc0ac\\uc6b4\\ub4dc \\ubc14 \\uacf5\\uac1c...\\uad6c\\uae00\\u00b7\\uc544\\ub9c8\\uc874, \\uc778\\uacf5\\uc9c0\\ub2a5 \\uc2a4\\ud53c\\ucee4 \\uc5f0\\ub3d9 \\ud1b5\\ud574 \\uc74c\\uc131\\ub9cc\\uc73c\\ub85c \\uc0ac\\uc6b4\\ub4dc \\ubc14 \\uc870\\uc791\",\"[AICON \\uad11\\uc8fc 2021] \\uad6c\\uae00 \\ucf54\\ub9ac\\uc544 \\uae40\\ud0dc\\uc6d0 \\uc804\\ubb34 \\\"\\ub514\\uc9c0\\ud138 \\uae30\\uc220\\uc740 \\uc138\\uc0c1\\uc758 \\ubb38\\uc81c\\ub97c \\ud574\\uacb0\\ud55c\\ub2e4\\\"\",\"\\uc120\\uc6b0\\uc724 \\uc640\\uadf8 \\ub300\\ud45c \\\"\\uad6c\\uae00 \\ud611\\uc5c5 \\uccab \\uad6d\\ub0b4 OTA\\u2026\\uc678\\uad6d\\uc778\\ub3c4 \\uc774\\uc81c \\uc6b0\\ub9ac \\uace0\\uac1d\\\" [\\uc778\\ud130\\ubdf0]\",\"\\uad11\\uc9c4\\uc708\\ud14d, 3D\\uc0ac\\uc6b4\\ub4dc \\ucd2c\\uc601 \\uc2e0\\uae30\\uc220 \\uac1c\\ubc1c...\\uad6c\\uae00 \\ub4f1 \\uc2a4\\ub9c8\\ud2b8\\ub514\\ubc14\\uc774\\uc2a4 \\uacb0\\ud569 1\\ucc28 \\uc0c1\\uc6a9\\ubaa8\\ub378 \\uc591\\uc0b0 \\ubaa9\\ud45c\",\"'\\uad6c\\uae00\\u00b7\\ub137\\ud50c\\ub9ad\\uc2a4' \\ub300\\uc0c1 \\ub9dd \\uc548\\uc815\\uc131 \\ud655\\ubcf4 \\uac00\\uc774\\ub4dc\\ub77c\\uc778 \\ub9c8\\ub828\\u2026 \\uc778\\ud130\\ub137 \\ud68c\\uc120 \\uc6a9\\ub7c9 \\ud655\\ubcf4 \\uc758\\ubb34\\ud654\",\"\\uad6c\\uae00 vs \\ub124\\uc774\\ubc84\\u2026 \\ube45\\ud14c\\ud06c \\u2018\\uac80\\uc0c9\\uc804\\uc7c1\\u2019 \\uc7ac\\uc810\\ud654 \\uad6d\\ub0b4\\uc2dc\\uc7a5 1\\uc704\\uc5d0 \\u2018\\uc0ac\\uc6a9\\uc790 \\uce5c\\ud654 \\uac80\\uc0c9\\u2019\\uc73c\\ub85c \\ub3c4\\uc804\\uc7a5\",\"\\uad6c\\uae00 vs \\ub124\\uc774\\ubc84\\u2026 \\ube45\\ud14c\\ud06c \\u2018\\uac80\\uc0c9\\uc804\\uc7c1\\u2019 \\uc7ac\\uc810\\ud654 \\uad6d\\ub0b4\\uc2dc\\uc7a5 1\\uc704\\uc5d0 \\u2018\\uc0ac\\uc6a9\\uc790 \\uce5c\\ud654 \\uac80\\uc0c9\\u2019\\uc73c\\ub85c \\ub3c4\\uc804\\uc7a5\",\"[\\uc704\\ud074\\ub9ac\\ub9ac\\ud3ec\\ud2b8 60\\ud638] '\\uc62c\\ud574 \\ud55c\\uad6d\\uc778\\uc774 \\uad6c\\uae00\\uc11c \\uac00\\uc7a5 \\ub9ce\\uc774 \\ucc3e\\uc740 \\uac80\\uc0c9\\uc5b4' 3\\uc704 \\uc624\\uc9d5\\uc5b4\\uac8c\\uc784, 2\\uc704 \\ubc31\\uc2e0\\uc608\\uc57d, 1\\uc704\\ub294\\u2026\",\"[\\uc704\\ud074\\ub9ac\\ub9ac\\ud3ec\\ud2b8 60\\ud638] '\\uc62c\\ud574 \\ud55c\\uad6d\\uc778\\uc774 \\uad6c\\uae00\\uc11c \\uac00\\uc7a5 \\ub9ce\\uc774 \\ucc3e\\uc740 \\uac80\\uc0c9\\uc5b4' 3\\uc704 \\uc624\\uc9d5\\uc5b4\\uac8c\\uc784, 2\\uc704 \\ubc31\\uc2e0\\uc608\\uc57d, 1\\uc704\\ub294\\u2026\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc791 \\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158 \\uad6c\\uae00\\u00b7\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc\",\"\\uc5d4\\ub3cc\\ud540\\ucee4\\ub125\\ud2b8 \\uc2e0\\uc791 '\\uc2a4\\ud0d1 \\ubc14\\uc774: \\uc0b0\\ud0c0 \\ub808\\uc774\\uc2a4' \\uad6c\\uae00 \\ud50c\\ub808\\uc774 \\uc2a4\\ud1a0\\uc5b4 \\ucd9c\\uc2dc\",\"\\ubbf8, \\uad6c\\uae00\\u00b7\\uba54\\ud0c0 '\\ud0dc\\ud3c9\\uc591 \\uad11\\ucf00\\uc774\\ube14' \\uc0ac\\uc6a9\\uc2b9\\uc778 \\uad8c\\uace0\\u2026\\\"\\uc548\\ubcf4 \\uc6b0\\ub824\\ub85c \\ud64d\\ucf69 \\uad6c\\uac04\\uc740 \\uc81c\\uc678\\\"\",\"\\uc2e4\\uc801 \\uc804\\ub9dd \\uc5c7\\uac08\\ub9ac\\ub294 \\u7f8e \\ube45\\ud14c\\ud06c, MS\\u00b7\\uad6c\\uae00\\u00b7\\uba54\\ud0c0 \\u2018\\ub9d1\\uc74c\\u2019 vs \\uc560\\ud50c\\u00b7\\uc544\\ub9c8\\uc874 \\u2018\\uae00\\uc384\\u2019\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc2e0\\uc791 \\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158...'\\uad6c\\uae00\\u00b7\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc'\",\"\\uc544\\uc774\\uc2a4\\ubc84\\ub4dc \\uac8c\\uc784\\uc988 '\\ubbf8\\ub974\\uc758 \\uc804\\uc1242: MOM', \\uad6c\\uae00 \\ubb34\\ub8cc \\uc778\\uae30 \\uc21c\\uc704 2\\uc704 \\ub2ec\\uc131\",\"\\ud55c\\uad6d\\uacf5\\uc608\\ub514\\uc790\\uc778\\ubb38\\ud654\\uc9c4\\ud765\\uc6d0, \\uad6c\\uae00 \\uc544\\ud2b8 \\uc564 \\uceec\\ucc98\\uc640 \\ud611\\uc5c5...\\ud55c\\uad6d\\uc758 \\uacf5\\uc608\\ubb38\\ud654 \\uc120\\ubcf4\\uc5ec\",\"\\ub137\\ub9c8\\ube14, \\uae30\\ub300\\uc2e0\\uc791 '\\uc138\\ube10\\ub098\\uc774\\uce20 \\ub808\\ubcfc\\ub8e8\\uc158' \\uad6c\\uae00/\\uacf5\\uc2dd \\uc0ac\\uc774\\ud2b8 \\uc0ac\\uc804\\ub4f1\\ub85d \\uc2e4\\uc2dc\",\"[\\ub354\\ubca8][\\ub274\\uc0bc\\uc131 \\ucc28\\uc138\\ub300 \\ub9ac\\ub354\\uc2ed]\\uc18c\\ud504\\ud2b8\\uc6e8\\uc5b4 \\uacbd\\uc7c1\\ub825 \\ub192\\uc778\\ub2e4\\u2026\\uad6c\\uae00\\u00b7MS\\ucd9c\\uc2e0 \\ubc1c\\ud0c1\\uc2b9\\uc9c4\",\"\\ud3ec\\uc2a4\\ud14d, \\uc2a4\\ud3ec\\uce20 \\uc778\\uacf5\\uc9c0\\ub2a5(AI) \\ubd84\\uc57c...\\uad6c\\uae00 \\ud074\\ub77c\\uc6b0\\ub4dc \\uc544\\u2027\\ud0dc \\uacf5\\uacf5\\ubd80\\ubb38 \\ud30c\\ud2b8\\ub108 \\uc120\\uc815\",\"[\\uc810\\uc2ec \\ube0c\\ub9ac\\ud551]\\uc554\\ud638\\ud654\\ud3d0 \\ud558\\ub77d\\uc138\\u00b7\\u00b7\\u00b7\\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uad6c\\uae00 \\uc804 \\ud68c\\uc7a5, \\uccb4\\uc778\\ub9c1\\ud06c \\ud504\\ub85c\\uc81d\\ud2b8 \\ud569\\ub958\",\"\\ub124\\uc624\\ub9ac\\uc9c4, \\uc2e0\\uc791 \\uac8c\\uc784 \\uad6c\\uae00 \\ub4f1 3\\ub300 \\uc571 \\ub9c8\\ucf13\\ub860\\uce6d\\u2026\\u201c\\ub0b4\\ub144 \\ucd5c\\uc18c 2\\uac1c \\uc774\\uc0c1 \\uc2e0\\uc791\\uacfc NFT\\uac8c\\uc784 \\uacf5\\uac1c \\uc608\\uc815\\u201d\",\"[AICON \\uad11\\uc8fc 2021] \\uad6c\\uae00 \\ucf54\\ub9ac\\uc544 \\uae40\\ud0dc\\uc6d0 \\uc804\\ubb34 \\uae30\\uc870 \\uac15\\uc5f0 \\ub098\\uc11c... \\\"\\ub514\\uc9c0\\ud138 \\uae30\\uc220 \\ud1b5\\ud574 \\ub2f9\\ub300\\uc758 \\uad00\\uc2ec\\uc0ac\\uc640 \\ubcc0\\ud654 \\ud30c\\uc545\\ud560 \\uc218 \\uc788\\uc5b4!\\\"\",\"\\uc601\\uc6c5 \\uc218\\uc9d1 \\ud30c\\ud2f0 \\ubc29\\uce58\\ud615 RPG '\\ub9d0\\ub2e8 \\ubcd1\\uc0ac\\uc5d0\\uc11c \\uad70\\uc8fc\\uae4c\\uc9c0 - \\uad70\\uc8fc \\ud0a4\\uc6b0\\uae30' \\uad6c\\uae00\\ud50c\\ub808\\uc774 \\ucd9c\\uc2dc\",\"[\\ud2b9\\uc9d5\\uc8fc]NHN\\ubc85\\uc2a4, \\uad6c\\uae00\\u00b7\\uc560\\ud50c\\uc5d0 \\uc2f8\\uc774\\uc6d4\\ub4dc \\uc571 \\uc2e0\\uccad\\u2026\\ub124\\uc774\\ubc84\\u00b7\\uce74\\uce74\\uc624 \\uc787\\ub294 K-\\ud50c\\ub7ab\\ud3fc \\ucd9c\\uc0ac\\ud45c\",\"\\uad6c\\uae00, 12\\uc6d4 '\\ud53d\\uc140 \\ud53c\\ucc98 \\ub4dc\\ub86d' \\uc5c5\\ub370\\uc774\\ud2b8 \\uacf5\\uac1c.. '\\ud53d\\uc1406' \\uc9c0\\ubb38 \\uc13c\\uc11c \\uc131\\ub2a5 \\uac1c\\uc120\",\"\\uc870\\uc0ac\\uae30\\uad00 \\u201c\\uad6c\\uae00 \\ud53d\\uc1406\\uc5d0 \\uc0bc\\uc131\\uc804\\uc790 5G\\ubaa8\\ub380 \\ud0d1\\uc7ac, \\ubbf8\\uad6d\\uc2dc\\uc7a5\\uc5d0\\uc11c \\ucc98\\uc74c\\\"\",\"\\uc870\\uc0ac\\uae30\\uad00 \\u201c\\uad6c\\uae00 \\ud53d\\uc1406\\uc5d0 \\uc0bc\\uc131\\uc804\\uc790 5G\\ubaa8\\ub380 \\ud0d1\\uc7ac, \\ubbf8\\uad6d\\uc2dc\\uc7a5\\uc5d0\\uc11c \\ucc98\\uc74c\\\"\",\"[\\uae09\\ub4f1\\uc655\\uc758 '\\uae09\\ub4f1\\ub9e5 \\ud544\\uc0b4\\uae30'] NHN\\ubc85\\uc2a4, \\uad6c\\uae00\\u00b7\\uc560\\ud50c \\uc571 \\ub4f1\\ub85d \\uc2ec\\uc0ac \\uc2e0\\uccad \\uc18c\\uc2dd\\uc5d0 \\uc0c1\\uc2b9! GO? STOP?!\",\"\\uad6c\\uae00 \\uc790\\uccb4 \\uac1c\\ubc1c \\uc571\\ud50c\\ub808\\uc774\\uc5b4 'Google Play Games' \\uacf5\\uac1c, \\uc571 \\ud50c\\ub808\\uc774\\uc5b4 \\uc0dd\\ud0dc\\uacc4 \\uc9c0\\uac01\\ubcc0\\ub3d9 \\uc62c\\uae4c\",\"\\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uc804 \\uad6c\\uae00 CEO, \\ube14\\ub85d\\uccb4\\uc778 \\uc624\\ub77c\\ud074 \\uc194\\ub8e8\\uc158 \\uac1c\\ubc1c\\uc0ac '\\uccb4\\uc778\\ub9c1\\ud06c' \\ud569\\ub958\",\"[\\uc5ec\\uc758\\uc625] \\uc5d0\\ub9ad \\uc288\\ubbf8\\ud2b8 \\uc804 \\uad6c\\uae00 CEO, \\ube14\\ub85d\\uccb4\\uc778 \\uc624\\ub77c\\ud074 \\uc194\\ub8e8\\uc158 \\uac1c\\ubc1c\\uc0ac \\uc804\\uaca9 \\ud569\\ub958\",\"\\ub098\\uc2a4\\ubbf8\\ub514\\uc5b4, '\\uad6c\\uae00 \\ud504\\ub9ac\\ubbf8\\uc5b4 \\ud30c\\ud2b8\\ub108 \\uc5b4\\uc6cc\\uc988 2021' \\uc218\\uc0c1\\u2026\\ube0c\\ub79c\\ub4dc \\uc9c0\\uc18d\\uac00\\ub2a5 \\uc131\\uc7a5\\uc5d0 \\uae30\\uc5ec\",\"[\\uc0bc\\uc815KPMG \\ubcf4\\uace0\\uc11c] \\ud14c\\ud06c \\uae30\\uc5c5, ESG \\ub9ac\\uc2a4\\ud06c \\uc9c1\\uba74\\u2026 \\\"\\uc6b0\\uc120 \\uacfc\\uc81c \\ub3c4\\ucd9c\\ud574\\uc57c\\\"\",\"\\uc774\\uc7ac\\uc6a9 \\uc0bc\\uc131\\uc804\\uc790 \\ubd80\\ud68c\\uc7a5, \\ubbf8\\uad6d\\uc5d0\\uc11c '\\ub274\\uc0bc\\uc131' \\ub3d9\\ub9f9 \\ud655\\uc778..\\ub9c8\\uc774\\ud06c\\ub85c\\uc18c\\ud504\\ud2b8\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uad6c\\uae00 \\uacbd\\uc601\\uc9c4 \\uc787\\ub530\\ub77c \\ub9cc\\ub098\",\"\\uc774\\uc7ac\\uc6a9 \\uc0bc\\uc131\\uc804\\uc790 \\ubd80\\ud68c\\uc7a5, \\ubbf8\\uad6d\\uc5d0\\uc11c '\\ub274\\uc0bc\\uc131' \\ub3d9\\ub9f9 \\ud655\\uc778..\\ub9c8\\uc774\\ud06c\\ub85c\\uc18c\\ud504\\ud2b8\\u00b7\\uc544\\ub9c8\\uc874\\u00b7\\uad6c\\uae00 \\uacbd\\uc601\\uc9c4 \\uc787\\ub530\\ub77c \\ub9cc\\ub098\",\"'\\uad6c\\uae00\\u2027\\uc560\\ud50c \\uc800\\uc2b9\\uc0ac\\uc790' EU\\uacbd\\uc7c1\\uc704\\uc6d0\\uc7a5, \\ube45\\ud14c\\ud06c \\uaddc\\uc81c \\uc704\\ud55c \\uaddc\\uce59 \\uc2dc\\ud589 \\ucd09\\uad6c\",\"'\\uad6c\\uae00\\u2027\\uc560\\ud50c \\uc800\\uc2b9\\uc0ac\\uc790' EU\\uacbd\\uc7c1\\uc704\\uc6d0\\uc7a5, \\ube45\\ud14c\\ud06c \\uaddc\\uc81c \\uc704\\ud55c \\uaddc\\uce59 \\uc2dc\\ud589 \\ucd09\\uad6c\"],\"id\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"topic\":[\"3\",\"3\",\"3\",\"3\",\"4\",\"0\",\"3\",\"4\",\"0\",\"3\",\"4\",\"0\",\"4\",\"4\",\"3\",\"4\",\"4\",\"3\",\"0\",\"0\",\"0\",\"0\",\"3\",\"4\",\"4\",\"3\",\"3\",\"2\",\"3\",\"4\",\"3\",\"3\",\"4\",\"4\",\"3\",\"3\",\"1\",\"1\",\"3\",\"4\",\"1\",\"3\",\"4\",\"1\",\"2\",\"4\",\"3\",\"1\",\"3\",\"1\",\"3\",\"2\",\"2\",\"2\",\"3\",\"3\",\"3\",\"3\",\"4\",\"4\",\"2\",\"2\",\"3\",\"3\"],\"x\":{\"__ndarray__\":\"UUTfQvR4IMNRyKnCwjTvQkkeQsPhb6zD6XBBw0keQsPhb6zD6XBBwwXJ+0GEqkfD6mQ+wlJo40G/IBZDFX+JQcrbJcKNS0BD3UTPwwmrG8NxhLzDcYS8w5Qzd0OsNApDX9wLwr9lZ8O/ZWfD9GJhQya9LEP8qKNCQ65XQ630wkGkAAvDpAALw95jXsLeY17CigIwQqyuk0MKNZ1CUkDJwih+w0J/Z2ZDDDgFQyh+w0I2apRDgvLWwglboEIld5RDy845QwVsQ0OalyDDPPCMQ0Tg1UNE4NVDx9TkQvPYA0NBqHBCyM4EQVRIo0IESaFB9OHUQ/Th1EM7ToTDO06Eww==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[64]},\"y\":{\"__ndarray__\":\"0JeTQkGdF8OK0S3DfpkvQ+YfZ0OaZgdCaDOGw+YfZ0OaZgdCaDOGw9teMEM0s3pC//+QQm+60cIb+O9Cdy8twyU5E0Oc9HbCBC/qQajNBEKEpu7BhKbuwdCrjcFsItzCktm/wivJGMMryRjD7F0fw5Q8gELu1Q3DeIXbQu9Y18Hb+oVD2/qFQ16pW8FeqVvBvkusQzd8k0L/ePJCgW3SwoLOpENspDZCD0S3QYLOpEM1kSXDh6/1QllyKMC4/RRDIxuPP5a0MEO7KJrCf5zSwkjb/MFI2/zBzLBZw8IQDsLsDUdCAYPuQQ+XkcILj8ZCvwjBwr8IwcLZuYHD2bmBww==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[64]}},\"selected\":{\"id\":\"1179\"},\"selection_policy\":{\"id\":\"1178\"}},\"id\":\"1163\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1177\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1152\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1153\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1155\"}},\"id\":\"1150\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1151\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1133\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1141\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1144\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1176\"},\"group\":null,\"major_label_policy\":{\"id\":\"1177\"},\"ticker\":{\"id\":\"1142\"}},\"id\":\"1141\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Topic\",\"@topic\"],[\"id\",\"@id\"],[\"Article\",\"@document\"]]},\"id\":\"1149\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"field\":\"color\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1167\",\"type\":\"Circle\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1163\"},\"glyph\":{\"id\":\"1165\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1167\"},\"nonselection_glyph\":{\"id\":\"1166\"},\"view\":{\"id\":\"1169\"}},\"id\":\"1168\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1155\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1146\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1154\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1182\"}],\"location\":\"top_left\"},\"id\":\"1181\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1137\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1135\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1173\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1139\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"hatch_color\":{\"field\":\"color\"},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1165\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1178\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1174\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1142\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1176\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1179\",\"type\":\"Selection\"},{\"attributes\":{\"tools\":[{\"id\":\"1149\"},{\"id\":\"1150\"},{\"id\":\"1151\"},{\"id\":\"1152\"},{\"id\":\"1153\"},{\"id\":\"1154\"}]},\"id\":\"1156\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1145\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1148\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"1170\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1166\",\"type\":\"Circle\"}],\"root_ids\":[\"1132\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n  const render_items = [{\"docid\":\"b4682a68-fa0e-4e7d-8772-58b06cbc8579\",\"root_ids\":[\"1132\"],\"roots\":{\"1132\":\"5a684a58-54da-4364-ac07-102665a18197\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1132"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "output_notebook()\n",
    "\n",
    "# 사용할 툴들\n",
    "tools_to_show = 'hover, box_zoom, pan, save, reset, wheel_zoom'\n",
    "p = figure(plot_width=720, plot_height=580, tools=tools_to_show)\n",
    "\n",
    "source = ColumnDataSource(data={\n",
    "    'x': W2d[:, 0],\n",
    "    'y': W2d[:, 1],\n",
    "    'id': [i for i in range(W.shape[0])],\n",
    "    'document': [article for words, article in words_list],\n",
    "    'topic': [str(i) for i in topicIndex],  # 토픽 번호\n",
    "    'color': [Category20[K][i] for i in topicIndex]\n",
    "})\n",
    "p.circle(\n",
    "    'x', 'y',\n",
    "    source=source,\n",
    "    legend='topic',\n",
    "    color='color'\n",
    ")\n",
    "\n",
    "# interaction\n",
    "p.legend.location = \"top_left\"\n",
    "hover = p.select({'type': HoverTool})\n",
    "hover.tooltips = [(\"Topic\", \"@topic\"), ('id', '@id'), (\"Article\", \"@document\")]\n",
    "hover.mode = 'mouse'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding은 단어가 가지는 고유한 벡터를 가지고 의미가 유사하면 유사도가 높도록(내적값이 커지도록) 의미가 작아지면 유사도가 작아지도록(내적값이 작아지도록) 해주는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec에는 CBOW와 Skip-Grad 두 가지 방식이 있습니다. CBOW는 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법입니다. 반대로, Skip-Gram은 중간에 있는 단어로 주변 단어들을 예측하는 방법입니다. 매커니즘 자체는 거의 비슷합니다. 우선 CBOW에 대해서 알아보겠습니다. 이해를 위해 매우 간소화된 형태의 CBOW로 설명합니다.\n",
    "\n",
    "**예문: \"The fat cat sat on the mat\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) CBOW**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 코퍼스에 위와 같은 문장이 있습니다. {\"The\", \"fat\", \"cat\", \"on\", \"the\", \"mat\"}으로부터 \"sat\"을 예측하는 것이 CBOW가 할 일입니다. 이 때 예측하는 단어 sat을 중심 단어(center word)라고 하고, 예측에 사용되는 단어들을 주변 단어(context word)라고 합니다.\n",
    "\n",
    "중심 단어를 예측하기 위해 앞, 뒤로 몇 개의 단어를 볼지 결정했다면 이 범위를 윈도우(window)라고 합니다. 예를 들어 윈도우 크기가 2이고 예측하고자 하는 중심 단어가 sat이라고 한다면 앞의 두 단어인 fat과 cat, 그리고 뒤의 두 단어인 on, the를 참고합니다. 윈도우의 크기가 n이라고 한다면, 실제 중심 단어를 예측하기 위해 참고하려고 하는 주변 단어의 개수는 2n이 됩니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG\">\n",
    "\n",
    "윈도우 크기를 정했다면, 윈도우를 계속 움직여서 주변 단어와 중심 단어 선택을 바꿔가며 학습을 위한 데이터 셋을 만들 수 있는데, 이 방법을 슬라이딩 윈도우(sliding window)라고 합니다. \n",
    "\n",
    "위 그림에서 좌측의 중심 단어와 주변 단어의 변화는 윈도우 크기가 2일 때, 슬라이딩 윈도우가 어떤 식으로 이루어지면서 데이터 셋을 만드는지 보여줍니다. 또한 Word2Vec에서 입력은 원-핫 벡터가 되어야 하는데, 우측 그림은 중심 단어와 주변 단어를 어떻게 선택했을 때에 따라서 각각 어떤 원-핫 벡터가 되는지를 보여줍니다. 밑의 그림은 결국 CBOW를 위한 전체 데이터 셋을 보여주는 것입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_1.PNG\">\n",
    "\n",
    "CBOW의 인공 신경망을 간단히 도식화하면 위와 같습니다. 입력층(Input layer)의 입력으로서 앞, 뒤로 사용자가 정한 윈도우 크기 범위 안에 있는 주변 단어들의 원-핫 벡터가 들어가게 되고, 출력층(Output layer)에서 예측하고자 하는 중간 단어의 원-핫 벡터가 필요합니다. \n",
    "\n",
    "또한 위 그림에서 알 수 있는 사실은, Word2Vec은 딥 러닝 모델(Deep Learning Model)은 아니라는 점입니다. 보통 딥 러닝이라함은, 입력층과 출력층 사이의 은닉층의 개수가 충분히 쌓인 신경망을 학습할 때를 말하는데 Word2Vec는 입력층과 출력층 사이에 하나의 은닉층만이 존재합니다. 이렇게 은닉층이 1개인 경우에는 일반적으로 심층신경망(Deep Neural Network)이 아니라 얕은신경망(Shallow Neural Network)이라고 부릅니다. 또한 Word2Vec의 은닉층은 일반적인 은닉층과 달리 활성화 함수가 존재하지 않으며 룩업 테이블이라는 연산을 담당하는 층으로 일반적인 은닉층과 구분하기 위해 투사층(projection layer)이라고 부르기도 합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_2.PNG\">\n",
    "\n",
    "CBOW의 인공신경망을 더 확대하여 알아보겠습니다. 이 그림에서 투사층의 크기가 M이라는 것과 입력층과 투사층 사이의 가중치 W는 V x M이고 투사층과 출력층 사이 가중치 W'의 크기는 M x V임을 주목해야 합니다.\n",
    "\n",
    "먼저 CBOW에서 투사층의 크기 M은 임베딩하고 난 벡터의 차원이 됩니다. 다시 말해, 위 그림에서 투사층의 크기는 M = 5이기 때문에 CBOW를 수행하고 나서 얻는 각 단어의 임베딩 벡터의 차원은 5입니다.\n",
    "\n",
    "두번째로 V는 단어 집합의 크기를 의미합니다. 즉, 위의 그림처럼 원-핫 벡터의 차원이 7이고, M은 5라면 가중치 W는 7 x 5 행렬이고, W'는 5 x 7 행렬이 될 것입니다. 이때 W와 W'는 동일한 행렬을 전치한 것이 아니라 서로 다른 행렬입니다. 인공 신경망의 훈련 전에 이 가중치 행렬 W와 W'는 대게 굉장히 작은 랜덤 값을 가지게 됩니다. CBOW는 주변 단어로 중심 단어를 더 정확히 맞추기 위해서 W와 W'를 학습해가는 구조입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_3.PNG\">\n",
    "\n",
    "입력으로 들어오는 주변 단어의 원-핫 벡터와 가중치 W 행렬의 곱이 어떻게 이루어지는지 보겠습니다. 위 그림에서 각 주변 단어의 원-핫 벡터를 $x$로 표기했습니다. 입력 데이터는 원-핫 벡터입니다. 입력 벡터와 가중치 W 행렬의 곱은 사실 W행렬의 i번째 행을 그대로 읽어오는 것(lookup)과 같기에 이 작업을 룩업 테이블(lookup table)이라고 합니다. 여기서 lookup해온 W의 각 행벡터가 사실 Word2Vec을 수행한 후의 각 단어의 M차원 크기를 갖는 임베딩 벡터들입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_4.PNG\">\n",
    "\n",
    "이렇게 각 주변 단어의 원-핫 벡터에 대해서 가중치 W가 곱해서 생겨진 결과 벡터들은 투사층에서 만나 이들의 평균인 벡터를 구합니다. CBOW는 투사층에서 벡터의 평균을 구하지만 뒤에서 볼 Skip-Gram은 입력이 중심 단어 하나이기에 투사층에서 벡터의 평균을 구하지 않습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_5.PNG\">\n",
    "\n",
    "이제 투사층에서 구해진 평균 벡터는 두번째 가중치 행렬 W'와 곱해집니다. 곱셈의 결과는 원-핫 벡터들과 동일한 차원을 가진 벡터로 나옵니다. \n",
    "\n",
    "이 벡터에서 CBOW는 소프트맥스 함수를 사용합니다. 출력된 벡터의 총 합은 1이고 이렇게 나온 벡터를 스코어 벡터(score vector)라고 합니다. 스코어 벡터는 각 인덱스번째 단어가 중심 단어일 확률을 나타냅니다. 그리고 스코어 벡터가 우리가 가진 답의 원-핫 벡터와 가까워져야 합니다. \n",
    "\n",
    "스코어 벡터를 $\\hat{y}$, 중심 단어를 $y$라고 했을 때, CBOW의 손실 함수로 cross-entropy 함수를 사용합니다.\n",
    "\n",
    "$$H(\\hat{y}, y) = -\\sum_{j=1}^{\\lvert V \\rvert} y_j log(\\hat{y}_j)$$\n",
    "\n",
    "cross-entropy 함수에 실제 중심 단어인 원-핫 벡터와 스코어 벡터를 입력값으로 넣고, 이를 식으로 표현하면 위와 같습니다. \n",
    "\n",
    "$$H(\\hat{y}, y) = -y_i log(\\hat{y_i})$$\n",
    "\n",
    "그런데 y가 원-핫 벡터임을 고려하면, 식을 위와 같이 간소화할 수 있습니다. c를 중심 단어에서 1을 가진 차원의 값의 인덱스라고 한다면 $\\hat{y}_c = 1$는 $\\hat{y}$가 $y$를 정확하게 예측한 경우가 됩니다. 이를 식에 대입하면 $-1log(1) = 0$이기에 결과적으로 정확히 예측한 경우의 cross-entropy 값은 0이 됩니다. 따라서 위 식을 최소화하는 방향으로 학습해야 하며 loss function으로 사용해도 됩니다.\n",
    "\n",
    "이제 역전파를 수행하면 W와 W'가 학습되는데, 학습이 다 되었다면 M차원의 크기를 갖는 W의 행이나 W'의 열로부터 어떤 것을 임베딩 벡터로 사용할지 결정하면 됩니다. 떄로는 W와 W'의 평균치를 가지고 임베딩 벡터를 선택하기도 합니다.\n",
    "\n",
    "Word2Vec의 알고리즘을 다시 요약해보면 다음과 같습니다.\n",
    "\n",
    "![4-3-1](_image/4-3-1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Skip-Gram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip-gram은 CBOW를 이해했다면, 매커니즘 자체는 동일하기 때문에 쉽게 이해할 수 있습니다. 앞서 CBOW에선 주변 단어를 통해 중심 단어를 예측했다면, skip-gram은 중심 단어에서 주변 단어를 예측하겠습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22660/word2vec_renew_6.PNG\">\n",
    "\n",
    "앞서 언급한 동일한 예문에 대해서 인공 신경망을 도식화해보면 위와 같습니다. 이제 중심 단어에 대해서 주변 단어를 예측하기 때문에, 투사층에서 벡터들의 평균을 구하는 과정은 없습니다. \n",
    "\n",
    "여러 논문에서 성능 비교를 진행했을 때, 전반적으로 skip-gram이 CBOW보다 성능이 좋다고 알려져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Negative Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대체적으로 Word2Vec를 사용한다고 하면 SGNS(Skip-Gram with Negative Sampling)을 사용합니다. 이는 skip-gram 방법에, 네거티브 샘플링이란 방법까지 추가로 사용하는 것입니다. 그렇기에 skip-gram을 전제로 네거티브 샘플링에 대해서 알아보겠습니다.\n",
    "\n",
    "위에서 배운 Word2Vec 모델은 속도가 문제입니다. 마지막 단계를 봅시다. 출력층에 있는 소프트맥스 함수는 단어 집합 크기의 벡터 내의 모든 값을 0과 1 사이의 값이면서 모두 더하면 1이 되도록 바꾸는 작업을 수행합니다. 그리고 이에 대한 오차를 구하고 모든 단어에 대한 임베딩을 조정합니다. 그 단어가 중심 단어나 주변 단어와 전혀 상관없는 단어라도 마찬가지입니다. 그런데 만약 단어 집합의 크기가 수백만에 달한다면 이 작업은 굉장히 무거워집니다.\n",
    "\n",
    "여기서 핵심은 모든 단어 집합에 대해서 소프트맥스 함수를 수행하고, 역전파를 수행하므로 주변 단어와 상관 없는 모든 단어까지 워드 임베딩 조정 작업을 수행한다는 것입니다. 만약 '강아지'와 '고양이'와 같은 단어에 집중한다면 '돈가스'나 '컴퓨터'와 같은 연관 관계가 없는 수많은 단어의 임베딩을 조정할 필요가 없습니다. \n",
    "\n",
    "그렇다면 전체 단어 집합이 아니라 일부 단어 집합에 대해서만 고려할 수는 없을까요? '강아지', '고양이' 같은 주변 단어들로 일부 단어 집합을 만듭니다. 그리고 여기에 '돈가스', '컴퓨터', '회의실' 같은 무작위로 선택된 주변 단어가 아닌 상관없는 단어들을 일부만 갖고옵니다. 이렇게 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어놓고 마지막 단께를 이진 분류 문제로 바꿔버립니다. 즉, Word2Vec은 주변 단어들을 긍정(positive)으로 두고 무작위로 샘플링 된 단어들을 부정(negative)으로 둔 다음에 이진 분류 문제를 수행합니다. \n",
    "\n",
    "이는 기존의 다중 클래스 분류 문제를 이진 분류 문제로 바꾸면서도 연산량에 있어서 훨씬 효율적입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Word2Vec Property**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4-3-2](_image/4-3-2.PNG)\n",
    "링크: https://ronxin.github.io/wevi/\n",
    "\n",
    "위 그림은 Word2Vec이 동작하는 것을 보여주는 페이지에 결과입니다. apple과 juice는 관계가 있기에 apple input vector와 juice output vector의 값이 모두 양수가 되는 것을 확인할 수 있습니다. 반대로 rice input vector와 juice output vector는 음수가 많이 나오는 것을 확인할 수 있습니다. \n",
    "\n",
    "또한 이렇게 구해진 embedding vector들은 유사한 관계를 가진 벡터쌍끼리 비슷한 관계를 가집니다. 예를 들어 (대한민국, 서울)과 (일본, 도쿄)는 (나라, 수도)의 관계를 가지고 있습니다. 그렇기에 대한민국 - 서울 = 일본 - 도쿄의 식이 성립됩니다. 그 외에도 여러 유사 관계를 밑의 그림에서 확인할 수 있습니다.\n",
    "\n",
    "![4-3-3](_image/4-3-3.PNG)\n",
    "\n",
    "이외에도 거의 대부분의 NLP분야에서 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 자료: https://shuuki4.wordpress.com/2016/01/27/word2vec-%EA%B4%80%EB%A0%A8-%EC%9D%B4%EB%A1%A0-%EC%A0%95%EB%A6%AC/  \n",
    "참고 자료: https://simonezz.tistory.com/35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 GloVe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA(Latent Semantic Analysis)는 각 단어의 빈도수를 카운트 한 행렬이라는 전체적인 통계 정보를 입력 받아 차원을 축소(Truncated SVD)하여 잠재된 의미를 끌어내는 방법론입니다. 반면, Word2Vec는 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여나가며 학습하는 예측 기반의 방법론입니다. \n",
    "\n",
    "LSA는 카운트 기반이기에 전체적인 통계 정보를 고려하기는 하지만, '왕:남자 = 여왕:?'과 같은 단어 의미의 유추 작업(Analogy task)에는 성능이 떨어집니다. Word2Vec는 예측 기반으로 단어 간 유추 작업에는 LSA보다 뛰어나지만, 임베딩 벡터가 윈도우 크기 내에서만 주변 단어를 고려하기 때문에 코퍼스의 전체적인 통계 정보를 반영하지 못합니다. GloVe는 이러한 기존 방법론들의 각각의 한계를 지적하며 LSA의 매커니즘이었던 카운트 기반의 방법과 Word2Vec의 매커니즘이었던 예측 기반의 방법론을 두 가지 모두 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 GloVe에 대해 간단하게 살펴보겠습니다. GloVe는 위에서 이야기했듯 Word2Vec에 카운터 기반의 방법을 합친 것입니다. 그렇기에 단어들의 쌍들이 나오는 개수를 먼저 count하여 행렬로 만듭니다. 그리고 $W_1 \\cdot W_2$가 구한 행렬과 같아지도록 학습시키는 것입니다. 이때 the 등의 관사는 빈도수가 너무 높기에 이를 억제하기 위해 log항을 추가합니다. 또한 빈도수에 따라 가중치를 주지만 이 역시 너무 커지지 않도록 f라는 함수를 사용합니다. 임베딩 벡터로는 Word2Vec과 마찬가지로 $W_1$을 사용하거나 두 개의 평균을 임베딩 벡터로 사용합니다. \n",
    "\n",
    "밑의 그림은 loss function(bias = 0)과 f함수를 보여줍니다.\n",
    "\n",
    "![4-3-4](_image/4-3-4.PNG)\n",
    "\n",
    "이제 구체적으로 GloVe의 동작을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Windoe based Co-occurrence Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 단어 쌍의 빈도수의 정보를 가지는 윈도우 기반 동시 등장 행렬에 대해 보겠습니다.\n",
    "\n",
    "단어의 동시 등장 행렬은 행과 열을 전체 단어 집합의 단어들을 구성하고, i 단어의 윈도우 크기(Window Size) 내에서 k 단어가 등장한 횟수를 i행 k열에 기재한 행렬을 말합니다. 예제를 보겠습니다.\n",
    "\n",
    "Ex)  \n",
    "I like deep learning  \n",
    "I like NLP  \n",
    "I enjoy flying  \n",
    "\n",
    "윈도우 크기가 N일 때는 좌, 우에 존재하는 N개의 단어만 참고하게 됩니다. 윈도우 크기가 1일 때, 위 텍스트를 가지고 동시 등장 행렬은 다음과 같습니다.\n",
    "\n",
    "|카운트|I|like|enjoy|deep|learning|NLP|flying|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|I|0|2|1|0|0|0|0|\n",
    "|like|2|0|0|1|0|1|0|\n",
    "|enjoy|1|0|0|0|0|0|1|\n",
    "|deep|0|1|0|0|1|0|0|\n",
    "|learning|0|0|0|1|0|0|0|\n",
    "|NLP|0|1|0|0|0|0|0|\n",
    "|flying|0|0|1|0|0|0|0|\n",
    "\n",
    "위 행렬은 행렬을 전치(Transpose)해도 동일한 행렬이 된다는 특징이 있습니다. 그 이유는 i 단어의 윈도우 크기 내에서 k 단어가 등장한 빈도는 반대로 k 단어의 윈도우 크기 내에서 i 단어가 등장한 빈도와 동일하기 때문입니다. \n",
    "\n",
    "참고 자료: http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture02-wordvecs2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Co-occurrence Probability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 동시 등장 확률에 대해서 알아보겠습니다. 아래의 표는 어떤 동시 등장 행렬을 가지고 정리한 동시 등장 확률(Co-occurrence Probability)을 보여줍니다. 여기서 이야기하는 동시 등장 확률 $P(k|i)$는 동시 등장 행렬로부터 특정 단어 i의 전체 등장 횟수를 카운트하고, 특정 단어 i가 등장했을 때 어떤 단어 k가 등장한 횟수를 카운트하여 계산한 조건부 확률입니다. \n",
    "\n",
    "$P(k|i)$에서 i를 중심 단어(Center word), k를 주변 단어(Context word)라고 했을 때, 위에서 배운 동시 등장 행렬에서 중심 단어 i의 행의 모든 값을 더한 값을 분모로 하고 i행 k열의 값을 분자로 한 값이라고 볼 수 있겠습니다. 다음은 GloVe의 제안 논문에서 가져온 동시 등장 확률을 표로 정리한 하나의 예입니다.\n",
    "\n",
    "|동시 등장 확률과 크기 관계 비(ratio)|k=solid|k=gas|k=water|k=fasion|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|$P(k \\vert ice)$|0.00019|0.000066|0.003|0.000017|\n",
    "|$P(k \\vert steam)$|0.000022|0.00078|0.0022|0.000018|\n",
    "|$\\frac{P(k \\vert ice)}{P(k \\vert steam)}$|8.9|0.085|1.36|0.96|\n",
    "\n",
    "위의 표를 통해 알 수 있는 사실은 solid가 등장했을 때, ice가 등장할 확률은 0.00019은 solid가 등장했을 때 steam이 등장할 확률인 0.000022보다 약 8.9배 크다는 사실입니다. 그도 그럴 것이 solid는 '단단한'이라는 의미를 가졌으니까 '증기'라는 의미를 가지는 steam보다는 당연히 '얼음'이라는 의미를 가지는 ice라는 단어와 더 자주 등장할 겁니다.\n",
    "\n",
    "수식적으로 다시 정리하면 k가 solid일 때, $\\frac{P(solid \\vert ice)}{P(solid \\vert steam)}$를 계산한 값은 8.9가 나옵니다. 이는 1보다 매우 큰 값입니다. 왜냐면 $P(solid \\vert ice)$의 값은 크고, $P(solid \\vert steam)$의 값은 작기 때문입니다.\n",
    "\n",
    "그런데 k를 solid가 아니라 gas로 바꾸면 이야기는 완전히 달라집니다. gas는 ice보다는 steam과 더 자주 등장하므로, $\\frac{P(gas \\vert ice)}{P(gas \\vert steam)}$를 계산한 값은 1보다 훨씬 작은 값인 0.085가 나옵니다. 반면, k가 water인 경우에는 solid와 steam 두 단어 모두와 동시 등장하는 경우가 많으므로 1에 가까운 값이 나오고, k가 fasion인 경우에는 solid와 steam 두 단어 모두와 동시 등장하는 경우가 적으므로 1에 가까운 값이 나옵니다. 보기 쉽도록 조금 단순화해서 표현한 표는 다음과 같습니다.\n",
    "\n",
    "|동시 등장 확률과 크기 관계 비(ratio)|k=solid|k=gas|k=water|k=fasion|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|$P(k \\vert ice)$|큰 값|작은 값|큰 값|작은 값|\n",
    "|$P(k \\vert steam)$|작은 값|큰 값|큰 값|작은 값|\n",
    "|$\\frac{P(k \\vert ice)}{P(k \\vert steam)}$|큰 값|작은 값|1에 가까움|1에 가까움|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Loss Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 손실 함수를 설명하기 전에 각 용어를 정리하겠습니다.\n",
    "\n",
    "- $X$: 동시 등장 행렬(Co-occurrence Matrix)\n",
    "- $X_{ij}$: 중심 단어 i가 등장했을 때, 윈도우 내 주변 단어 j가 등장하는 횟수\n",
    "- $X_i$: $\\sum_j X_{ij}$: 동시 등장 행렬에서 i행의 값을 모두 더한 값\n",
    "- $P_{ik}$: $P(k \\vert i) = \\frac{X_{ik}}{X_i}$: 중심 단어 i가 등장했을 때, 윈도우 내 주변 단어 k가 등장할 확률  \n",
    "    Ex) $P(solid \\vert ice)$ = 단어 ice가 등장했을 때, 단어 solid가 등장할 확률\n",
    "- $\\frac{P_{ik}}{P_{jk}}$: $P_{ik}$를 $P_{jk}$로 나눠준 값  \n",
    "    Ex) $\\frac{P(solid \\vert ice)}{P(solid \\vert steam)}$ = 8.9\n",
    "- $w_i$: 중심 단어 i의 임베딩 벡터\n",
    "- $\\bar{w_k}$: 주변 단어 k의 임베딩 벡터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe의 아이디어를 한 줄로 요약하면 **'임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 만드는 것'** 입니다. 즉, 이를 만족하도록 임베딩 벡터를 만드는 것이 목표입니다. 이를 식으로 표현하면 다음과 같습니다.\n",
    "\n",
    "$dot product(w_i, \\bar{w_k}) \\approx P(k \\vert i) = P_{ik}$\n",
    "\n",
    "뒤에서 보겠지만, 더 정확히는 GloVe는 아래와 같은 관계를 가지도록 임베딩 벡터를 설계합니다.\n",
    "\n",
    "$dot product(w_i, \\bar{w_k}) \\approx log P(k \\vert i) = log P_{ik}$\n",
    "\n",
    "임베딩 벡터들을 만들기 위한 손실 함수를 처음부터 차근차근 설계해보겠습니다. 가장 중요한 것은 단어 간의 관계를 잘 표현하는 함수여야 한다는 것입니다. 이를 위해 앞서 배운 개념인 $P_{ik}/P_{jk}$를 식에 사용합니다. GloVe의 연구진들은 벡터 $w_i, w_j, \\bar{w_k}$를 가지고 어떤 함수 $F$를 수행하면 $P_{ik}/P_{jk}$가 나온다는 초기 식으로부터 전개를 시작합니다.\n",
    "\n",
    "$$F(w_i, w_j, \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "아직 이 함수가 $F$가 어떤 식을 가지고 있는지는 정해진 것이 없습니다. 위의 목적에 맞게 근사할 수 있는 함수식은 무수히 많겠으나 최적의 식에 다가가기 위해서 단계별로 디테일을 추가하겠습니다. 함수 $F$는 두 단어 사이의 동시 등장 확률의 크기 관계 비(ratio) 정보를 벡터 공간에 인코딩하는 것이 목적입니다. 이를 위해 GloVe 연구진들은 $w_i$와 $w_j$라는 두 벡터의 차이를 함수 $F$의 입력으로 사용하는 것을 제안합니다.\n",
    "\n",
    "$$F(w_i - w_j, \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "그런데 우변은 스칼라값이고 좌변은 벡터값입니다. 이를 성립하기 위해서 함수 $F$의 두 입력에 내적(dot product)을 수행합니다.\n",
    "\n",
    "$$F((w_i - w_j)^T \\bar{w_k}) = \\frac{P_{ik}}{P_{jk}}$$\n",
    "\n",
    "정리하면, 선형 공간(Linear space)에서 단어의 의미 관계를 표현하기 위해 뺄셈과 내적을 택했습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 함수 $F$가 만족해야 할 필수 조건이 있습니다. 중심 단어 $w$와 주변 단어 $\\bar{w}$라는 선택 기준은 실제로는 무작위 선택이므로 이 둘의 관계는 자유롭게 교환될 수 있도록 해야합니다. 이것이 성립되게 하기 위해서 GloVe 연구진은 함수 $F$가 실수의 덧셈과 양수의 곱셈에 대해서 **준동형(Homomorphism)** 을 만족하도록 합니다. 이를 쉽게 정리하면 $a$와 $b$에 대해서 함수 $F$가 $F(a + b)$가 $F(a)F(b)$와 같도록 만족시켜야 한다는 의미입니다.\n",
    "\n",
    "식으로 나타내면 다음과 같습니다.\n",
    "\n",
    "$$F(a + b) = F(a)F(b), \\forall a, b \\in \\mathbb{R}$$\n",
    "\n",
    "이제 이 준동형식을 현재 전개하던 GloVe 식에 적용할 수 있도록 조금씩 바꿔보겠습니다. 전개하던 GloVe 식에 따르면, 함수 $F$는 결과값으로 스칼라 값($\\frac{P_{ik}}{P_{jk}}$)이 나와야 합니다. 준동형식에서 $a$와 $b$가 각각 벡터값이라면 함수 $F$의 결과값으로는 스칼라 값이 나올 수 없지만, $a$와 $b$가 각각 사실 두 벡터의 내적값이라고 하면 결과값으로 스칼라 값이 나올 수 있습니다. 그러므로 위의 준동형식을 아래와 같이 바꿔보겠습니다. 여기서 $v_1, v_2, v_3, v_4$는 각각 벡터값입니다. 아래의 $V$는 벡터를 의미합니다.\n",
    "\n",
    "$$F(v_1^T v_2 + v_3^T v_4) = F(v_1^T v_2)F(v_3^T v_4), \\forall v_1, v_2, v_3, v_4 \\in V$$\n",
    "\n",
    "그런데 앞서 작성한 GloVe 식에서는 $w_i$와 $w_j$라는 두 벡터의 차이를 함수 $F$의 입력으로 받았습니다. GloVe식에 바로 적용을 위해 준동형식을 뺄셈에 대한 준동형식으로 변경합니다. 그러면 곱셈도 나눗셈으로 바뀌게 됩니다.\n",
    "\n",
    "$$F(v_1^T v_2 - v_3^T v_4) = \\frac{F(v_1^T v_2)}{F(v_3^T v_4)}, \\forall v_1, v_2, v_3, v_4 \\in V$$\n",
    "\n",
    "이제 이 준동형식을 GloVe 식에 적용하겠습니다. 우선, 함수 $F$의 우변은 다음과 같이 바뀌어야 합니다.\n",
    "\n",
    "$$F((w_i - w_j)^T \\bar{w_k}) = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "그런데 이전의 식에 따르면 우변은 본래 $\\frac{P_{ik}}{P_{jk}}$였으므로, 결과적으로 다음과 같습니다.\n",
    "\n",
    "$$\\frac{P_{ik}}{P_{jk}} = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "$$F(w_i^T \\bar{w_k}) = P_{ik} = \\frac{X_{ik}}{X_i}$$\n",
    "\n",
    "좌변을 풀어쓰면 다음과 같습니다.\n",
    "\n",
    "$$F(w_i^T \\bar{w_k} - w_j^T \\bar{w_k}) = \\frac{F(w_i^T \\bar{w_k})}{F(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "이는 뺄셈에 대한 준동형식의 형태와 정확히 일치합니다. 이제 이를 만족하는 함수 $F$를 찾아야 합니다. 그리고 이를 정확하게 만족시키는 함수가 있는데 바로 지수 함수입니다. $F$를 지수 함수 **exp** 라고 해봅시다.\n",
    "\n",
    "$$exp(w_i^T \\bar{w_k} - w_j^T \\bar{w_k}) = \\frac{exp(w_i^T \\bar{w_k})}{exp(w_j^T \\bar{w_k})}$$\n",
    "\n",
    "$$exo(w_i^T \\bar{w_k}) = P_{ik} = \\frac{X_{ik}}{X_i}$$\n",
    "\n",
    "위의 두 번째 식으로부터 다음과 같은 식을 얻을 수 있습니다.\n",
    "\n",
    "$$w_i^T \\bar{w_k} = log P_{ik} = log(\\frac{X_{ik}}{X_i}) = log X_{ik} - log X_i$$\n",
    "\n",
    "그런데 여기서 상기해야할 것은 앞서 언급했듯이, 사실 $w_i$와 $\\bar{w_k}$는 두 값의 위치를 서로 바꾸어도 식이 성립해야 합니다. $X_{ik}$의 정의를 생각해보면 $X_{ki}$와도 같습니다. 그런데 이게 성립되려면 위의 식에서 $log X_i$ 항이 걸림돌입니다. 이 부분만 없다면 이를 성립시킬 수 있습니다. 그래서 GloVe 연구팀은 이 $log X_i$항을 $w_i$에 대한 편향 $b_i$라는 상수항으로 대체하기로 합니다. 같은 이유로 $\\bar{w_k}$에 대한 편향 $\\bar{b_k}$를 추가합니다.\n",
    "\n",
    "$$w_i^T \\bar{w_k} + b_i + \\bar{b_k} = log X_{ik}$$\n",
    "\n",
    "이 식이 손실 함수의 핵심이 되는 식입니다. 우변의 값과 차이를 최소화하는 방향으로 좌변의 4개의 항이 학습을 통해 바뀌게 됩니다. 즉, 손실 함수는 다음과 같이 일반화될 수 있습니다.\n",
    "\n",
    "$$Loss \\; function = \\sum_{m, n = 1}^V (w_m^T \\bar{w_n} + b_m + \\bar{b_n} - log X_{mn})^2$$\n",
    "\n",
    "여기서 $V$는 단어 집합의 크기를 의미합니다. 그런데 아직 최적의 손실 함수라기에는 부족합니다. GloVe 연구진은 $log X_{ik}$에서 $X_{ik}$값이 0이 될 수 있음을 지적합니다. 대안 중 하나는 $log X_{ik}$항을 $log (1 + X_{ik})$로 변경하는 것입니다. 하지만 이렇게 해도 여전히 해결되지 않는 문제가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 동시 등장 행렬 $X$는 마치 DTM처럼 희소 행렬일 가능성이 다분하다는 점입니다. 동시 등장 행렬 $X$에는 많은 값이 0이거나, 동시 등장 빈도가 적어서 많은 값이 작은 수치를 가지는 경우가 많습니다. 앞서 빈도수를 가지고 가중치를 주는 고민을 하는 TF-ID나 LSA와 같은 몇 가지 방법들을 본 적이 있습니다. GloVe의 연구진은 동시 등장 행렬에서 동시 등장 빈도의 값 $X_{ik}$이 굉장히 낮은 경우에는 정보에 거의 도움이 되지 않는다고 판단합니다. 그래서 이에 대한 가중치를 주는 고민을 하게 되는데 GloVe 연구팀이 선택한 것은 바로 $X_{ik}$의 값에 영향을 받는 가중치 함수 $f(X_{ik})$를 손실 함수에 도입하는 것입니다. \n",
    "\n",
    "GloVe에 도입되는 $f(X_{ik})$의 그래프를 그려보겠습니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22885/%EA%B0%80%EC%A4%91%EC%B9%98.PNG\">\n",
    "\n",
    "$X_{ik}$의 값이 작으면 상대적으로 함수의 값은 작도록 하고, 값이 크면 함수의 값은 상대적으로 크도록 합니다. 하지만 $X_{ik}$가 지나치게 높다고해서 지나친 가중치를 주지 않기 위해 함수의 최대값은 정해져 있습니다. (최대값은 1) 예를 들어 'It is'와 같은 불용어의 동시 등장 빈도수가 높다고해서 지나친 가중을 받아서는 안 됩니다. 이 함수의 값을 손실 함수에 곱해주면 가중치의 역할을 할 수 있습니다.\n",
    "\n",
    "이 함수 $f(x)$의 식은 다음과 같이 정의됩니다. \n",
    "\n",
    "$$f(x) = min(1, (\\frac{x}{x_{max}}^{\\frac{3}{4}}))$$\n",
    "\n",
    "최종적으로 다음과 같은 일반화 된 손실 함수를 얻어낼 수 있습니다.\n",
    "\n",
    "$$Loss \\; function = \\sum_{m, n = 1}^V f(X_{mn})(w_m^T \\bar{w_n} + b_m + \\bar{b_n} - log X_{mn})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Pre-trained dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GloVe](https://nlp.stanford.edu/projects/glove/)에선 이미 학습된 임베딩 벡터를 제공합니다. 자료마다 뒤에 설명이 적혀있으니 참고하여 필요한 데이터를 사용하면 됩니다. 예를 들어 Wikipedia 2014 + Gigaword5에 대한 설명은 다음과 같습니다. \n",
    "\n",
    "- 6B tokens: 60억개의 토큰(중복 단어 허용)\n",
    "- 400k vocab: 40만개의 고유 단어(40만개의 one-hot vector)\n",
    "- uncased: 대소문자 구분 안 함\n",
    "- 50d, 100d, 200d, & 300d vectors: 50, 100, 200, 300을 target dimension으로 학습된 임베딩 벡터가 있음을 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Doc2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec(Paragraph2Vec)는 기존 Word2Vec에 paragraph vector를 더해 확장한 문서 임베딩 모델입니다. 타켓 단어와 이전 단어 k개가 주어졌을 때, 이전 단어들과 해당 문서의 아이디로 타켓 단어를 예측합니다. 그리고 이 과정에서 문맥이 비슷한 문서 벡터와 단어 벡터가 유사하게 임베딩됩니다.\n",
    "\n",
    "Doc2Vec은 다량의 코퍼스를 문서 임베딩 할 때 훌룡한 성능을 보여줍니다. Word2Vec이 CBOW와 Skip-Gram우로 나뉘었듯 Doc2Vec도 PV-DM(Distributed Memory version of Paragraph Vector)과 PV-DBOW(Distributed Bag of Words version of Paragraph Vector)로 나눠집니다. 아래와 같은 예시가 있을 때 동작하는 것을 살펴보겠습니다.\n",
    "\n",
    "- sentence: the cat sat on the mat\n",
    "- window size: k = 3\n",
    "- [$\\text{paragraph}_1$, the, cat, sat] - on\n",
    "- [$\\text{paragraph}_1$, cat, sat, on] - the\n",
    "- [$\\text{paragraph}_1$, sat, on, the] - mat\n",
    "\n",
    "Doc2Vec은 paragraph에서 단어를 예측하며 로그 확률 평균을 최대화하는 과정에서 학습됩니다. $\\text{paragraph}_{id}$가 학습의 입력 데이터로 들어가기에 문맥이나 단어가 paragraph 벡터에 녹아든다고 볼 수 있습니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOvRfL%2FbtqBzPhTjCD%2FNeKAov500OG05vrsvraZV0%2Fimg.png\" width = \"600px\" height = \"300px\"> \n",
    "\n",
    "각 문서 paragraph는 별도의 (문서의 수 x d 차원) 크기의 행렬에 담깁니다. 학습이 완료된 후, 이 행렬을 이용하여 paragraph의 임베딩된 벡터를 사용합니다. 즉, paragraph의 정보돠 이전 단어들을 통해 다음 단어를 유추하는 것입니다. 이를 PV-DM이라고 합니다. \n",
    "\n",
    "반대로 하나의 $\\text{paragraph}_{id}$로 해당 문서 내 단어들을 유추하는 것을 PV-DBOW라고 합니다. \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbx8qpy%2FbtqBzjXPOfy%2FNPzuVPVD1RGp4TxKtIXQoK%2Fimg.png\">\n",
    "\n",
    "이제 예시를 통해 살펴보겠습니다. \n",
    "\n",
    "![4-3-5](_image/4-3-5.PNG)\n",
    "\n",
    "위 그림을 보면 input에 (study, female, 10s)가 들어가 있는 것을 볼 수 있습니다. 이는 단어인 'study'외에도 paragraph와 관련된 정보들이 추가로 들어가 있기 때문입니다. input을 통해 10대 여자가 썼다는 정보를 얻을 수 있습니다. \n",
    "\n",
    "![4-3-6](_image/4-3-6.PNG)\n",
    "\n",
    "입력이 여러개이기에 연산 과정에서 데이터들이 각 가중치에 곱해지고 합해집니다. 이 과정을 통해 단어뿐만 아니라 추가적으로 들어오는 paragraph의 정보들도 함께 학습합니다. 위 상황은 (study, female, 10s)라는 input을 통해 (math)라는 output을 얻은 것입니다. \n",
    "\n",
    "반대도 가능합니다. \n",
    "\n",
    "![4-3-7](_image/4-3-7.PNG)\n",
    "\n",
    "위 그림의 경우 단어만 주어지고 이를 통해 다음 단어뿐만 아니라 성별과 나이까지 유추합니다. 그렇기에 loss도 각각 따로 구하고 다른 가중치를 곱하여 합하는 것을 볼 수 있습니다. 소프트맥스를 할 때도 마찬가지로 (i, study, math), (male, female), (10s, 20s, 30s, 40s) 세 분류로 나누어 각각 소프트맥스해줍니다. \n",
    "\n",
    "![4-3-8](_image/4-3-8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.4 Other Applications of Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec을 다른 방향으로 사용할 수도 있습니다. 예를 들어 밑의 그림을 보겠습니다. \n",
    "\n",
    "![4-3-9](_image/4-3-9.PNG)\n",
    "\n",
    "(John, Jane, Michael)이란 사람이 input으로 주어지고 그들이 구매하거나 관심있는 (Galaxy, iPhone, Macbook, iPad)가 output으로 주어집니다. 이를 통해 그 사람이 관심있는 상품들을 묶어 학습시킬 수도 있습니다. 즉 $W_1$은 사용자에 대한 임베딩 벡터, $W_2$는 사용자가 구매한 상품에 대한 임베딩 벡터가 되는 것입니다.\n",
    "\n",
    "또한 임베딩 벡터를 통하여 비슷한 제품군을 묶고 관련 상품으로 추천할 수도 있습니다.\n",
    "\n",
    "![4-3-10](_image/4-3-10.PNG)\n",
    "\n",
    "위 그림을 보면 비슷한 옷끼리 가까운 거리에 위치하는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Word2Vec 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab, Twitter, Okt, Kkma\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 데이터를 확인하고 Word2Vec 형식에 맞게 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    \"정말 맛있습니다. 추천합니다.\",\n",
    "    \"기대했던 것보단 별로였네요.\",\n",
    "    \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n",
    "    \"완전 최고입니다! 재방문 의사 있습니다.\",\n",
    "    \"음식도 서비스도 다 만족스러웠습니다.\",\n",
    "    \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n",
    "    \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n",
    "    \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n",
    "    \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n",
    "    \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"       \n",
    "]\n",
    "\n",
    "test_words = [\"음식\", \"맛\", \"서비스\", \"위생\", \"가격\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization과 vocab을 만드는 과정은 지난 챕터 실습들과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenized(data):\n",
    "    tokenized = []\n",
    "    for sent in tqdm(data):\n",
    "        tokens = tokenizer.morphs(sent, stem=True)\n",
    "        tokenized.append(tokens)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = make_tokenized(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "\n",
    "for tokens in tqdm(train_tokenized):\n",
    "    for token in tokens:\n",
    "        word_count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 14), ('도', 7), ('이다', 4), ('좋다', 4), ('별로', 3), ('다', 3), ('이', 3), ('너무', 3), ('음식', 3), ('서비스', 3), ('하다', 2), ('방문', 2), ('위생', 2), ('좀', 2), ('더', 2), ('에', 2), ('조금', 2), ('정말', 1), ('맛있다', 1), ('추천', 1), ('기대하다', 1), ('것', 1), ('보단', 1), ('가격', 1), ('비싸다', 1), ('다시', 1), ('가다', 1), ('싶다', 1), ('생각', 1), ('안', 1), ('드네', 1), ('요', 1), ('완전', 1), ('최고', 1), ('!', 1), ('재', 1), ('의사', 1), ('있다', 1), ('만족스럽다', 1), ('상태', 1), ('가', 1), ('개선', 1), ('되다', 1), ('기르다', 1), ('바라다', 1), ('맛', 1), ('직원', 1), ('분들', 1), ('친절하다', 1), ('기념일', 1), ('분위기', 1), ('전반', 1), ('적', 1), ('으로', 1), ('짜다', 1), ('저', 1), ('는', 1), ('신경', 1), ('써다', 1), ('불쾌하다', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(list(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "w2i = {}\n",
    "for pair in tqdm(word_count):\n",
    "    if pair[0] not in w2i:\n",
    "        w2i[pair[0]] = len(w2i)\n",
    "\n",
    "i2w = {v:k for k, v in w2i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['정말', '맛있다', '.', '추천', '하다', '.'], ['기대하다', '것', '보단', '별로', '이다', '.'], ['다', '좋다', '가격', '이', '너무', '비싸다', '다시', '가다', '싶다', '생각', '이', '안', '드네', '요', '.'], ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.'], ['음식', '도', '서비스', '도', '다', '만족스럽다', '.'], ['위생', '상태', '가', '좀', '별로', '이다', '.', '좀', '더', '개선', '되다', '기르다', '바라다', '.'], ['맛', '도', '좋다', '직원', '분들', '서비스', '도', '너무', '친절하다', '.'], ['기념일', '에', '방문', '하다', '음식', '도', '분위기', '도', '서비스', '도', '다', '좋다', '.'], ['전반', '적', '으로', '음식', '이', '너무', '짜다', '.', '저', '는', '별로', '이다', '.'], ['위생', '에', '조금', '더', '신경', '써다', '좋다', '.', '조금', '불쾌하다', '.']]\n",
      "{'.': 0, '도': 1, '이다': 2, '좋다': 3, '별로': 4, '다': 5, '이': 6, '너무': 7, '음식': 8, '서비스': 9, '하다': 10, '방문': 11, '위생': 12, '좀': 13, '더': 14, '에': 15, '조금': 16, '정말': 17, '맛있다': 18, '추천': 19, '기대하다': 20, '것': 21, '보단': 22, '가격': 23, '비싸다': 24, '다시': 25, '가다': 26, '싶다': 27, '생각': 28, '안': 29, '드네': 30, '요': 31, '완전': 32, '최고': 33, '!': 34, '재': 35, '의사': 36, '있다': 37, '만족스럽다': 38, '상태': 39, '가': 40, '개선': 41, '되다': 42, '기르다': 43, '바라다': 44, '맛': 45, '직원': 46, '분들': 47, '친절하다': 48, '기념일': 49, '분위기': 50, '전반': 51, '적': 52, '으로': 53, '짜다': 54, '저': 55, '는': 56, '신경': 57, '써다': 58, '불쾌하다': 59}\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenized)\n",
    "print(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Dataset 클래스 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Word2Vec을 학습시키는 대표적인 방법인 Skip-Gram과 CBOW로 구현하겠습니다. 간단하게 요약하자면 다음과 같은 특징을 가지고 있었습니다.\n",
    "\n",
    "- CBOW는 주변단어를 이용해 주어진 단어를 예측하는 방법입니다.\n",
    "- Skip-Gram은 중심 단어를 이용하여 주변 단어를 예측하는 방법입니다. \n",
    "- 즉, 두 방법은 input과 output을 어떻게 설정하는지에 대한 차이가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 모델에 들어가기 위한 input을 만들기 위해 Dataset 클래스를 먼저 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = [] # input word\n",
    "        self.y = [] # output word\n",
    "        \n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i - window_size >= 0 and i + window_size < len(token_ids):\n",
    "                    self.x.append(token_ids[i - window_size:i] + token_ids[i + 1: i + window_size + 1])\n",
    "                    self.y.append(id)\n",
    "        self.x = torch.LongTensor(self.x) # (전체 데이터 개수, 2* window_size)\n",
    "        self.y = torch.LongTensor(self.y) # (전체 데이터 개수)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, train_tokenized, window_size=2):\n",
    "        self.x = [] # input word\n",
    "        self.y = [] # output word\n",
    "        \n",
    "        for tokens in tqdm(train_tokenized):\n",
    "            token_ids = [w2i[token] for token in tokens]\n",
    "            for i, id in enumerate(token_ids):\n",
    "                if i - window_size >= 0 and i + window_size < len(token_ids):\n",
    "                    self.y += (token_ids[i - window_size:i] + token_ids[i + 1: i + window_size + 1])\n",
    "                    self.x += [id] * 2 * window_size # id로 window_size 내 주변 단어를 모두 유추해야함\n",
    "        \n",
    "        self.x = torch.LongTensor(self.x) # (전체 데이터 개수)\n",
    "        self.y = torch.LongTensor(self.y) # (전체 데이터 개수)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델에 맞는 Dataset 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 9988.82it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(0), tensor(17)), (tensor(0), tensor(18)), (tensor(0), tensor(19)), (tensor(0), tensor(10)), (tensor(19), tensor(18)), (tensor(19), tensor(0)), (tensor(19), tensor(10)), (tensor(19), tensor(0)), (tensor(22), tensor(20)), (tensor(22), tensor(21)), (tensor(22), tensor(4)), (tensor(22), tensor(2)), (tensor(4), tensor(21)), (tensor(4), tensor(22)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(23), tensor(5)), (tensor(23), tensor(3)), (tensor(23), tensor(6)), (tensor(23), tensor(7)), (tensor(6), tensor(3)), (tensor(6), tensor(23)), (tensor(6), tensor(7)), (tensor(6), tensor(24)), (tensor(7), tensor(23)), (tensor(7), tensor(6)), (tensor(7), tensor(24)), (tensor(7), tensor(25)), (tensor(24), tensor(6)), (tensor(24), tensor(7)), (tensor(24), tensor(25)), (tensor(24), tensor(26)), (tensor(25), tensor(7)), (tensor(25), tensor(24)), (tensor(25), tensor(26)), (tensor(25), tensor(27)), (tensor(26), tensor(24)), (tensor(26), tensor(25)), (tensor(26), tensor(27)), (tensor(26), tensor(28)), (tensor(27), tensor(25)), (tensor(27), tensor(26)), (tensor(27), tensor(28)), (tensor(27), tensor(6)), (tensor(28), tensor(26)), (tensor(28), tensor(27)), (tensor(28), tensor(6)), (tensor(28), tensor(29)), (tensor(6), tensor(27)), (tensor(6), tensor(28)), (tensor(6), tensor(29)), (tensor(6), tensor(30)), (tensor(29), tensor(28)), (tensor(29), tensor(6)), (tensor(29), tensor(30)), (tensor(29), tensor(31)), (tensor(30), tensor(6)), (tensor(30), tensor(29)), (tensor(30), tensor(31)), (tensor(30), tensor(0)), (tensor(2), tensor(32)), (tensor(2), tensor(33)), (tensor(2), tensor(34)), (tensor(2), tensor(35)), (tensor(34), tensor(33)), (tensor(34), tensor(2)), (tensor(34), tensor(35)), (tensor(34), tensor(11)), (tensor(35), tensor(2)), (tensor(35), tensor(34)), (tensor(35), tensor(11)), (tensor(35), tensor(36)), (tensor(11), tensor(34)), (tensor(11), tensor(35)), (tensor(11), tensor(36)), (tensor(11), tensor(37)), (tensor(36), tensor(35)), (tensor(36), tensor(11)), (tensor(36), tensor(37)), (tensor(36), tensor(0)), (tensor(9), tensor(8)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(38)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(38)), (tensor(5), tensor(0)), (tensor(40), tensor(12)), (tensor(40), tensor(39)), (tensor(40), tensor(13)), (tensor(40), tensor(4)), (tensor(13), tensor(39)), (tensor(13), tensor(40)), (tensor(13), tensor(4)), (tensor(13), tensor(2)), (tensor(4), tensor(40)), (tensor(4), tensor(13)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(2), tensor(13)), (tensor(2), tensor(4)), (tensor(2), tensor(0)), (tensor(2), tensor(13)), (tensor(0), tensor(4)), (tensor(0), tensor(2)), (tensor(0), tensor(13)), (tensor(0), tensor(14)), (tensor(13), tensor(2)), (tensor(13), tensor(0)), (tensor(13), tensor(14)), (tensor(13), tensor(41)), (tensor(14), tensor(0)), (tensor(14), tensor(13)), (tensor(14), tensor(41)), (tensor(14), tensor(42)), (tensor(41), tensor(13)), (tensor(41), tensor(14)), (tensor(41), tensor(42)), (tensor(41), tensor(43)), (tensor(42), tensor(14)), (tensor(42), tensor(41)), (tensor(42), tensor(43)), (tensor(42), tensor(44)), (tensor(43), tensor(41)), (tensor(43), tensor(42)), (tensor(43), tensor(44)), (tensor(43), tensor(0)), (tensor(3), tensor(45)), (tensor(3), tensor(1)), (tensor(3), tensor(46)), (tensor(3), tensor(47)), (tensor(46), tensor(1)), (tensor(46), tensor(3)), (tensor(46), tensor(47)), (tensor(46), tensor(9)), (tensor(47), tensor(3)), (tensor(47), tensor(46)), (tensor(47), tensor(9)), (tensor(47), tensor(1)), (tensor(9), tensor(46)), (tensor(9), tensor(47)), (tensor(9), tensor(1)), (tensor(9), tensor(7)), (tensor(1), tensor(47)), (tensor(1), tensor(9)), (tensor(1), tensor(7)), (tensor(1), tensor(48)), (tensor(7), tensor(9)), (tensor(7), tensor(1)), (tensor(7), tensor(48)), (tensor(7), tensor(0)), (tensor(11), tensor(49)), (tensor(11), tensor(15)), (tensor(11), tensor(10)), (tensor(11), tensor(8)), (tensor(10), tensor(15)), (tensor(10), tensor(11)), (tensor(10), tensor(8)), (tensor(10), tensor(1)), (tensor(8), tensor(11)), (tensor(8), tensor(10)), (tensor(8), tensor(1)), (tensor(8), tensor(50)), (tensor(1), tensor(10)), (tensor(1), tensor(8)), (tensor(1), tensor(50)), (tensor(1), tensor(1)), (tensor(50), tensor(8)), (tensor(50), tensor(1)), (tensor(50), tensor(1)), (tensor(50), tensor(9)), (tensor(1), tensor(1)), (tensor(1), tensor(50)), (tensor(1), tensor(9)), (tensor(1), tensor(1)), (tensor(9), tensor(50)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(3)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(3)), (tensor(5), tensor(0)), (tensor(53), tensor(51)), (tensor(53), tensor(52)), (tensor(53), tensor(8)), (tensor(53), tensor(6)), (tensor(8), tensor(52)), (tensor(8), tensor(53)), (tensor(8), tensor(6)), (tensor(8), tensor(7)), (tensor(6), tensor(53)), (tensor(6), tensor(8)), (tensor(6), tensor(7)), (tensor(6), tensor(54)), (tensor(7), tensor(8)), (tensor(7), tensor(6)), (tensor(7), tensor(54)), (tensor(7), tensor(0)), (tensor(54), tensor(6)), (tensor(54), tensor(7)), (tensor(54), tensor(0)), (tensor(54), tensor(55)), (tensor(0), tensor(7)), (tensor(0), tensor(54)), (tensor(0), tensor(55)), (tensor(0), tensor(56)), (tensor(55), tensor(54)), (tensor(55), tensor(0)), (tensor(55), tensor(56)), (tensor(55), tensor(4)), (tensor(56), tensor(0)), (tensor(56), tensor(55)), (tensor(56), tensor(4)), (tensor(56), tensor(2)), (tensor(4), tensor(55)), (tensor(4), tensor(56)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(16), tensor(12)), (tensor(16), tensor(15)), (tensor(16), tensor(14)), (tensor(16), tensor(57)), (tensor(14), tensor(15)), (tensor(14), tensor(16)), (tensor(14), tensor(57)), (tensor(14), tensor(58)), (tensor(57), tensor(16)), (tensor(57), tensor(14)), (tensor(57), tensor(58)), (tensor(57), tensor(3)), (tensor(58), tensor(14)), (tensor(58), tensor(57)), (tensor(58), tensor(3)), (tensor(58), tensor(0)), (tensor(3), tensor(57)), (tensor(3), tensor(58)), (tensor(3), tensor(0)), (tensor(3), tensor(16)), (tensor(0), tensor(58)), (tensor(0), tensor(3)), (tensor(0), tensor(16)), (tensor(0), tensor(59)), (tensor(16), tensor(3)), (tensor(16), tensor(0)), (tensor(16), tensor(59)), (tensor(16), tensor(0))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_set = CBOWDataset(train_tokenized)\n",
    "skipgram_set = SkipGramDataset(train_tokenized)\n",
    "print(list(skipgram_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 모델 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차례대로 두 가지 Word2Vec 모델을 구현하겠습니다.\n",
    "\n",
    "- self.embedding: vocab_size 크기의 one-hot vector를 특정 크기의 dim차원으로 embedding 시키는 layer\n",
    "- self.linear: 변환된 embedding vector를 다시 원래 vocab_size로 바꾸는 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n",
    "        self.linear = nn.Linear(dim, vocab_size)\n",
    "    \n",
    "    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "    def forward(self, x): # x:(B, 2W)\n",
    "        embeddings = self.embedding(x) # (B, 2W, d_w)\n",
    "        embeddings = torch.sum(embeddings, dim=1) # (B, d_w)\n",
    "        output = self.linear(embeddings) # (B, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n",
    "        self.linear = nn.Linear(dim, vocab_size)\n",
    "    \n",
    "    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n",
    "    def forward(self, x): # x:(B)\n",
    "        embeddings = self.embedding(x) # (B, d_w)\n",
    "        output = self.linear(embeddings) # (B, V)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(vocab_size=len(w2i), dim=256)\n",
    "skipgram = SkipGram(vocab_size=len(w2i), dim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 모델 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 하이퍼파라미터를 설정하고 DataLoader 객체를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 5\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "cbow_loader = DataLoader(cbow_set, batch_size=batch_size)\n",
    "skipgram_loader = DataLoader(skipgram_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 CBOW 모델을 학습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 202.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.517364501953125\n",
      "Train loss: 5.722186088562012\n",
      "Train loss: 4.509489059448242\n",
      "Train loss: 4.71565055847168\n",
      "Train loss: 5.350027084350586\n",
      "Train loss: 4.911778926849365\n",
      "Train loss: 3.9825315475463867\n",
      "Train loss: 5.044991970062256\n",
      "Train loss: 4.438126564025879\n",
      "Train loss: 4.177204132080078\n",
      "Train loss: 4.603321075439453\n",
      "Train loss: 5.182714462280273\n",
      "Train loss: 4.771857738494873\n",
      "Train loss: 4.823988437652588\n",
      "Train loss: 4.422669410705566\n",
      "Train loss: 3.94539213180542\n",
      "##################################################\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 372.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.3733344078063965\n",
      "Train loss: 5.599576473236084\n",
      "Train loss: 4.3914265632629395\n",
      "Train loss: 4.599921703338623\n",
      "Train loss: 5.2240891456604\n",
      "Train loss: 4.6652021408081055\n",
      "Train loss: 3.808961868286133\n",
      "Train loss: 4.932811737060547\n",
      "Train loss: 4.332380294799805\n",
      "Train loss: 4.0147881507873535\n",
      "Train loss: 4.421172142028809\n",
      "Train loss: 4.863188743591309\n",
      "Train loss: 4.64410924911499\n",
      "Train loss: 4.702084064483643\n",
      "Train loss: 4.267542362213135\n",
      "Train loss: 3.8243963718414307\n",
      "##################################################\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 400.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.231768608093262\n",
      "Train loss: 5.478585243225098\n",
      "Train loss: 4.275032043457031\n",
      "Train loss: 4.485116004943848\n",
      "Train loss: 5.098927021026611\n",
      "Train loss: 4.427643775939941\n",
      "Train loss: 3.6395773887634277\n",
      "Train loss: 4.822075366973877\n",
      "Train loss: 4.22916316986084\n",
      "Train loss: 3.858006238937378\n",
      "Train loss: 4.246267795562744\n",
      "Train loss: 4.555294990539551\n",
      "Train loss: 4.518178939819336\n",
      "Train loss: 4.5822834968566895\n",
      "Train loss: 4.115230560302734\n",
      "Train loss: 3.706716537475586\n",
      "##################################################\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.092677116394043\n",
      "Train loss: 5.359189510345459\n",
      "Train loss: 4.160326957702637\n",
      "Train loss: 4.371255874633789\n",
      "Train loss: 4.97455358505249\n",
      "Train loss: 4.199728012084961\n",
      "Train loss: 3.4745688438415527\n",
      "Train loss: 4.712802410125732\n",
      "Train loss: 4.12832498550415\n",
      "Train loss: 3.706940174102783\n",
      "Train loss: 4.078704357147217\n",
      "Train loss: 4.260048866271973\n",
      "Train loss: 4.394067764282227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 355.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 4.464550018310547\n",
      "Train loss: 3.9659085273742676\n",
      "Train loss: 3.592409372329712\n",
      "##################################################\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 410.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.956080436706543\n",
      "Train loss: 5.241368293762207\n",
      "Train loss: 4.047332763671875\n",
      "Train loss: 4.258368492126465\n",
      "Train loss: 4.850984573364258\n",
      "Train loss: 3.9820339679718018\n",
      "Train loss: 3.314148187637329\n",
      "Train loss: 4.605008125305176\n",
      "Train loss: 4.029695510864258\n",
      "Train loss: 3.5615880489349365\n",
      "Train loss: 3.9187049865722656\n",
      "Train loss: 3.978358268737793\n",
      "Train loss: 4.271775245666504\n",
      "Train loss: 4.348851680755615\n",
      "Train loss: 3.8197689056396484\n",
      "Train loss: 3.4815196990966797\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cbow.train()\n",
    "cbow = cbow.to(device)\n",
    "optim = torch.optim.SGD(cbow.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs + 1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(cbow_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = cbow(x) # (B, V)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 Skip-Gram 모델을 학습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 441.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7030582427978516\n",
      "##################################################\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 481.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6635866165161133\n",
      "##################################################\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 586.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.624561309814453\n",
      "##################################################\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 735.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.585994243621826\n",
      "##################################################\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 646.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5478954315185547\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "skipgram.train()\n",
    "skipgram = skipgram.to(device)\n",
    "optim = torch.optim.SGD(skipgram.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(1, num_epochs + 1):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Epoch: {e}\")\n",
    "    for batch in tqdm(skipgram_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) # (B, W), (B)\n",
    "        output = skipgram(x) # (B, V)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    print(f\"Train loss: {loss.item()}\")\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 음식\n",
      "tensor([-7.8031e-01,  3.4020e-01,  2.3965e-01,  1.1466e+00, -4.7382e-01,\n",
      "        -1.1625e-01,  2.5119e+00,  6.0728e-01,  2.4680e+00,  1.2630e-01,\n",
      "        -2.7188e-02,  3.9423e-01,  9.8465e-01, -5.1491e-01,  9.3773e-01,\n",
      "        -2.0908e+00,  9.9917e-01, -2.5360e-01, -4.9429e-01,  3.4974e-01,\n",
      "        -7.9115e-01, -3.7272e-01, -7.2416e-01,  7.1037e-01,  1.3163e-01,\n",
      "         5.8675e-01, -9.7430e-02,  1.3822e+00, -2.8502e-01, -7.8537e-01,\n",
      "        -9.5123e-01, -1.0286e+00,  7.6688e-01, -3.2761e-01,  1.3801e-01,\n",
      "        -4.0390e-01, -8.6721e-01, -1.2883e+00,  1.1042e+00,  2.2619e+00,\n",
      "         9.7791e-02,  9.4427e-01,  8.9367e-01,  1.3734e+00,  2.7213e-01,\n",
      "        -7.3901e-01,  3.9341e-01,  6.8423e-01,  1.5472e+00, -1.0421e-01,\n",
      "        -7.3628e-01, -2.1654e+00,  2.4462e-01,  9.1695e-01, -4.6950e-02,\n",
      "         5.0610e-03, -4.6465e-01, -7.3774e-01, -1.1797e+00, -8.8331e-01,\n",
      "         4.4442e-01,  9.0978e-01,  2.5616e+00,  1.6349e-01,  9.5964e-02,\n",
      "        -8.8922e-02,  1.5621e+00,  5.1451e-01, -5.3047e-01, -7.1057e-01,\n",
      "         1.9713e+00,  1.9023e+00,  9.7000e-01,  1.6177e+00, -4.8513e-01,\n",
      "        -5.9215e-01, -6.2762e-01,  6.5475e-02, -7.2082e-01, -1.6420e-01,\n",
      "        -2.2280e-01,  1.2401e+00,  3.4138e-01, -1.2840e+00, -1.6350e+00,\n",
      "        -6.5896e-01, -3.0616e-01, -1.3532e+00,  1.0170e+00,  3.7837e-01,\n",
      "        -2.6662e-01,  1.8364e+00,  2.4980e-01,  1.3723e+00, -1.7900e-02,\n",
      "        -1.4385e-01,  1.9547e+00, -5.1830e-01,  3.8538e-01,  9.2184e-01,\n",
      "        -5.4997e-01, -4.7631e-02, -1.0276e-01,  1.2959e-01, -3.1721e-01,\n",
      "         2.7689e-01,  6.1655e-01, -2.1437e+00, -1.4720e+00, -8.0351e-01,\n",
      "        -3.1372e-01,  1.7194e+00, -1.9934e+00,  1.7667e-02, -4.0639e-02,\n",
      "         3.7951e-01,  2.5669e-01, -1.6582e+00, -1.1023e-03,  1.9758e+00,\n",
      "        -1.6434e+00, -8.2522e-03, -8.5538e-01,  9.7460e-01,  1.5014e+00,\n",
      "         1.0897e-01,  2.0340e-01, -9.7940e-02,  2.3217e+00, -2.8914e-01,\n",
      "         1.0236e+00, -4.7788e-01,  1.3557e+00, -9.1947e-01, -9.4932e-01,\n",
      "        -1.3046e+00,  2.5262e+00,  1.1113e+00, -1.8813e-01, -7.9594e-01,\n",
      "        -8.4787e-01,  1.6889e+00,  3.4893e-01,  1.2047e-01,  3.1440e-01,\n",
      "         5.1613e-01,  9.5289e-01, -3.4682e-02,  4.3395e-01, -1.2423e+00,\n",
      "        -1.5560e-01,  3.4323e-02, -1.8101e+00, -9.7124e-01, -4.2865e-01,\n",
      "         5.4273e-01,  4.7482e-01, -1.2503e+00,  6.8545e-01,  3.9855e-01,\n",
      "         1.6989e-01,  1.4513e+00, -2.6038e-01,  2.2006e-01, -5.2606e-01,\n",
      "         1.6740e-01,  7.6959e-01, -9.7723e-01,  1.3092e+00,  1.7030e+00,\n",
      "        -7.1313e-01,  5.6531e-02,  4.8902e-01,  3.2708e-02,  8.6103e-02,\n",
      "        -1.0802e+00, -1.0031e+00, -1.4843e-02, -5.7045e-01,  1.8234e-01,\n",
      "        -1.0143e+00, -4.3484e-01, -8.4060e-01, -3.5553e-01, -1.0867e+00,\n",
      "        -4.1910e-01,  2.9517e-01,  7.2969e-02,  9.1472e-01, -4.2685e-01,\n",
      "         1.2463e+00, -8.6465e-01, -1.0092e+00,  8.5423e-01,  1.2691e+00,\n",
      "         2.9808e+00, -3.2207e-01, -5.6910e-01, -8.9806e-01, -3.3563e-01,\n",
      "        -9.4357e-01,  3.5381e-01, -2.9078e-01, -1.2577e+00,  4.7150e-01,\n",
      "        -3.9397e-01, -1.1603e+00, -1.4829e+00,  7.2038e-01, -7.6397e-02,\n",
      "         3.6751e-01,  7.5057e-01,  2.9799e-01,  1.8045e-02,  1.1808e+00,\n",
      "         2.4704e+00,  1.2356e+00, -9.0351e-01, -6.5906e-01,  1.7421e+00,\n",
      "        -3.6901e-01, -4.2717e-01,  6.7428e-01, -1.3162e+00, -1.4041e+00,\n",
      "        -4.2978e-01, -3.7173e-01,  1.1054e+00, -6.6969e-02, -8.8388e-01,\n",
      "        -1.3366e+00, -1.6624e-01, -1.0108e+00, -1.7806e-01,  3.7672e-01,\n",
      "        -3.2116e-01, -1.0270e+00,  1.8875e+00,  2.1317e+00, -1.3088e+00,\n",
      "         9.4271e-01, -1.7540e+00,  1.6453e+00,  4.4708e-01, -1.1201e-01,\n",
      "         3.8833e-01,  1.1898e+00,  1.0451e+00, -1.2772e+00, -1.4186e-02,\n",
      "        -4.9965e-01, -1.4359e-01,  7.3072e-01,  1.1311e+00,  8.0893e-01,\n",
      "        -4.7645e-01], grad_fn=<SqueezeBackward1>)\n",
      "Word: 맛\n",
      "tensor([ 1.6901e-01, -1.0049e+00,  1.3480e+00,  1.5568e-01, -8.4420e-01,\n",
      "        -2.6936e-01,  3.4812e-01,  1.6002e-01, -1.4371e+00,  2.5747e-02,\n",
      "        -7.1336e-01,  1.6903e+00, -7.1813e-02,  1.6065e-01,  1.1732e+00,\n",
      "        -1.1890e-01,  1.3415e+00, -5.9285e-01, -4.0044e-02,  6.3289e-01,\n",
      "         1.7741e+00,  1.5503e+00,  1.6715e-01, -7.3411e-01,  9.1571e-01,\n",
      "        -2.4276e-02,  1.4787e-04,  3.8662e-01,  1.9371e-01, -2.5370e-01,\n",
      "         5.1686e-01,  4.7265e-01,  1.3874e+00,  1.6561e+00,  1.7488e-01,\n",
      "         3.1223e-01, -1.1457e+00,  6.7954e-01, -4.6328e-01,  1.0931e+00,\n",
      "        -1.8031e-01, -5.1148e-02, -1.1415e+00, -1.4564e+00, -2.1409e+00,\n",
      "         1.2218e+00, -1.4853e+00, -4.2371e-01,  5.8552e-02, -4.8069e-02,\n",
      "         6.2347e-01, -7.4163e-01,  1.5641e+00,  8.0746e-01, -1.8197e+00,\n",
      "        -9.8870e-01,  2.2681e-01,  6.7259e-01, -1.0937e+00,  4.1984e-01,\n",
      "         1.2354e-01,  7.9609e-01,  1.9227e+00,  5.8682e-01, -8.4621e-01,\n",
      "        -2.7316e-01, -8.2723e-01, -6.6811e-01, -1.6487e+00, -1.2285e+00,\n",
      "        -6.4610e-01,  9.6252e-01,  9.1570e-01,  2.0233e-01, -4.2204e-01,\n",
      "        -3.4222e-01, -1.4430e-01,  1.2569e+00,  4.5863e-01,  1.5787e+00,\n",
      "         2.6811e-01,  5.3112e-01,  9.0662e-01, -5.8903e-01, -2.3962e-01,\n",
      "        -2.3606e+00, -4.1559e-01, -1.5379e-01, -3.1408e-02,  5.9724e-01,\n",
      "         8.0533e-02, -5.4447e-01,  1.5772e-01, -9.6826e-02,  2.0465e-01,\n",
      "        -4.9360e-01, -8.1467e-01,  5.3285e-01, -1.1031e+00,  1.7485e-01,\n",
      "         7.2805e-01, -3.2677e+00,  3.1684e-01,  7.9653e-01, -1.0023e+00,\n",
      "         1.0586e+00, -6.0206e-01, -1.4041e+00, -2.9468e-01,  1.5900e+00,\n",
      "        -3.9742e-01,  7.7016e-01, -5.4905e-01,  6.6624e-01, -3.3869e-01,\n",
      "        -1.9782e-01,  3.2276e-01,  4.9011e-01,  4.9391e-01,  7.9482e-01,\n",
      "         9.5320e-01, -1.1591e+00,  2.5278e-01,  2.1663e+00, -3.8787e-01,\n",
      "         7.8097e-01, -6.6166e-01,  1.2409e+00,  3.1721e-01, -1.5158e-01,\n",
      "        -1.4952e+00,  3.0164e-01,  9.9046e-01, -6.1769e-01, -9.2716e-02,\n",
      "        -7.6265e-02, -8.3602e-01, -2.2131e+00, -1.1500e+00, -2.7803e+00,\n",
      "        -1.8718e+00, -3.0469e+00,  7.7717e-01,  2.6127e-01,  7.3508e-02,\n",
      "        -7.2526e-01, -1.1701e+00, -3.9109e-01, -9.1339e-01,  4.0621e-01,\n",
      "        -2.1739e+00, -2.3541e-02,  4.1758e-01,  1.8640e-01,  2.5454e-01,\n",
      "         5.5782e-01,  1.5423e+00,  8.9363e-03,  2.0581e+00,  1.3317e+00,\n",
      "         1.0482e+00,  9.7399e-01, -2.0417e+00, -1.0542e+00,  8.0093e-01,\n",
      "         1.3092e+00, -3.5777e-01, -1.4895e+00,  7.8532e-01,  1.4665e+00,\n",
      "        -8.4920e-01,  1.0046e+00,  1.1601e+00,  1.7930e-01, -4.6181e-01,\n",
      "         1.4162e-01,  1.0516e+00, -1.8358e-01,  2.9896e-03, -1.3641e-01,\n",
      "        -4.2434e-01, -3.7151e-01,  2.6657e+00, -1.3582e+00,  8.2084e-01,\n",
      "         5.9090e-01, -2.4172e+00,  4.8679e-01, -5.7218e-01,  7.2174e-01,\n",
      "        -8.7474e-01, -2.2682e-01, -6.6114e-01,  7.6970e-01, -1.2855e+00,\n",
      "         1.3430e-01,  1.6261e+00,  1.1888e+00, -1.6298e+00,  7.8212e-01,\n",
      "        -7.3374e-01, -2.5756e-01,  2.2563e-01,  5.8384e-01, -1.2601e+00,\n",
      "         1.3137e+00, -9.4048e-01,  3.6340e-01, -1.2359e+00, -8.0351e-01,\n",
      "        -3.6785e-01,  1.6215e+00, -5.9459e-01, -1.1406e+00,  7.3910e-01,\n",
      "        -5.2536e-01, -6.9264e-01,  5.5694e-01,  3.7339e-01,  1.2103e-01,\n",
      "         7.6081e-02, -5.3887e-01, -3.0115e-01,  5.5235e-01,  1.0532e+00,\n",
      "        -1.4490e+00,  1.5598e-01, -1.1971e+00, -1.2939e+00, -8.1929e-01,\n",
      "         5.9641e-01,  1.7379e+00, -7.7979e-01,  9.7815e-01,  1.3706e-01,\n",
      "        -7.2082e-01,  1.4945e+00,  5.1033e-02,  1.0608e+00, -4.7713e-01,\n",
      "        -5.0263e-01, -2.5994e-01, -8.5715e-01,  3.3785e-01,  1.5411e-01,\n",
      "         1.0512e+00, -4.5928e-01,  2.2648e-02,  4.8071e-01, -2.9716e-01,\n",
      "         4.0865e-01,  7.9106e-01, -3.5934e-01,  1.0250e-01, -1.1335e+00,\n",
      "        -7.7716e-01], grad_fn=<SqueezeBackward1>)\n",
      "Word: 서비스\n",
      "tensor([ 1.4786,  0.3905, -0.8332,  0.6824,  0.6825, -0.2595,  0.2169,  1.3872,\n",
      "        -0.0100, -0.1580,  1.7148,  1.0895, -0.3647, -0.1574, -0.7596,  0.2503,\n",
      "        -1.3668,  1.4090,  0.2179,  0.5259, -1.1860, -0.0156,  0.5940, -0.4192,\n",
      "        -0.0226, -0.5109, -0.4486, -0.3341, -0.1876,  0.7814,  0.4346,  0.1015,\n",
      "         0.4027,  0.0152,  1.4765,  0.3903, -0.9880,  0.1375, -0.1512, -0.4297,\n",
      "         0.2159,  1.7700,  0.7895,  0.6924,  0.4461, -0.2688, -0.4754, -1.2588,\n",
      "        -0.5341, -0.3940,  0.9390, -0.0104,  0.2510,  1.4521, -0.2193,  1.4028,\n",
      "        -1.3823,  2.2198, -0.4409,  0.9056,  1.4681, -0.8094, -0.2513,  0.4803,\n",
      "        -0.6269,  0.1240, -0.0824,  0.5644,  0.2763, -1.3303, -0.5262, -1.5006,\n",
      "        -0.4220,  0.7490,  0.7180, -0.1650, -1.1135,  0.0506,  0.4551, -1.1252,\n",
      "        -0.4166,  0.6934, -0.1839, -0.2096,  1.1315,  1.9822, -1.5004,  0.2958,\n",
      "        -0.2023,  0.3634,  1.1735, -0.8921, -2.3070, -1.4083,  0.7632,  0.8900,\n",
      "        -0.0410, -0.5672, -0.8005, -2.7274,  0.6574,  0.6026, -0.0748,  0.3155,\n",
      "         1.0800,  1.6752,  0.3543, -0.5470,  0.8532, -0.1549, -0.8645,  0.1838,\n",
      "        -0.0161, -0.6124,  1.9449,  0.2742, -0.8567,  0.0487,  0.4903,  0.4960,\n",
      "        -1.2039,  1.6423,  1.2369, -0.9319, -0.1591, -0.2267, -0.1603,  0.6340,\n",
      "        -0.8392,  0.2487, -0.6730, -1.3916,  0.2334, -0.3258,  1.2465,  0.9748,\n",
      "         0.2215, -1.0458,  1.0770,  0.1202, -0.5817, -2.0978,  1.9575, -0.1301,\n",
      "        -2.3554, -0.5285,  0.9435, -0.8807, -0.4890, -0.9258,  0.1643,  0.2921,\n",
      "         0.9330,  1.2865,  0.6115, -0.1013,  0.2073, -0.5822,  0.9370,  0.4972,\n",
      "        -1.2810,  0.3117, -0.0859,  0.4496,  0.0574, -0.2001, -1.4972, -0.5973,\n",
      "         0.1081, -1.3723, -0.6360, -0.4325,  1.1219,  0.2154,  0.0724, -0.9239,\n",
      "         0.1641, -0.3740, -0.7120,  0.1564, -1.5373,  1.1095, -0.7086, -0.0225,\n",
      "        -0.1747,  0.3444, -0.1286,  1.6360,  0.9330,  0.1188,  0.8471,  1.4425,\n",
      "         0.7179, -0.7834,  1.1145, -1.2957, -1.2940,  1.2295,  0.4106,  0.5870,\n",
      "        -0.7864,  0.6853, -0.0083,  0.3745, -0.5534, -1.4724,  1.0150, -0.8643,\n",
      "        -1.1095, -0.8150,  1.8162, -1.9256, -0.5253,  0.9136, -1.4277,  0.3404,\n",
      "         0.7384,  1.4030, -0.1202, -0.9031,  0.7609,  0.8396, -0.0690,  1.1332,\n",
      "        -0.9305, -0.6475,  0.7680, -2.6760, -0.2516,  0.6909, -0.3202, -1.7600,\n",
      "        -0.1745, -0.0107,  0.9714,  0.5449,  0.0936,  0.8449,  0.4360, -1.2196,\n",
      "         0.8882, -0.9520,  0.5715,  0.3791, -1.4208,  0.3457,  0.2081,  0.7361,\n",
      "        -0.4422,  0.3124, -0.0735,  0.8806, -0.8429,  1.7410, -0.2047, -2.0036],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Word: 위생\n",
      "tensor([-0.1306, -0.5503,  0.5981,  1.8302,  0.1846, -1.8209,  0.5263, -0.3091,\n",
      "         0.0841, -1.3783, -0.5422,  1.2531, -1.0689, -0.6920,  1.1438, -1.3189,\n",
      "        -1.4783,  0.8767,  0.8526, -1.6881, -1.2899,  0.0588,  0.9375,  1.2213,\n",
      "        -0.5093, -2.4534,  1.3259, -0.0463,  1.1031,  0.7655,  0.2626, -0.5971,\n",
      "        -1.2813,  0.2130,  0.6178, -0.5844,  0.6627,  0.3429,  0.3647, -0.6265,\n",
      "         0.7559,  0.5838,  0.1278, -0.1372, -1.4410, -2.1312,  1.6435, -0.0296,\n",
      "        -0.2525,  0.0705,  0.9042,  1.2123, -0.6495,  0.2127,  0.5034, -0.4762,\n",
      "        -0.7084, -1.7937, -0.6218,  1.5456, -0.7402,  0.3890,  2.2705, -1.1000,\n",
      "        -0.4446,  0.1800, -1.1886,  0.8471, -0.5484, -1.7029, -0.2535, -0.0286,\n",
      "         1.2128, -0.4033,  2.0873,  1.1846, -0.7220, -0.6984, -0.8581, -0.0054,\n",
      "         0.2558, -1.0960,  0.4160,  0.3282, -0.4621, -0.7780,  0.2706, -0.2725,\n",
      "        -0.4773,  1.2636,  0.3878, -0.0492, -1.5415,  0.2287,  0.9904,  0.9204,\n",
      "        -1.1925,  0.4645,  0.3404, -0.1524, -0.5073, -1.0112, -1.6690, -0.7504,\n",
      "         0.8497,  1.1142, -1.6302, -0.2487, -0.1865,  1.7033, -0.8740,  0.4011,\n",
      "        -0.4040,  0.0094,  0.4626,  0.1769, -1.0019, -0.3839,  0.2870, -1.8927,\n",
      "         0.1181,  1.5805, -0.0747,  0.0530, -1.0567, -0.0885, -0.7684, -0.6548,\n",
      "        -0.8156,  0.4568,  0.0609,  0.4350, -0.4085, -0.8899, -0.6338, -1.6243,\n",
      "         0.6539,  0.3071,  0.2140, -0.3226,  0.3615, -0.2384, -1.1142, -0.4122,\n",
      "         0.1026, -0.8625,  0.2809, -1.1912,  1.6659,  0.9913,  0.6064, -0.0044,\n",
      "        -1.5937,  1.2577,  0.8393, -0.8690, -1.1631, -0.0654, -1.6048, -0.1612,\n",
      "        -1.7264, -0.8909, -0.8089, -1.7673,  0.2937, -1.0551, -0.1806,  1.1926,\n",
      "        -0.1650,  1.4575,  0.3186, -0.2004,  1.2739, -0.3049,  1.8466, -0.2369,\n",
      "        -1.1611,  0.4048, -0.7719, -0.9549,  0.2042, -0.6746, -0.3499, -0.2160,\n",
      "        -0.8772,  0.5782,  0.9718,  2.3043, -0.0473,  0.5502,  0.9040,  0.1089,\n",
      "         0.6408, -0.6027, -0.7139, -0.8962,  1.1385, -1.6694, -0.2347, -1.2821,\n",
      "        -1.1654, -0.4584,  0.4595,  0.1401, -1.4371, -1.5660,  0.2138,  0.6419,\n",
      "        -0.2066, -0.2180,  2.8650,  0.8050, -0.1723, -0.6224, -1.0556, -0.7432,\n",
      "        -1.4035,  0.0217, -1.0817, -1.5586, -0.5679, -0.1897, -0.0445, -1.5548,\n",
      "         1.0591,  0.5604, -0.6568, -0.7803, -1.0942,  1.8636,  1.3162, -0.2088,\n",
      "         0.7473,  0.2843, -0.6974, -0.0235, -0.7480, -0.4158,  0.0723, -0.0562,\n",
      "         0.5322,  0.6094, -1.4957,  0.0674,  2.0369,  1.6286,  0.3153,  1.5175,\n",
      "        -0.0265,  0.9406,  0.7995, -0.0992, -0.1685,  1.5488,  0.7992, -0.3007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Word: 가격\n",
      "tensor([-8.0965e-01,  1.8518e+00,  7.0028e-01, -9.7737e-01,  1.1395e-01,\n",
      "         8.1721e-01,  1.8472e-01, -1.6783e+00, -9.1599e-01,  9.3096e-01,\n",
      "         3.4165e-01,  5.1518e-01, -6.7325e-01, -1.8944e+00,  2.6670e-01,\n",
      "        -5.0753e-01, -1.0888e+00,  1.7228e-01,  6.5019e-01,  4.2171e-01,\n",
      "         7.4153e-01, -1.4398e+00,  1.4322e+00, -4.2825e-02,  1.0888e-03,\n",
      "        -1.2548e+00, -1.2899e-01,  1.1182e-01, -1.3197e+00,  5.6138e-01,\n",
      "         2.7946e-01,  9.6595e-01,  1.3965e-01,  1.0532e+00,  4.3431e-01,\n",
      "         7.7353e-01, -8.8760e-01,  4.7291e-01,  2.0867e+00, -1.3279e-01,\n",
      "        -1.9776e-01, -1.5983e-01,  8.8798e-01,  2.0015e+00, -9.9080e-01,\n",
      "         3.7029e-01, -6.4019e-01, -1.0480e+00,  1.2524e-01, -3.3436e-01,\n",
      "        -9.7821e-01, -2.8486e+00, -1.4798e-01, -4.5723e-01,  1.3780e+00,\n",
      "         7.9205e-01, -6.8587e-01, -1.5576e-01,  1.1264e-01, -2.3960e+00,\n",
      "         1.5794e+00,  5.0979e-03, -9.8058e-01, -1.1610e+00,  1.5532e+00,\n",
      "         9.1733e-02,  1.3534e+00,  7.0596e-01, -5.3444e-01, -4.7658e-01,\n",
      "         2.0636e-01, -1.1733e+00, -5.1508e-01, -3.0931e-01, -4.1946e-01,\n",
      "         3.4572e-01, -5.8687e-01, -1.6034e+00, -1.1595e+00, -6.1469e-01,\n",
      "        -1.3930e+00, -2.1698e-01,  5.4527e-02, -2.5565e+00,  4.4855e-01,\n",
      "        -1.0519e+00, -3.0263e-01,  2.0952e-01, -5.7367e-01,  1.3690e-01,\n",
      "         1.9352e+00, -2.0027e-02,  1.9303e-01, -5.1098e-01, -4.6199e-01,\n",
      "         2.6107e-01, -3.9752e-01,  2.5428e+00, -1.7225e+00,  1.6051e+00,\n",
      "         1.0206e+00, -1.0391e+00, -3.4299e-01,  5.2178e-01, -8.9704e-01,\n",
      "        -8.4118e-01,  7.5761e-01, -1.4196e+00, -8.5993e-02, -1.2593e+00,\n",
      "        -1.1290e-01,  2.2576e-01, -5.4540e-01,  6.1779e-01,  1.5775e+00,\n",
      "        -9.7427e-01, -5.5002e-01,  4.9793e-01, -1.2230e+00, -5.1931e-01,\n",
      "         2.1633e+00, -9.0222e-01, -7.0338e-01, -9.2751e-01, -3.3058e-01,\n",
      "        -1.6480e+00, -2.2832e-01, -1.2155e-01, -8.7960e-01, -6.4992e-01,\n",
      "         1.3998e+00,  1.7956e-01, -1.0770e-01,  1.0948e+00,  1.9888e-01,\n",
      "         8.2993e-01,  2.3199e+00,  4.7803e-01,  2.9562e-02, -5.5670e-01,\n",
      "         4.7429e-01,  7.0182e-01, -8.2699e-01, -6.6544e-01,  8.4800e-01,\n",
      "         2.2838e-01,  1.2905e+00, -4.4617e-01,  6.3598e-01, -7.1121e-01,\n",
      "        -5.9919e-01,  1.8028e+00,  6.4534e-01,  1.1291e+00, -8.1661e-01,\n",
      "         1.0726e-03, -1.2488e+00,  1.2401e+00, -1.9581e+00,  6.5370e-01,\n",
      "         1.0659e+00,  8.5115e-01,  1.7011e+00,  3.4682e-01,  1.5328e+00,\n",
      "         9.6251e-01,  1.7253e+00, -1.0591e+00, -1.5345e+00, -2.0918e-01,\n",
      "        -3.9503e-01,  3.4039e-01,  9.8129e-01, -9.9683e-01, -2.3404e+00,\n",
      "         6.5583e-01, -8.4204e-01, -1.5520e+00, -1.6055e+00,  1.1070e+00,\n",
      "        -3.6491e-02, -1.1632e-01,  8.8725e-01, -7.8314e-01,  1.5193e-01,\n",
      "         6.1178e-01, -1.1269e-01,  4.8437e-01, -3.4669e-01, -7.0832e-01,\n",
      "        -6.9608e-01, -2.1627e+00, -2.4018e-01, -4.2566e-01, -1.3250e-01,\n",
      "        -5.5337e-01, -6.8013e-02,  1.1942e-01,  5.2750e-02,  1.6676e+00,\n",
      "        -9.0238e-01,  2.2026e-01, -1.2480e+00,  4.2234e-01, -1.4971e-01,\n",
      "         6.1410e-01,  3.3572e-01,  4.5658e-01, -5.6234e-01,  1.0450e+00,\n",
      "         6.0659e-01, -1.1285e+00, -1.6710e-02, -9.6300e-01,  2.6695e-01,\n",
      "        -5.5280e-01, -5.3736e-01,  9.8844e-01, -4.8514e-01,  2.0609e-01,\n",
      "        -1.4276e+00, -3.3616e-01,  6.7304e-01, -1.4876e+00,  1.2799e+00,\n",
      "        -4.5736e-01, -3.6241e-01, -4.4477e-01, -9.8067e-01,  4.0120e-01,\n",
      "        -1.0357e+00,  1.3047e+00, -2.1641e+00,  2.6026e-01,  1.3470e+00,\n",
      "         2.6431e-01,  9.2605e-01, -9.1644e-01,  8.6914e-01, -1.5532e+00,\n",
      "         1.0205e+00,  1.1146e+00,  6.0641e-02,  8.7321e-02,  1.7003e+00,\n",
      "         2.3906e-01,  8.5954e-01, -9.2422e-01, -4.6875e-02, -4.9152e-01,\n",
      "        -1.7092e-01,  4.2116e-02,  2.1851e-01, -1.0242e+00,  4.1510e-01,\n",
      "         2.1404e-02], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = cbow.embedding(input_id)\n",
    "    \n",
    "    print(f\"Word: {word}\")\n",
    "    print(emb.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 음식\n",
      "tensor(2.7317, grad_fn=<UnbindBackward0>)\n",
      "Word: 맛\n",
      "tensor(2.5442, grad_fn=<UnbindBackward0>)\n",
      "Word: 서비스\n",
      "tensor(3.7710, grad_fn=<UnbindBackward0>)\n",
      "Word: 위생\n",
      "tensor(2.9354, grad_fn=<UnbindBackward0>)\n",
      "Word: 가격\n",
      "tensor(3.1709, grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    emb = skipgram.embedding(input_id)\n",
    "    \n",
    "    print(f\"Word: {word}\")\n",
    "    print(max(emb.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['음식', '맛', '서비스', '위생', '가격']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, top_k=5):\n",
    "    input_id = torch.LongTensor([w2i[word]]).to(device)\n",
    "    input_emb = skipgram.embedding(input_id)\n",
    "    score = torch.matmul(input_emb, skipgram.embedding.weight.transpose(1, 0)).view(-1)\n",
    "    \n",
    "    _, top_k_ids = torch.topk(score, top_k)\n",
    "    return [i2w[word_id.item()] for word_id in top_k_ids][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['있다', '완전', '정말', '더']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('가격')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6) Word2Vec 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib 패키지 한글 깨짐 처리\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "# plt.rc('font', family='AppleGothic) # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Skip-Gram 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_weight = pca.fit_transform(skipgram.embedding.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAANNCAYAAAD8vm0LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAB+FElEQVR4nOzde1xUdf7H8fcBvIG3TI1cBSxTzNo1o4utrZRoeEu6W6NFZWRlbakZhZUZpBW6Flku1WarbGzapmlFiv5w1zZNbDPLTCsF73fJRIRhzu+PiZFhBkSFOQy8no+Hj+F8z/ec+czqBm++l2OYpikAAAAAgHUCrC4AAAAAABo6ghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgsSBfvVHbtm3NiIgIX70dAAAAANQpa9eu3W+aZjtv53wWzCIiIpSbm+urtwMAAACAOsUwjLzKzjGVEQAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAHi1efNmbdy40eoyAKBBCLK6AAAAYK3Ro0crMTFRERERbu1r165VUVGRIiMjJUkXXHCBfve737n1ycvL05YtW3xVKgDUWwQzAABQLd26ddPixYvd2mJjYy2qBgDqF4IZAABwWblypWbPni1J+vnnn3XnnXdaWxAANBAEMwAAGqCMDCkpScrPl0JCpMhI6dFHpcsvv1wXXXSRJOlf//qX2zXBwcGKiYlxa2vVqpWvSgaAeo1gBgBAA5ORISUkSIWFzuNff5WefFJq106y2RqrcePGkpxBrKioyHXd+++/b0W5ANAgEMwAAGhgkpJOhLIyRUVvasyY1srLK9HRo0fVpUsXNWvWTJK0dOlSpaSkuPru2bNHpmkqNDTU1ZaYmMh6MwA4AwQzAAAamPz8ii1PSNqjw4cDFBsbpObNm6tjx4766KOPJEn9+/dX//79Xb3nzp0ru92u+Ph4X5UMAPUewQwAgAYmLEzKyyvf0llSZ4WHS716WVQUADRwPGAaAIAGJiVFCg52bwsOdrYDAKzBiBkAAA2MzeZ8LduVMSzMGcrK2ssMHz7c6/UxMTEyTbOWqwSAhsXw1X9Yo6KizNzcXJ+8FwAAAADUNYZhrDVNM8rbOaYyAgAAAIDFCGYAAAAAYDGCGQAAAABYjGAG1IB58+ZZXQIAAAD8GMEMOAWxsbGur3NycjR16lRJ0l//+le3ft26dVN0dLTbny5duvi0VgAAAPgPtssHTkFBQYErjP38888677zzvPbr3LmzsrKy3NrKhzoAAACgPIIZcApCQkJ08803S5JWr16tbdu2SZIcDodiYmL06KOPasiQIdq6datiYmLcrs3Ly/N5vQAAAPAPBDPgFJSUlGjjxo2SpPz8fBmGIUkKCAhQdna2q19ZHwAAAKA6ziiYGYZxuaRUSYGSFpqm+VKNVAXUIRkZUlKSlJ8vtWuXpKVLf9HVV0sXXHCBLr74YklSYGCgJGnp0qVKSUlxXVtaWiqHw6FGjRq52hITE5nWCAAAADeGaZqnd6FhNJL0oaSRpmkeOln/qKgoMzc397TeC7BKRoaUkCAVFp5oa9Zsl/r1m6HS0vVyOBzq0qWLHnnkEXXt2tXj+sWLF2vr1q0aM2aMD6sGAABAXWQYxlrTNKO8nTuTXRkHSsqT9J5hGMsMw+h1BvcC6qSkJPdQJknHjt2uNWuGaPHixfr000913333acSIESouLnb1ufXWWyVJzZo1U/PmzX1ZMgAAAPzQmUxlvEBSG0lDJHWU9J6k3uU7GIaRIClBksLCws7grQBr5Od7a/1Ve/Z0V0CA8/ca3bp1U2BgoI4fP67GjRtLkg4ePChJ6tevn48qBQAAgD87k2Bml7TENE27pK2GYTgMwzDMcnMjTdNMl5QuOacynlmpgO+FhUmemymmqWnTERowwCFJstvtmjBhglq0aOHqsW7dOo9dGSXp73//uzp06FCLFQMAAMAfnUkw+0LSeEnvGIZxjqQS83QXrAF1VEqK5xqz4ODeSk/Pks1W+XX79u2r/eIAAABQb5x2MDNN80vDMH4wDONzOUfPxtZcWUDdUBa+ynZlDAtzhrWqQhkAAABwqk57V8ZTxa6MAAAAABqy2tqVEQAAAABQAwhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgCoMTk5OUpOTra6DAAA/E6Q1QUAAPzP7Nmz1bRpUw0fPlySdN1112natGnasmWLq09JSYkGDhzoce3XX3+t3bt3KyiIb0EAAJThuyIA4LRkZGQoNzdXkvTjjz/q66+/1o8//qhmzZpJkho1aqTs7GyP62JjY31aJwAA/oBgBgA4LTabzTVi9vXXX2vjxo3Kz89Xt27dJEnHjh3T4MGDFRDgPmv+m2++kWEYPq8XAIC6jGAGADhl3bp10z//+U/XiNlFF12k5ORk5eTkaOXKlZKk0tJSBQcHa/HixVaWCgCAXyCYAQCqJSNDSkqS8vOlsLDeGj8+XEFBH7nOz5o1S6Zpuk1VXL16tWJiYjzuNXXqVEVFRfmkbgAA/AHBDABwUhkZUkKCVFjoPM7LkyZMaKIHH+yo6OgT/TZs2KCsrCxFRUWpefPm2rdvnyRp7ty5stvtio+P93ntAAD4A4IZAOCkkpJOhLIyx45t18yZM/T11yfaCgoKNGzYMJ/WBgBAfWCYpumTN4qKijLL1iIAAPxLQIDk+e0iR9JKmeZEj/5Lly5VSkpKlfdMTExkh0YAQINiGMZa0zS9zuVnxAwAcFJhYc7pixUFBr6t6Gj3LfEvvfRSTZs2Tf379/dRdQAA+D+CGQDgpFJS3NeYSVJwcLTS07fIZrOuLgAA6ouAk3cBADR0NpuUni6Fh0uG4XxNTxehDACAGsKIGQCgWmw2ghgAALWFETMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQxAtRUXFysvL6/KPh988IGPqgEAAKg/CGYAvMrKytJrr73mOo6NjdXOnTv1/PPPS5KefPJJRUdHKzo6WhdccIHmzp0rSXrzzTctqRcAAMCfBVldAIC66cCBA9q3b1+l56dMmeL6esSIEbr22mt9URYAAEC9xIgZAK+WLVum77//XkVFRZKkdevWacSIER795syZowsvvFAdOnRwtcXExGjhwoU+qxUAAMDfEcwAeJg1a5auuOIKPfPMM4qPj9f+/fv1hz/8wTVdUZIOHz6sJ554Qnl5eXrqqafcrs/OztawYcN8XTYAAIDfYiojADfbtm3Tvn379PTTT0uSnnrqKZmm6danoKBAY8eO1SOPPKKePXu6nbv66qt9VSoAAEC9YVT8gau2REVFmbm5uT55LwCnJiNDSkqS8vOlsDApJUW69dYSJScna8WKFTIMQ0ePHlW/fv30xBNPqHXr1jp27JgGDhzoca9Dhw5p3bp1FnwKAACAus0wjLWmaUZ5O8eIGdDAZWRICQlSYaHzOC/Pebxw4Uu68spWWr58uQICAmSapl577TVNnz5dkydPVrNmzZSTk+Nxv9jYWN9+AAAAgHqANWZAA5eUdCKUlSkslJYsKdbZZ5+tgADnfyYMw1Dbtm11/PhxC6oEAACo3xgxAxq4/Hzv7QUFT2rt2gl69913FRgYqNLSUkVGRio1NbXK+7Vq1aoWqgQAAKjfWGMGNHAREc7pixWFh0tbt/q6GgAAgPqrqjVmTGUEGriUFCk42L0tONjZDgAAAN8gmAENnM0mpac7R8gMw/manu5sBwAAgG+wxgyAbDaCGAAAgJUYMQMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAB8oKSkxPX15s2btXHjxir7L1q0qLZLAgDUIQQzAABqUVxcnCTpvvvu0/79+yVJa9eu1apVqyRJMTExbn+mTp0qSZo5c6Yl9QIArBFkdQEAANRnhYWFkqTi4mLZ7XavfbKzs31ZEgCgDiKYAQBQS44cOaLt27dLknbv3q0DBw5oz549ysvL0znnnGNxdQCAuoSpjAAA1JLVq1fr4MGD2rdvn7Zs2aKvvvpKH3/8sb766quTXrt3717FxcVpzpw5PqgUAGA1RswAAKglH3zwgdLS0hQfH68RI0Zo4cKFmj9/vjIzM1VUVFTlte3bt9eCBQt8UygAwHIEMwAAalBGhpSUJOXl5Ssk5Lj69LlFhw/PUHx8vN588019+umnHtekpqbK4XDIbrersLBQCQkJFlQOALASwQwAgBqSkSElJEjO/T6CdfTocxo1aoOuuupinX/++Xr66af19ttvq3379q5r0tLSVFBQIMMwFBQUpJYtWyo0NNSyzwAAsAbBDACAGpKUVBbKJKmtJKmoSNq8ebokKSQkRI888ogyMzNd13Tv3t3HVQIA6iI2/wAAoIbk53tv37492LeFAAD8DiNmAADUkLAwKS/Pe3t5w4cPP+m9srKyaqgqAIA/YMQMAIAakpIiBVcYHAsOdrYDAFAVghkAADXEZpPS06XwcMkwnK/p6c52AACqwlRGAABqkM1GEAMAnDpGzAAAAADAYjUSzAzD+MowjNiauBcA1FW7du3Sl19+WWWf4uJi5Xnb/QEAAKAKZxzMDMO4WVKrGqgFAOoEu92uhIQE9evXT3379tXMmTMlST/99JM++eQTV7+srCy99tprruPY2Fjt3LlTzz//vM9rBgAA/u2MgplhGC0kjZSUUTPlAID15syZo8jISC1btkw5OTn6v//7P/38888e/Q4cOKB9+/ZZUCEAAKhvznTE7FVJyZIc3k4ahpFgGEauYRi5/PACwF84HA61a9dOkmQYhs4++2w5HJ7/mVu2bJm+//57FRUVSZLWrVunESNG+LRWAABQP5x2MDMMwyYp3zTNNZX1MU0z3TTNKNM0o8p+yAGAum7kyJFauXKl7r77btlsNl1wwQXq0qWLW59Zs2bpiiuu0DPPPKP4+Hjt379ff/jDHzR37lyLqgYAAP7sTLbLv0NSoWEYmZIukhRtGMYW0zR/qJnSAMA3MjKkpCQpP1/q1KlETz75i5KTk1VSUiK73a7jx49r3bp1rpGxbdu2ad++fXr66aclSU899ZRM07TyIwAALPDNN98oKSlJx48flyQ1bdpUL7zwgi666CJJUklJiQYOHOhx3ddff63du3crKIgnV+EEoyZ+mDAMY5KkVaZpZlXWJyoqyszNzT3j9wKAmpSRISUkSIWFZS0/KSjoFcXEBMkwNqpRo0bq1auXmjZtqq5du2rdunWaNGmSJOc33OTkZK1YsUKGYejo0aPq16+fnnjiCbVu3dqiTwQA8AWHw6HLL79c8+fPV0REhCRp69atuuWWW7R69WoFBFQ+MS02NlaLFy8mmDVAhmGsNU0zytu5GvnXYJrmpJq4DwD4WlJS+VAmSefLbn9V338vTZo0W0FBQa51YytXrnS79qWXXlKrVq20fPlyBQQEyDRNvfbaa5o+fbomT57suw8BAPC53bt3q3Pnzq5QJkkREREKDw/Xnj17dO655+rYsWMaPHiwR0j75ptvZBiGjytGXUdMB9Cg5eefWnt5xcXF6tixo+sbrmEYatu2rbZv316DFQIA6qIOHTpo9+7dysrK0nXXXSdJ+vTTT7V3716de+65kqTS0lIFBwdr8eLFVpYKP0EwA9CghYVJ3p4HHRZ28muffPJJTZgwQe+++64CAwNVWlqqyMhIpaam1nyhAADLlV+THBYmTZgwX0uXvqSXX35ZknTJJZdo/vz5btesXr1aMTExHveaOnWqoqK8zmhDA1Uja8yqgzVmAOoizzVmUnCwlJ4u2WzVu8eUKVP02GOPqWnTppKc2+gHBgYqOjq60muWLl2qwMBAXXvttW7tCxcu1LBhwyo9rsyiRYs0dOjQ6hUMADhlZ/r9Yu7cubLb7YqPj6+1GlH31foaMwDwV2XfTMv/BjQlpXrfZKdNm6ZDhw5p3rx5Onz4sBo1aqTRo0dr27ZtrgXdAwYMUHFxsb755hv9/ve/V2hoqDIzM7Vjxw6vi77T0tLcgljF44q/dY2JiVFiYqJmzpxJMAOAWuS5Jtl5nJRU/V/kAVUhmAFo8Gy20/umOnDgQBUXF+vzzz/XsGHDFBwcrDZt2rj1WbJkiY4fP66OHTvqo48+0oYNG5Samqrc3FwNGTJEkrRhwwbXZiGNGzfW8OHDJUl//vOfvb5vdnb2qRcLADgj7muPl0maIsk5Hd7LTEU9/vjjmjJlikf77NmzXV8nJiYqNja2RuuE/yKYAcBpuvDCCyVJe/fuVaNGjdSzZ0+PPqWlpRo7dqyee+453XfffZoyZYqGDx+uwMBAt/tkZmYqKytLa9asUY8ePXTDDTewYxcA1CHua5L7/fZHCg+XKvt9WdmmIEB1VP6ABQDASc2ZM0fXXHONnn76aRVWmONy9OhR3XfffRo+fLgefPBBvfjii0pNTdXZZ5+ts846y63v9OnTtXr1at1xxx3auXOnJkyY4Dq3e/duHTlypMo69u7dq7i4OM2ZM6fmPhwAwCUlxbmmrLzgYGc7UBMYMQOAaiq/G1enTqW65ppZOn58pTIyMvTvf/9bQ4cO1cyZM139Q0JC9Le//U0rV65UcnKyJOf2ytOmTZMkxcXFufouWbJEWVlZkqQxY8a4prY4HA5NnTpVffv21Q033FBpbe3bt9eCBQtq+BMDAMqcyZpkoDoIZgBQDRV348rPl957r4Vee+2vKikpUXR0tC688EK1aNFCq1atcrv2/PPPd+3YWObTTz/V119/rYsuukiS1KtXL2VmZuq2225Tdna2OnXqJEkKCAjQjBkz3K5NTU2Vw+GQ3W5XYWGhEhISaudDAwDcnO6aZKA6CGYAUA2eu3EFqrj4Tj3xxAyde24XDRkyRO3bt5ckj62Qly9frnfeecetbffu3UpMTHQdT548Wenp6br//vvVrVs3vfrqq17rSEtLU0FBgQzDUFBQkFq2bKnQ0NCa+IgAAMBCBDMAqAb33bhOOHTo5Ndu2bJFEydOrPK5ZkFBQXrwwQdPeq/u3buf/A0BAIDfIZgBQDW478Z1wllnSRMnTvSYbjho0CCNHTvWdTxu3DiPDT8q9gEAAA2XYZqmT94oKirKzM3N9cl7AUBNq7jGTHLuxpWeznoDAABQPYZhrDVNM8rbObbLB4BqsNmcISw8XDIM5yuhDAAA1BSmMgJANbEbFwAAqC2MmAEAAACAxQhmAAAAAGAxghkAwK98++23VpcAAECNI5gBAOqknj17Kjo6WtHR0erZs6emTp0qSXr00UetLQwAgFrA5h8AgDopNDRUWVlZkqScnBytWrXK4ooAAKg9jJgBAPyKaZpKTU3VunXrrC4FAIAaw4gZAKBOcjgc2r9/vySpoKDA1W4Yhvr06aNzzz3XqtIAAKhxBDMAQJ2RkSElJUn5+VLLllfo5psT1aWL89xNN93k6nfllVdaVCEAALWDYAYAqBMyMqSEBKmw0HlcUPC81qyR7rtP6tp1jbZt22ZtgQAA1CLDNE2fvFFUVJSZm5vrk/cCAPifiAgpL8+zPTxcio6O15YtW5Sdna1GjRr5vDYAAGqCYRhrTdOM8naOzT8AAHVCfr631kLl5T2qyMhIjR07VjabTbt27fJ1aWhANm7cqE2bNlldBoAGiKmMAIA6ISys4ojZx5JmqX37R5WY2E+S1K1bN02YMEGXXHKJxo4da0WZqCcGDBig4uJiffPNN/r973+v0NBQZWZmatWqVQoKClLXrl2tLhFAA8NURgBAnVBxjZkkBQdL6emSzWZdXai/iouLdd555yk/P1/Jyclavny5du/erYkTJ2rEiBFWlwegHqpqKiPBDABQZ5TflTEsTEpJIZSh9qSmpqq4uFiS9NRTT0mSZs+eraCgIIIZgFrBGjMAgF+w2aStWyWHw/lKKENtKCoq0qRJk9SsWTM99dRT6ty5s+6++26VlJRYXRqABow1ZgAAoEEJCAjQgAEDdNVVV0mSbr/9dg0ZMkSNGjVSp06dFBgYaHGFABoighkAAGgQTkyVbaywsKsUETFK0o8e/ZKSknxfHIAGj2AGAADqvYqby+TlSfv2veWxuczs2bO1Z88ea4oE0KCxxgwAANR7SUnuO35KzmMGxwDUFYyYAQCAes/7A8w929u2bcsaMwCWIJgBAIB6z/MB5ifayxsyZIhvCgKACpjKCAAA6r2UFOcDy8sLDna2A0BdQDADAAD1ns0mpadL4eGSYThfK278AQBWYiojAABoEGw2ghiAuosRMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsFWV0AAMA/ffzxx3r55ZclSXl5eTJNUxEREZKksWPH6vrrr7ewOgAA/IthmqZP3igqKsrMzc31yXsBAHyjtLRUCxYs0Pvvvy/DMDRs2DDdfPPNatSokdWlAQBQ5xiGsdY0zShv5xgxAwCclrfeekvff/+9rr32Wk2cOFEOh0NbtmzRAw88oC5duigxMdHqEgEA8BuMmAEATtnBgwf1888/u44//fRTlZaWasiQIa62zp076+yzzz6l+8bExCg7O9utLTY2VllZWa7jyMhIdezY0a1Ps2bNtGjRolN6LwAAfI0RMwDAGcvIkJKSpPx86dxzD+i663J1+eXOc+3atZMklf8FXIsWLU45mG3ZskXR0dFubdu3b3c7joiIcAtqAADUBwQzAMBJZWRICQlSYaHzeOfOC/TPf16gb7+9SS1bFrj1bd68uRYsWHBa79O2bVuNHz/ere2FF15wOx4wYIAmTZrkcW1iYqKaNm16Wu8LAIDVmMoIADipiAgpL8+zvWnTWB075j56VXHq4an4z3/+o+PHj7u1NWnSRFdffbWWLVumKVOmVHn9hAkTNGDAgNN6bwAAahtTGQEAZyQ/33t7UdHp37P81Mh27ZaqTZsUnXNO5f0TExOVnZ2tLVu2qLS01O1cYGCgOnfufPrFAABgMYIZAOCkwsK8j5gFBW1STEyMW9vmzZtPer+KUyP37u2vX3/tr4kTJZtNmj9/vvbv36/Ro0d7XJudne0xqvb222/rf//7X/U/EAAAdQzBDABwUikp7kFKkoKDpfT0n2Wznfr9kpLc7yU5jx944BHZbK9Wee3ChQv166+/urUdOHDg1IsAUGft2LFDu3btUlSU1xlfQL1EMAMAnFRZ+CqbehgW5gxrpxPKpMqnRh45skGSNHDgQI/pimXsdrtycnJO740B1CmFhYVKSEhQfn6+2rRpo7feektt27bV5s2btXLlSoIZGhSCGQCgWmy20w9iFVU2NTIgYJ3H1EhJeuedd9SpUydJ0vfff++1z1//+ledf/75NVMgAJ945ZVXdO211+qee+7R8uXLNXHiRM2aNcvqsgBLEMwAAD5X+dTIfScNf3neEh0Av/Tf//7X9XiNa6+9Vi+++KK1BQEWCrC6AABAw2OzSenpUni4ZBjO1/T0mhuRA+AfDMNQYGCg67j810BDw4gZAMASNTk1EoB/at68uQ4ePKg2bdqopKREDofD6pIAyzBiBgAAAJ/JyHA+tD4gQFq+PEE33DBeW7du1cSJE3X77bdbXR5gGUbMAAAA4BMVn2G4Z0+0Dh+WHn74Dd17b2/FxcVZWR5gKYIZAAAAfMLbMwyPH4/W+vXRIpOhoWMqIwAAAHyismcYVtYONCSMmAEAAMAnKnuGYViY+3F0dLSio6N9UhNQVzBiBgAAAJ9ISXE+s7C84GBnO9DQEcwAAADgEzzDEKgcUxkBAADgMzzDEPCOETMAAAAAsBjBDAAAAAAsRjBDg3bkyBH93//9X5V9Fi5c6KNqAAAA0FARzNAglJaW6uGHH1bfvn3Vp08fvf3225KkAwcOKCMjw61vTEyM23FaWprP6gQAAEDDRDBDg5Cenq6wsDCtWLFCK1as0CeffKLvvvvOa9/i4mIfVwcAAICGjmCGBuH777/XwIEDJUmBgYGKjo7WDz/84NHPbrdr7dq1stvtvi4RAAAADRjBDA3C9ddfr9TUVP3666/Kz8/XggUL1KdPH49+n3zyicLDw/XRRx+52hwOh4YPH6709HRflgwAAIAGhOeYod7KyJCSkqT8fCksLEa33VaqRx55RCEhIXr99dfVvn17bd261dW/pKREb7zxhpYsWaL4+HgNGDBAzZs3V0BAgDIzM637IKgTunbtqg4dOri1tWvXTvPmzbOoIgAAUJ8QzFAvZWRICQlSYaHzOC9Peu2165Sefp3Xh1ra7Xbdd999evjhh9WxY0clJyfr5ptv9tgYBA1XWFiYsrOzrS4DAADUUwQz1EtJSSdCmbRd0lIVFpbqkUfsOnCgWEVFRTp69KiuueYaZ4/t2zV48GANGjRIknTllVfq+eefV1AQ/xcBAABA7eOnTtRL+fnlj5pLOk9SoA4eDFKfPo3VuHFjBQcHuzb5iIiIUEREhNs9LrvsMh9VCwAAgIbutIOZYRitJc2SFCrnJiJ3maa5pYbqAs5IWJhz+qJTa0l9JUnh4VKvXif6lV9jBpRxX58opaRIZ511lqKjo7Vnzx6ZpqnQ0FBJ0qeffqpmzZpZXDEAAPB3hmmap3ehYXSQJNM0dxqGMVjSINM0H6qsf1RUlJmbm3t6VQKnqOIaM0kKDpbS0+V1jRlQ5mT/dubOnSu73a74+HjLagQAAP7JMIy1pmlGeTt32tvlm6a50zTNnb8dHpJ09HTvBdQ0m835g3R4uGQYzldCGarDfX2iU2Ghsx0AAKC2nPaImesGhvE7SWmSxpQLamXnEiQlSFJYWNileSfmlgFAnRQQILn/Z3GppBRJUt++3q9JTExUbGxsbZcGAAD8XFUjZmcUzAzDGCJpqKSnTNM8UFVfpjIC8AcREeXXJ54QHi6xJBEAAJyJWpnKaBjG7yUNNU3z/pOFMgDwFykpzjVl5QUHO9sBAABqy2kHM0mxkq42DCPntz9/r6miAMAqrE8EAABWOOM1ZtXFVEYA8H+bN29WaWmpIiMjK+3zww8/KCAgQBdccEGV91q9erVWr16tRx55pKbLBACgTqpqKiMPmAYAeEhJSdHSpUslSaWlpQoODtZnn32mtWvXqqioSJGRkcrMzFRRUZHi4+Nlt9s1f/58SdKKFSv0xz/+0RXMDh06pHvvvVdHjhzR8ePHNWrUKN155506duyYDh48aNlnBACgLiGYAQA8JCUlKem3ZwR8+eWXmjNnTpX9AwIC1LFjR0lSmzZt3M7NmDFD99xzj4YMGSKHw6Ho6GjdeOONtVM4AAB+imAGAKjS4sWLdf3111fZp7i4WJMmTZIk7dq1S927d3edO+ecc1RUVCTJOfrWsmVLNW3atNbqBQDAHxHMAACV2rZtmz7//HM999xzXs//9NNP+uKLL1RcXKzHHntMrVu31ubNm936jB49WmlpaXr66adVWlqql19+WUFBp//tJyPD+cDv/HwpLMy5YyabswAA/B3BDADg1aFDh3T//ffr7bfflmEYHucvv/xyHT16VD/88IOCgoIUEhKi1q1b65xzzlFgYKCrX0BAgAYNGqTPPvtMkrRs2TItW7ZMkjRo0KBTqikjQ0pIkAoLncd5ec5jiXAGAPBvBDMAgMco1J13rtQXXzyn5ORkRUREeL3mvPPO048//qiXXnrJ49yTTz7pdtyiRQt16dLFre27777TJ598ossvv7zadSYlnQhlZQoLne0EMwCAPyOYAUAD520UaurU/+qVV/6hK65oV+W1O3fu1KhRozR8+HBX29y5c7Vr1y63fhs3blRqaqpbW0FBgQYPHnxKtebnV2z5UtJPys+//ZTuAwBAXXMmD5gGANQD3kahSkom6MUXqw5lp2L37t0aMWKEsrOzXX/WrFnj2jCkusLCKrZcLul2L+2oCZs3b9bGjRur7HP06FHX1NTyFi5cWOVxZRYtWlT9AgGgHmHEDAAaOM9RqKrbK0pJSdFbb73lOt69e7cSExM9+r388suaO3euW9sf/vAHTZs2rdq1pqS4j+5JUnCwsx2nrzrPrYuNjZXdbpfkfCTC+++/r9jYWL311luaM2eO+vXr53bPtLQ0DRs2rNLjmJgYt/4xMTFKTEzUzJkzNXTo0Nr6qABQZxHMAKCBCwtzTl/01l5R+SmLkhQfH6/4+PiTvsfw4cM9rj0dZevI2JWxZlX3uXXZ2dlV3mfDhg2aPHmyJKlx48auv/M///nPp3U/AGhICGYA0MD52yiUzUYQq03VeW5dZS688EJlZmYqKytLa9asUY8ePXTDDTd43dUTAOCONWYA/NrGjRu1adMmj3a73S7TNCU5t2c/evToSe/VUNe22GxSeroUHi4ZhvM1PZ3w0xCVPbeu4jTDyvzvf//TqFGj3NqmT5+u1atX64477tDOnTs1YcIE17ndu3fryJEjVd5z7969iouLq3TUDgDqK4IZAL/gbT2KJK1atUpffvmlqz0uLk6SlJycrHXr1kmS5syZo0OHDrldW/7P1KlTJUkzZ86szY9Qp9ls0tatksPhfCWUNTwne26dNz179tRf//pXt7YlS5bo2Wef1fnnn68xY8Zo/fr1kiSHw6GpU6eedPpi+/bttWDBAo0cOfL0PggA+CmmMgKoV8p+G3/s2DGVlpZW2o+1LWjITue5dZL0448/qrS0VEePHtV5550nwzDcHiYuSb169VJmZqZuu+02ZWdnq1OnTpKcDxqfMWOGW9/U1FQ5HA7Z7XYVFhYqoexp4QDQABHMAPiNiRMnur52OBwe5w8fPqy833ax2L17t/bv3++z2gB/cbrPrbvhhhv0xhtvqEmTJmrRooVslQyrTp48Wenp6br//vvVrVs3vfrqq177paWlqaCgQIZhKCgoSC1btlRoaOgZfz4A8FcEMwB+Y8SIEa6vV61a5XF+1apVatSokbZu3art27drxYoVuu666yRJ999/v6644go988wzld6/bG3LTTfdxDQq1FuVP7dOeuCByq+7//77q3X/oKAgPfjggyft171792rdDwAaCoIZgDqr/HSrJk2ktWsjq1z79MEHH2jOnDkaN26cevToofXr17ueu/TXv/5VHTt2rPL9yta2APXZmT63DgBQOwhmAOqkitOtioqke+6Zry+/lK6+Wq4dF8t88803atq0qaKiotS0aVPddddd2rVrl6ZPn+71/qxtQUN1Js+tqygrK0uSNHv27JO+b3XXdZbdEwAaGoIZgDrJc7rVRBUX79Y//iH17i3Xw3DLdO3aVSkpKSouLlbz5s116aWXSpKaNGmiDRs2uPVlbQsaMn97bh0ANBQEMwB1kue0qmhJ0oEDkrdf4jdt2lRNmzaVJLftu/v376+MjAy3vqxtQUNWNh24/K6MKSk8IgEArEYwA1Anncp0KwCnxmYjiAFAXWNUXKdRW6Kioszc3FyfvBcA/1dxjZnknG6Vns4PlAAAwD8ZhrHWNM0ob+cCfF0MAFSHzeYMYeHhkmE4XwllAACgvmIqI4A6i+lWAACgoWDEDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAYJmjR49q2bJlVpcBAIDlCGYAgFr37bff6uqrr9ZVV12l//73v5KkmJgYHTp0SHPmzLG4OgAArMd2+QCAWjdp0iT985//VHBwsG677TZ99tlnVpcEAECdwogZAKDWFRcXq0OHDmrdurWaNWsmu91+WvdZtGjRSfvs2LFDubm5p3V/AACsQjADAPhUSEiIbrzxRn333XeV9omJiXH7M3XqVEnSzJkzPfrGxsa6HW/evFlZWVk1WzQarIULF1Z57E11foEAABURzAA/tnnzZqaEoc7KyJAiIqSAACk721RGhrO9oKBACxYsUI8ePaq8Pjs72/UnMTGx0n7FxcU1WDXgLi0trdLjU/kFAgCcDGvMAD8we/ZszZ07V5J06NAh9enTR6+88op27NihNWvW6LrrrrO4QsBdRoaUkCAVFjqPjx07R6NGrdfevc3VpEkTBQTUzO8FTdNUbm6uiouL1bhx4xq5J7BhwwZNnjxZktS4cWMNHz5ckvTnP//Zo292drZPawNQfxHMAD8QHx+v+Ph4SdLkyZPVu3dvawsCTiIp6UQoc5qqoqKxmjixSN9//5fTvu/evXsVFxenm266SSNHjtTSpUvVsWNHffjhh7rtttvOuG5Aki688EJlZmYqKytLa9asUY8ePXTDDTfIMAyrSwNQjzGVEfAjmzZt0nfffadGjRpp1KhRevnll60uCfAqP79iS1tJf9exY+8rLCzM6zXlpz5+/rlcUx/La9++vRYsWKCRI0fKbrfr1Vdf1WeffaY333xTv/zySw1/CjRk06dP1+rVq3XHHXdo586dmjBhguvc7t27deTIkUqvLfsFAo+CAHAqGDED/ERubq4mTZqkN998U+3atVNUVJT+85//aO3atVaXBngIC5Py8ry3e1Nx6mNRkXT33alavNihiy+2q7CwUAkJCa7+drtdDzzwgEaNGqVOnTrphRde0M0336x//OMftfBp0FBkZDhHe/PzpSZNluitt7J0/vnSmDFjXJvMOBwOTZ06VX379q30PmW/QACAU0EwA+q40tJSPfTQQ3I4HMrIyFCrVq3kcDjUvHlzNWvWzOryAK9SUtyDliQFBzvby5StzZk9e7YiIipOfUxTSUmBcnIMjR8fpJYtWyo0NNR1dufOnerXr5/i4uIkSZdffrmSk5OZaobT5vnLgV66555MmeZtOuecbHXq1EmSFBAQoBkzZkhybvKRmpoqh8Mhu93zFwgAcCoIZkAdVP63tmFhgUpMTNHo0WdLcm520KNHD3377bcWVwlUzmZzvp74d+wMZWXtFXlOfewuSdqzR7r0Us/+YWFhHlMiL7/88jMrGg2a57rIySouTtcDD9yvSZO66dVXX/W4Ji0tTQUFBTIMQ0FBnr9AAIBTQTAD6piKv7XNy5PGjTtbLVo4f6h96aWXdNFFFyk5OVnPPvusoqOjLa0XqIzNVnkQq+hUpz4CNc3zlwNBkh7U0aPSuHHer+nevXstVwWgIWHzD6CO8fytrfP48ce/1p133inTNDVv3jy1adNGt99+u3Jzc2WapjXFAjUkJcU51bG8ilMfJVXrwdHR0dGaOHFiDVaHhqCyXwLwywEAvmL46ge6qKgoMzc31yfvBfizgADJ8/+WxyVN0fffD1dkZKSr9aefftKcOXP0+OOPKyQkxJdlAjXOfQpv1VMfgZpWcbaC5PzlQHo6/w4B1BzDMNaaphnl9RzBDKhbIiK8T+kKD5e2bvV1NQDQcPDLAQC1rapgxlRGoI6p7pQuAEDNstmcvwBzOJyvhDIAvkQwA+oYm805dSY8XDIM5ytTaQAAAOo3dmUE6qBT2c0OAAAA/o8RMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAgFOwaNEiq0sAANRDQVYXAABAXRQTE+NxnJiYqJkzZ2ro0KEWVQUAqK8IZgAAVCI7O9vqEgAADQRTGQEAAADAYgQzAABOwd69exUXF6c5c+ZYXQoAoB4hmAEA8JuMDCkiQgoIkD7/3HlcUfv27bVgwQKNHDnS5/UBAOov1pgBACBnCEtIkAoLncdFRdLdd6dq8WKHLr7YrsLCQiUkJFhbJACg3iKYAQAgKSnpRChzSlNJSYFycgyNHx+kli1bKjQ01KryAAD1HMEMAABJ+fkVW7pLkvbskS691OflAAAaGNaYAQAgKSzs1NoBAKhJBDMAACSlpEjBwe5twcHO9vKysrJ8VxQAoMEgmAEAIMlmk9LTpfBwyTCcr+npznYAAGoba8wAAPiNzUYQAwBYgxEzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAagNtvv93n75mTk6Pk5OST9lu0aJEPqgGAui3I6gIAAEDN6dmzp1q3bi1JOnz4sIYPH67ExETt27fP1efjjz/Wyy+/LEnKy8uTaZqKiIiQJI0dO1bXX3+9x33feOMNSdIDDzzgcW7JkiV66aWXJEkFBQUaPHiwJk2a5NEvJibG4zgxMVEzZ87U0KFDT/mzAkB9QjADAKAeCQ0NVVZWliTniNWqVas8+gwePFgDBw7UJ598oszMTJWWlur222/XkCFDFBDgOZnG4XDos88+k2EYuv/++z36REZGasyYMZKk77//XsePH9fq1au1YcMGj3tlZ2fXxMcEgHqHqYwAUIuOHj2qZcuWebQvXLiwyuPKMOULp8s0Tb322mv67rvv9Pbbb2v8+PFyOBxKSkrSxIkTVVJSooceekjTpk1zu66wsFBjxozRvffeq1GjRumBBx7QkSNH3PosX75c69evV8eOHdW/f38lJCTowIEDKigo8OVHBAC/xogZAFTDhRdeqPbt27u17dq1Sz/88IMk6aGHHnJ9/fXXX2v//v2KjY3VW2+9pTlz5qhfv35u16alpWnYsGGVHjPlC7WhS5cuatmypXr06KEePXpIkt5//33Z7XYNHjxYd911lyRp3759ateunSZPnqwNGzboiSee0CWXXCJJCgsLU0JCgrp27arnnntOktS2bVvl5OTogw8+kGmaatKkiW655RYFBwdr5cqVJ61r7969iouL00033aSRI0fW0qcHgLqNYAYA1RAaGqrXX3/dre3BBx90fT1z5kzX14MGDfJ6jw0bNmjy5MmSpMaNG2v48OGSpD//+c9e+zPlC6cjODhYQ4YMkSQVFRW5Nv0wDEOxsbH6+eeftXHjRlf/8PBwSXJra9u2rdq1a6dx48YpJCTE7f4XX3yx3nvvPRUWFrrahgwZ4nrP8ux2u3r37n3Smtu3b68FCxZU/0MCQD1EMAOAaoiPj/cISnfeeack6fjx41q1apV+/fVXHT16VLt37/Z6jwsvvFCZmZnKysrSmjVr1KNHD91www0yDKPW60f9lpEhJSVJ+flSWNi/lJT0i+67r6XXvuedd55CQkJks9k8zjVv3twtIFUMZeUFBwe7Ha9cuVLFxcW69tprXW2bN2/Wt99+q1tuucXVlpqaKofDIbvdrsLCQiUkJFT3YwJAvUYwA4AqLF26VCkpKZWenz17tsaNG6edO3eqdevWatu2rVq0aCFJ2rNnj5588kkFBga6+k+fPl1HjhzRiBEj9Omnn2rChAmu3fF2796tkJAQ1/XeMOXrzO3YsUO7du1SVFRUpX0WLVrkN1NGMzKkhASpbAArL08aPfpGBQdnq3z2Kv+LhXPOOcfriGz5KbTLli3TlClTqnzvCRMmaMCAAZKk7du36/nnn9e5557rOl9QUOAxZbegoECGYSgoKEgtW7ZUaGjoKX1eAKivCGYA4MWJEYj+Cgvrr6SkAt1yi+laj3PHHXfIMAy1atXKdU18fLymTp2qs846S5JzetbTTz+tF154wdVnyZIlrh3zxowZo9jYWEnOXe+mTp2qvn376oYbbqi0LqZ8VV/ZaEx+fr7atGmjt956S23bttXmzZu1cuVKRUVF1Yu1fElJJ0JZGYfD2e5lUKza+vXr57E28mQef/xxxcfHu45XrlypnJwc13H37t1PvyAAqOcIZgBQgbcRiIceekOfflqk3//e2TZjxgy9//77XrcDnzNnjiTnmp6K07169eqlzMxM3XbbbcrOzlanTp0kSQEBAZoxY4ZbX6Z8nZlXXnlF1157re655x4tX75cEydO1KxZszz6+ftavvx8b62Fysvrpeho9+mMaWlpuvjii13HmzdvVmlpqSIjIyVVvj6yul5++WXNnTvXdVxxxAwAUDmCGQBU4G0EoqRkpT755FcdPHiirWzL8BUrVigtLU25ubmy2Wxq3Lixbr75Zq/3njx5stLT03X//ferW7duevXVV732Y8rXmfvvf//rGl289tpr9eKLL1pb0GmIiYnxCI6xsbGuUVe73a6QkAf1668/SbJLulXSQ5JeUqtW2crJmSRJSklJ0dKlS/Xwww+rtLRUjRs31pIlS7R27VoVFRW5gtnYsWNd77Ns2TIFBgYqOjq6WrUOHz7ctaHNqSr7PADQkBHMAKAC7yMQdhUX56jcrCyXq666Sr169VJQUJCaNGnievjuvHnzPPoGBQW57eZYGaZ8nTnDMNzW95X/+mRqYy3ff/7zH1199dUn7bdw4ULXKNOWLVs8gtH27dtdX8+ZM0fXXx+pBQvSVVhoSrpF0kA1aSJde6108OBBjRo1SkeOHJFpmrrvvvvUtWtX3X333dq2bZsk58js7NmztX79el188cUKDQ1VZmamtm3bpqAgfkwAAF/hv7gAUEFYmHP6orsNatw4WhUHD9566y116dJFjRo18lF1qK7mzZvr4MGDatOmjUpKSuRwOKp9bU2s5RsyZIgWL17sOn7uuedco1+xsbGy2+2SpGbNmmnRokWukbDyz7Rr27atxo8f73bf8msWHQ6HYmPbadAgKSnJUF7e2erQwaF775UCApyha/To0RowYIAcDoeuu+46XXrppQoLC3PdY/z48YqPj1ePHj3c1oMBAHyLYAYAFaSkuK8xk6Tg4Hylp5/aZgpl07Nmz5590r7VXefElK+qld82vn37BN1ww3i9++4zeuONN1zP86qoNtbybd++Xfneh15dqvN3npqaquPHj7u1lZ+SOXLkSD388MMqLl6uP/6xWGPGXKLx47to5crdys52htOyAGiapkpLS7V69Wqdd955bvdcvXq19uzZo88//1xr167V8uXLlZ+f7za1EQBQuwhmAFBBWfg68VwoZ1g7kx3uUPsqbtqyZ0+0Dh+WHn74Dd17b2/FxcV5XFNba/lmzJih3//+95o3b57rGV6lpaWKjo52hZ1ff/1VktSoUSM1adLE9Rk+/1wyjKVq0iRFnTtL55zj/T3GjRun3r17Kzk5WSUlJbLb7Tp+/LjWrVunoqIiSdJjjz2m559/Xm+88YZCQkJUWFiozMxMJScna/z48TrnnHPUs2dPvfDCC/r888/18MMPKyMjQ4888ki1fqEAAKg5BDMA8MJmI4j5G2+bthw/Hq3166PlJZNJqvm1fHa7XVOmTFGHDh2Umpqq8ePH66efftITTzyhwMBA1yjZ66+/rtGjR0uSevfurYceekhffvmtsrPjVFoqSf11/Hh/5edLEydKTZrM1/79+13XSNJPP/2kyZMnKygoSBs3blSjRo0UFNRLy5c31eHDXdWypV0tWuxQfHy87r//fm3fvl0PPfSQDh8+LMk5Gpedna20tDS9/vrr6tatm2bOnKn4+HjNnz+/Rv93AQCcHMEMAFAvVDZz8CQzCs9Y+emTHTrs0y23XKynn46T5Aw/3377rQzDUOfOnd2uK7+tvCQdO9ZDpaXzJcW62goLH1FS0qtKTfV83/PPP9+1q+fs2bO1enWQ/v73Eb+F05X65ZdCPflkhlavDlKzZs3Uv39/maapg+W2Fm3evLnuuusunX/++Tp69KguuOACffzxxzXxPwsA4BQRzAAA9YL3TVuc7eVFR0efdAv46q7lqzh9cseOc5WeHqff/W6T1q59VgcPHpRpmgoJCdGTTz7pdm1RUZFrXVurVq1UVGTI89vyBuXnSwMHDlSpcyitUvPmVRwxbKmSkmf12WfjVVDwiVvff/zjH66v27Rpo1mzZikmJkZ9+vRxtZd/UDQAoPYRzAAAlvj222910UUXVdnn8OHDKikpUbt27arst2jRIqWkDPWyaYtzfWBt8TZ9srBQmjjxbq1b9zd169ZNkrR7924NGzZMK1asUNOmTRUdHa17771XjRs3VosWLfTnP/9ZTZtKvy0NK2edmjSJUcVnNL/zzjuuh5OXOXDAe42//PKtR9tbb70lSVq1alV1PyoAoJYRzAAAtapnz55q3bq1JGfQGj58uBITE/Xoo4+61lwdPnxYCQkJOnTokEpKSjRp0iRFR0crJydH27dv15gxYyQ5H7hcXkxMjBITEzVz5kxlZQ2V5NtNWyqbJnn8eLFatmzpOg4JCXHtiihJiYmJHtdccIH0008Vg+W+au0GGh8fr0mTyo8Y9vntj9S0qbyOECYlJbkeCD1p0iQ99thjatWqlVufQYMGsTMjAPgIwQwAUKtCQ0NdUwNzcnK8jtI8//zzuuuuuzR48GD98ssvGjBggL744guv96tqm3lfb9pS2fTJ0NBZuueee1RcXCzTNGUYhp5//nmFhIRUeq8OHaQnnpBGjZKOHz/1YOn9MQ9SenrWSe8xadIkTZo0qXpvBACoFQQzAKinYmJiqv18NCuYpqnU1FT1799fW7ZsUd++fSVJLVu2VKdOnVRYcY5gHVRZGEpNvVQ226endK+y8Gqznd7fGY95AAD/FmB1AQCA+s3hcGj//v3av3+/CgoKXO2GYahPnz4699xzddNNNyk5OVmHDx/WihUrFBAQUOXoUkV79+5VXFyc5syZUxsfoVI2m5SeLoWHS4bhfD3VB5HXdD1bt0oOh/OVUAYA/uOMRswMw3he0p9+u0+CaZrf1UhVAIAzdvToUY81WZI0b948nXXWWbX63uW3kG/Z8grdfHOiunRxnrvppptc/a688kpJks1mU1ZWlpKTkxUWFnbKDzdu3769FixYUEPVnxqeeQcAqAmnHcwMw7ha0jmmafY1DOMiSS9LGlRjlQEAzkhla7RqW8Ut5AsKnteaNdJ990ldu67Rtm3bvF4XGxuroKAgde/eXc2aNdORI0dUUlLi2vijTGpqqhwOh2ur+YSEhNr+SEC1LFy4UMMqbqFZwaJFizR06FAfVQTAn5zJiNkASe9Jkmma3xqG0aZmSkJDtmnTJjkcDkVGRlba57HHHtNf/vIXH1YF+IeyUaq8vKVq0iRFnTtL55zjvW9iYqJiY2O9nzxDlW0hn5QkRUfP1JYtWzR06FCv69/mzp2rQYMG6dZbb9UPP/ygWbNm6ZZbbnGdT0tLU0FBgQzDUFBQkFq2bKnQ0NBa+RyAN+vWrdO4ceO0fv16XXzxxdqwYYO6d++uF198UWlpaa5gVtUOogQzAN6cSTBrL2lfuWO7YRgBpmk6yhoMw0iQlCBJYRWf8IkGbcCAASouLtY333yj3//+9woNDVVmZqa+/PJL2e12RUZG6pJLLtHZZ58tSTp06JBuueUWJSYmav369RZXD9Q97qNU/XX8eH/l50sTJ/p+mp33LeQLlZf3lCIjI3XDDTfIZrPplVde0bnnnuvq8d133ykwMFDvv/++IiMjNWPGDJ111ln697//rT/96U+SpO7du/vmQwCV+MMf/qDs7GwNGDBAS5Ys0a233qp33nnH65rIurz5DoC650w2/yiQVH6RgqN8KJMk0zTTTdOMMk0z6mQPB0XDsmTJEmVlZalJkyZatmyZ+vfvr+joaKWUexLsOeeco+zsbGVnZ2vatGlu12/cuFGHDx/2cdWAu127dunLL7+sss+iRYt8Uov3UaqRSkryydu78fw93MeSblP79kOVmJioYcOGafLkyZowYYKmT58uyRnKJk+erOnTp2v27NmaNm2ahgwZooyMDL3zzjvKzc319ccAKlVYWKiNGzdKkvbs2aO9e/daXBGA+uBMRsz+I+lmSf8xDONCSdtrpiQ0FK+88oomTpyoKVOmaOLEibr33ns1d+5c2e32Kq8zTVM5OTn605/+5HpoLVCb5s6dqylTpriN7rz88ss6evSosrOzdfnll1s+bcn7KNW+Sh+AXJs8t5AfrODgwfotg0mSIiMj3XZQ7NGjh9577z0FBDh/X/i3v/1NgYGBkqR33nnnpO9ZttU84AtffvmlmjVrps2bNys/P1+rVq1S586dJUlxcXFuG9xUVLaD6E033aSRI0f6qmQAfuBMgtnHkgYZhvEfSUck3V8zJaG+Ky4u1ksvvaQ2bdrowQcfVGZmpkaNGqVZs2a59bv22ms1fvx41/HgwYMlObfYHj16tE9rBh5//HHFx8e7ta1cudLt2MppS94fdLxPjRtHKzravXXevHmqzVkMp/s8rbJQJskVyoC6oPwuo2FhUpcu72vu3LkaNWqUEhIS9NFHH+n222+XJNfuoO+++67Xe1m5gyiAuu20g9lv0xYfqMFaUM+d2JigVO3bX6bp06+TJA0fPlzXXXedgoKC1Lp1a5WWlkqSJkyYoH/+85+uHdzWrl2rtWvXatAgNv8EKvL+oOO1lj1Tiy3kUV9U3GU0L2+DduwwtWnTZWrbtq3uueceZWZmat68eR7XsoMogFNxRs8xA6rL/RtbM+3de53uu69U8+Y9qwMHVigoKEh2u119+/bVc88957quW7duOqfCtnJPPPGExo4d69sPgAZvwYIF2rp1q+s4Li6uWtf5atrS6Y5SAaia5/rNLrLbX1Ri4l7dcUcXnXPOOXr44Yf1n//8x+06dhAFcKoIZvAJbxsTHDuWrpwcQ4cO/VuGYcg0TT333HN64403XM8tmjNnjtatW+d2XfkfjgFfGDx4sC666CJ98sknstvtuv766xUWFqYNGzac9FpfTltilAqoeZ7rNBtLaqwdO1rqxRdflOSchtu3b189//zzrl7sIArgVBHM4BPeNyAwVFDQXIZhOI8MQyEhIa5jyblTG9sNw9cqridJSTlLNttZ+vbbb2W329WzZ0+v1zFtCah/vK/f9Lb7KACcGYIZfML7N7b71LLlRF1zzTUKCgpSaWmpLrvsMrct80tKSjx2u5OkGTNm6KKLLqrdotEgea4nOaK7735bWVmSw7FGx44d05YtW3T06FG3f5tMWwLqJ+/rN53tFVXnF4nsIAqgMgQz+IT3b2yBev31KVVOvVq2bFntFweU4znttqlKSi5TdnagFi++Wo0bN1aTJk0UEhKin3/+2dWLaUtA/cT6TQC+QjCDT/CNDf7Cc9ptI0l/1J490qWXup/ZsmWLj6oCYCXWbwLwBcM0TZ+8UVRUlJmbm+uT9wKA0xUR4X09SXi4VJ/3nTl69KhWrVqlfv36WV0KAAD1lmEYa03TjPJ2LsBbIwA0VCkpzvUj5VW2nqQu6tatm2JiYtz+lD34VpJiY2M9romNjdWhQ4c0Z84cX5YKAADKYSojAJTj79NuO3XqxE6mAAD4IYIZAFTQENaTHDp0SO+++64kqbS01OJqAAAAUxkBoAFq0qSJevbsqZ49e7o9OxAAAFiDETMA8FOeD8KWzjrrLEVHR3v0/fTTT9WsWTPXcXBwsKvf1KlTfVQxAACoDMEMAPyQ54Owncfp6fNOOg1z1apVstvt+vXXXxUV5XVjKNSCn376SXa7Xd26dfN6/q677nJNL5Wkjz76SMePH9ctt9ziqxIBABYimAGAH/J8EPZSFRam6N57pTff9H5NYmKi4uPj9X//939q0qSJWrZsqV69evmi3Abr008/1bRp0yRJ27Ztk2maCgsLkyQ9+uijGjJkiO677z4dOnRIK1eu1M033yxJeuONN1RYWKiioiLLagcA+BbBDAD8kOeDsPtL6q/iYiknx/f1wLuBAwdq4MCBKikp0cCBA2W327V48WI1bdrU1eeVV16Rw+HQ4MGDNXv2bElSSEiIRRUDAKzC5h8A4Id+G3Spdjuss2bNGg0ePFjx8fEaM2aMBg4cqE8//VR2u12Sc71f06ZN9f3332v79u367LPPNHDgQNb+AUADY5im6ZM3ioqKMnNzc33yXgBQ31VcYyY5H4Sdnl7/t/r3J2PHjlVJSYnGjx+v8PBwSdK+ffv0+uuv68iRI0pNTZUkvfjiiyosLFRubq4++OADNW3aVJmZmSoqKlJ8fLyFnwAAUJMMw1hrmqbXBd5MZQQAP+TvD8Kuz9x3y5yulBTpt0wmSWrXrp2effZZSVJJSYmmT5+un376Senp6frss880aNAgvfPOOxZVDwCwCiNmAADUEPeRzKWSUhQQIHXtKkl7ZJqmQkNDXf3Hjx+vw4cPa8iQIWrUqJFCQkK0d+9etW3bVu+//z4jZgBQz1Q1YkYwAwCghkREOB9dUFF4uJScPFd2u91r0Jo1a5batm3r2pURAFA/VRXM2PwDAIAa4rlbZtXtAACUYY0ZAAA1JCzM+4hZdXbLnDx5smbNmuXWdt111+nxxx+voeoAAHUZUxkBAKgh7JYJAKgKUxkBAPABm80ZwsLDJcNwvhLKANR1+fn52r59e5V9Fi1a5KNqGi6CGQAANchmk7ZulRwO5yuhDEBdExsb63a8fPly5eTkSJJiYmLc/pQ97H7mzJm+LrPBYY0ZAAAA0ECUlJToyy+/1LFjx9SsWTOvfbKzs31cFSRGzAAAAIAGIy0tTXFxcXrqqaesLgUVEMwAAACAeq60tFR/+ctftGvXLv3tb39Tr169dO+996qoqKha1+/du1dxcXGaM2dOLVfacDGVEQAAAKinMjKkpCQpL8+u9u27a/r0xyRJI0eO1IABA9S0aVOdf/75CgwMrPI+7du314IFC3xQccNFMAMAAADqIfdHeDTR3r2xuvPOoRo3bqMuuihckrRv3z6FhIRo/PjxrutSU1PlcDhkt9tVWFiohIQEaz5AA0MwAwAAAOqhpCT35ypKksOxSAUFscrOzpIkJScnKzo6Wn369JHkXINWUFAgwzAUFBSkli1bKjQ01NelN0gEMwAAAKAeys/33l7VsrLu3bvXTjE4KYIZAAAAUA+FhUl5eeVbdksaroCAbxQdHS1JysvL0wcffKA77rhDjz/+uAVVogzBDAAAAKiHUlLKrzGTpFAFB+coPV2y2U7tXllZWTVdnmXuuusuvfvuu1aX4YHt8gEAAIB6yGaT0tOl8HDJMJyvpxPK/NX333+vgQMHqn///oqLi9POnTslSXv27LG4Mu8YMQMAAADqKZut4QSxisaOHau3335bHTp00DfffKMnnniiTj+HjREzAAAAAPVOUFCQOnToIEn6/e9/r8OHD7vOrVy5Urt27bKoMu8IZgAAAADqncaNG7umL37zzTfq1KmT69yqVavq3JRGpjICAAAAqBcyMpzPb8vPlzp0mK7bbntSEREONW/eXFOmTHH1K/9A7bqCYAYAAADA72VkuO9CuWNHuA4ceEajR5/vF+vsDNM0ffJGUVFRZm5urk/eCwAAAEDDEhFR8bltkhSj8PBsbd3q+3q8MQxjrWmaUd7OscYMAAAAgN/Lzz+19rqGqYwAAAAA/F5YmLcRs91q3Dha0dHurVOmTFHv3r19VFn1EMwAAAAA+L2UFPc1ZpIUHPyt3zxUm6mMAAAAAPyezSalp0vh4ZJhOF/9JZRJjJgBAAAAqCdsNv8JYhUxYgYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAT5w9OhRLVu2zOoyAAAAUEcRzIAadPvtt6tPnz7q2LGjYmJitGTJEsXGxurQoUOaM2eO1eUBAACgjiKYATXovffe09y5czVkyBBlZ2drwIABVpcEAAAAP0AwA2rYL7/8oiNHjlhdBgAAAPwIwQyoYevWrdOGDRtcx0eOHNFHH31kYUUAAACo6whmwBnKyJAiIqSAAOfrjBnz1bt3b61bt06SZJqmSktLLa0RAAAAdRvBDDgDGRlSQoKUlyeZppSX94HWr4/SxRc/p+TkZJWUlKhly5a64YYbrC4VAAAAdViQ1QUA/iwpSSosLDs6Iuk9lZS8pxdfbKS//e0B/fvf/7awOgAAAPgLRsyAM5CfX/6ohaT5khopP1+69tpr1a9fP2sKA4AGYuHChSfts2jRIh9UAgBnhhEz4AyEhTmnMXprBwDUnEcffVRff/21JKmwsFBXXHGF0tLSlJaWpmHDhkmSYmJi3K6JiYlRYmKiZs6cqaFDh/q6ZAA4JQQz4AykpDjXmJ2YzigFBzvby2RlZUmSZs+e7dviAKAemTFjhuvrDz/8UDt27PDaLzs720cVAUDNYiojcAZsNik9XQoPlwzD+Zqe7mwHANSOTz75RIMHD7a6DACoUYyYAWfIZiOIAYCvfPXVVzp27Jg6d+4sSXI4HIqLi9NVV11V6TV79+5VXFycbrrpJo0cOdJXpQLAKSGYAQCAOicjw7nzbX6+c91uSorUp0+eEhMTlZmZ6eoXEBCgBQsWSJKWLFni9V7t27d39QGAuopgBqBO+vTTTzVt2jRJ0s6dOyVJHTp0kOTcBGDIkCGSpFtvvVUHDx50u3bz5s3K87YrCwC/UPaMyLL1u3l50j33/Etdu87Sv/41U23atKn02tTUVDkcDtntdhUWFiohIcFHVQPAmSGYAaiTBg4cqIEDB0qSnnzySdntdr388sse/d5//32PtptvvrnW6wNQe9yfESlJJSou3qyCggW64ILgSq9LS0tTQUGBDMNQUFCQWrZsqdDQ0FqvFwBqAsEMQJ22ZcsWffXVVyotLdWWLVtc60qq4nA4fFAZgNri/oxISWok6Qlt3171dd27d6+ligCg9hHMANRZubm5euKJJ/Tuu+/K4XDorrvu0gsvvKDevXtr6dKlSin/XIJydu3apejoaCUmJio2NtbHVQM4UzwjEkBDZJim6ZM3ioqKMnNzc33yXgD8U/nF/iEhD+iKKwz9619TtX//fjkcDrVv315PPvmkSkpKlJ6ebnW5AGpJxTVmkvMZkTyOBIC/MwxjrWmaUV7PEcwA1AWeP4g5FBwcoPR0yTTnym63Kz4+XpJkmqYMw5Ak9ezZU23btnW71/bt27Vx40bfFQ+gxnnblZFQBsDfVRXMmMoIoE7wXOwfoMJCZ3tysnvfslAmSW3btlV2drbbeaYvAv6PZ0QCaGgIZgDqBPfF/sskTZHkXGcye7azde7cua4eEyZM0IABA3xVHgAAQK0imAGoE9wX+/f77Y8UHi5VGBBzk5+fr+joaLe2n3/+uTZKBAAAqDUEMwB1QkqK98X+lWy86LJp06baLQwAAMAHAqwuAAAk51qS9HTnCJlhOF/ZgQ0AADQUjJgBqDNY7A8AABoqRswAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDAAAAAAsRjADAAAAAIsRzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAAAAACxGMAMAAAAAixHMAAAAAMBiBDMAAAAAsBjBDACq4ejRo1q2bJnVZQAAgHoqyOoCAKAuyszM1OHDhzV69GhJ0qFDhzRnzhz169dPBw8e1I033uhxzaZNm7Rz505flwoAAOqBkwYzwzAiJK2R9FO55haSxkh6RlIzSbmmaY6pjQIBwJfeeecdrV69Whs2bFBJSYm+/vpr9e7dW/369XP1adOmjXJycjyujYmJ8WGlAACgPqnuVMaPTdO8suyPpF2SCiT1++34HMMwLqu1KgHAR+6++27NnDlTbdq0UUhIiKZNm6a77rqrWtcGBDA7HAAAnJ7T/inCNM2vTNN0/HZ4SNLRin0Mw0gwDCPXMIzcffv2ne5bAYDPfPPNN7r99tv1wAMP6MUXX9Tw4cOVkZFRaf+yqY4SwayhGDt2rHbv3m11GQCAeuaMf4owDOMGSUWmaW6oeM40zXTTNKNM04xq167dmb4VANSKjAwpIkIKCJBiYn5W376vKiQkRIcOHdKHH36oyy6rfELA1q1bXV8TzPyLt6mnsbGxrq/j4+N19dVXKyYmRjExMa6R04MHD8put/usTtQdBw4c0LPPPqvrr79e119/vZ555hkdOHDgpNfl5+dr+/btPqgQgD877Z8iDMNoZBjGi5LONU3zkRqsCQB8JiNDSkiQ8vIk05T27YvThAmhyszcrq1btyooKEhdu3at5r0qH1mDf3rvvfeUnZ2t7Oxsvfvuu1aXA4uNGDFCl156qTIzM5WZmanLLrtMd9xxh0e/IUOGuB0vX77c67pUACjvTHZlTJb0iWmaK2qqGOBMXHnllVq1apXVZcDPJCVJhYVlR7skzVZhYaneeWedoqMLtWnTJhUVFem6666TJC1dulQpKSmu67/55htFR0e73TMxMdFt5AV104YNGzz+7jZv3lyta19//XVdd9116tu3by1UhrrqyJEj6tOnj4KDgyVJf/zjHzVlyhS3PiUlJcrNzZXdbldQEJtfA6i+6v4XY4hhGLnljptJGiLpCsMwytrSTdP8R00WBwC1LT+//FFrSddJClRhYZymTQtSs2bNFBwcrKNHj2revHnq37+/+vfvb0mtqFkXXnihsrOz3doqBurS0lKVlJTIbrerqKhILVu2lCT17t1b5513ns9qRd3wl7/8RSNGjJDD4ZBpmgoMDNQrr7zi1ufVV19Vv379lJKSomeffdaiSgH4o5MGM9M0t0pqW/ulAIDvhYU5pzE6NZPUS5IUHi5FRp7od/z4cV+XhhqUkeEcHc3Pd/6dp6RIv/76q6Kjo/XLL7/INE21atVKRUVFrmsuu+wyjRs3ToGBgQoKcob05ORkSdIll1yijh07WvVx4GP79+/Xjz/+KEl65pln3M6VlpZq1apV6ty5szIyMrRv3z5lZGTo9ddf14MPPqi//OUvVpQMwA8xxg6gQUtJca4xOzGdUQoOdraX17FjR82ePduntaFmlK0jLPs7zstzHqenr5LNJs2dO1d2u13x8fFu1z300EO68cYb1a5dO6akNVBlgT4v75DatPlaw4ZJl1/uvW+zZs104YUXauzYsZKkBx98UDt37lSTJk0UGhqqwMBAH1YOwB/xnQZ+q+JvwPm5CafDZnO+VhxNKWuH/3NfR+hUWOhsP9nf85NPPqnk5GS30TECesPgHugv0MGDF+jvfx+mL74o0DnnnOjXvHlzLV68WJL0hz/8QQ8++KA2bPDYqFpJSUm+KRyA3+JHWfglb78BDw5epYwMfqD2ZwsXLtSwYcOq7LN161bl5+frT3/6U429r83Gv5v6zH0doSQtlZSivDyp/N4f5QMXG7jAW6AvLT2uY8dyVH6DxYqPXXj99dc97jV79mzt2bOnFqoEUJ8QzOCXPL9hlqqwcIKSkqbxA7YfePTRR/X1119LkgoLC3XFFVcoLS1NaWlprmCWnp6uf/zDuZ/Q4cOH1bdvX73yyivaunWrVq5cWaPBDPWb+zpCSeovqb/Cw6Xq7GB+yy23qEmTJm5tSUlJbAJTz3kG+qrbAeBMEczglzy/MQZKmsY3TD8xY8YM19cffvihduzY4dEnISFBCQkJkqTnn39eHTp0UExMjA4dOqQbbrjBV6WiHqjuOkJvmLbYcHkGeknapCZNYlR+kGzTpk0nvVfbtm1ZYwbgpAhm8Evev2E62+FfPvnkEz311FOVnl+/fr2++uorTZw4Uffee69ycnK0cuVKH1YIf8c6QpwO74H+Z6Wnn/q/nYoPnAYAbwKsLgA4HSkpzt94l1fd34Cj7vjqq6907Ngxde7cWZLkcDgUFxenl156SZK0YMECTZkyRXPmzNF3332nmJgYjRs3zsqS4adsNmnrVsnhcL4SynAyNpuUnu58dIZhOF9PJ5QBQHUxYga/xG/A/Yu3Z0j16ZOnxMREZWZmuvoFBARowYIFrq3Le/furb///e8KCgrSRRddpOzsbK1fv97rjmcAUNPYGAiALxHM4Lf4hukfvO2gec89/1LXrrP0r3/NVJs2bTyuCQoK0uzZszV16lSPHc9KSkp01113+aJ0AAAAnyGYAahVnjtolqi4eLMKChbogguCK7tMknPL8sTERLc21pgBAID6iGAGoFZ57pTZSNIT2r7dgmIAAADqKDb/AFCrKtsp83R30GzUqJGCK+78AlRh2bJlyjnJA8vy8/NP2gcAgNpEMANQq05lB83s7OyT3u+Pf/yjxo4dW0PVoT6KjY11O962bZu2/zZEO3v2bEVHRys6Olq9evXS6NGjJRHMAADWYyojgFrFDprwtZ07d1Z6Lj4+XvHx8ZKkKVOmqG3btoqOjlZBQYGGDRvmowoBAPDEiBmAWsczpOAr69at05YtW7RmzZoq+3333Xf64osvNGrUKOXk5CgtLc1HFQIA4B3BDABQL5SUlOiZZ57RihUrNHHiRB08eNBrv48//liTJ0/Wu+++q02bNik6OloPP/ywj6sFAMAdwQwA4JcyMqSICCkgQAoLK9CVV96sMWPGqFevXnrllVc0YsQIFZZ7VoPD4dCdd96pb7/9VnPnztVZZ52lbt26KScnR6+//roaN25s3YcBADR4rDEDAPidig8u37atlfbte0X5+e1UXFysyMhIffzxxzIMw3VNQECA/v73v+v48eOaMGGCvv76awUFBamkpERXXnmlkpOTLfo0AABIhmmaPnmjqKgoMzc31yfvBQCo3yIipLw8z/ZWrZK1YEEfRUdHV3ptcnKy2rRpowcffNDV9vLLL6tRo0Z69NFHa7xWAADKGIax1jTNKG/nmMoIAPA7ng8udyooOPm15UfRyjgcDgUE8C0RAGAdRswAAH6nqhGz88//UGeddZZb+6BBg1zPvzt+/LgSExPdpjJeccUVSklJUVAQM/wBALWnqhEzghkAwO9UXGMmOR9cnp7O4xgAAHUXUxkBAPWKzeYMYeHhkmE4X/09lO3YsUNffvlltfr997//9UFFAABfYs4GAMAv2Wz+GcSefPJJffHFF/rxxx/1u9/9Ts2aNdOMGTN0+PBh5eTk6PLLL3f1fe6557R8+XIFBQUpNDRUb775prZs2aLs7GxdddVVFn4KAEBNI5gBAOBDU6ZMkSTdfvvtevDBB3X11VdLknJyctz6ff/999q8ebNWrFghSXr99deVkZGh7t27+7ReAIBvMJURAAAf+/nnn7Vv3z5NmzZNJSUlXvuEh4frl19+0ccff6x///vfWr58uXr37u3jSgEAvkIwAwDAh3JzczVu3DhlZmbq4Ycf1o033qiNGzd69AsODta8efNkGIZ27NihF154Qa1atZLD4bCgagBAbWMqIwAAtSwjQ0pKcj5/7eyzN2vq1Llq2zZE/fr104UXXqgmTZro2LFjCgsLk+Tc0n/06NEKDAzUwYMHtXv3bl1zzTVq3ry5LrnkEos/DQCgNhDMAACoRRW39t+//3aNHv2kUlO/0DnnuPeNj4+XJDVp0kTvvPOOJGnVqlXKysrSHXfcoenTp2v16tXq2bOn7z4AAMAnCGYAANSipCT3561Jkt0+RceOSeX3+8jJyfHYAGTMmDG68847dfnll6tjx4569NFH9dVXX2nTpk21XjcAwLcIZgAA1KL8/FNrL+/w4cMKCwtzbaEfGRmpyMjIGqwOAFBXEMwAAKhFYWFSXp739vJatGihDh06ePS79dZb1bhxY7e2Xr166aWXXqrJMs/IsmXLFBgYqOjo6Er73H777Xrvvfd8VxQA+BmCGQAAtSglxX2NmSQFBzvby7v00kt16aWXurXNnTvXBxVW34ABA1RcXKz169fr4osvVmhoqDIzM7Vt2zYFBTl/pIiNjVVWVpYk5/TMVatWKTExUfv27bOydACo8whmAADUIpvN+Vq2K2NYmDOUlbX7kyVLlkiSevTo4bEerkxpaam2b98uSYQxADgFBDMAAGqZzeafQcyb1atXa8+ePfr888+1du1aLV++XPn5+Ro7dqwkqaCgQKmpqZKk7du3KyoqSpJkmqZee+01XXPNNerRo4dl9deGzZs3q7S0tEbW/y1atEhDhw6tgaoA+BuCGQAAqJaioiK98MIL+vzzz/Xwww8rIyNDjzzyiGbPnu3q06ZNG82YMUPSiamMZSIjI9W6dWvfFl2DUlJStHTpUknOkcHg4GB99tlnWrt2rYqKilzBbNCgQSouLna79n//+58OHDjgOo6JiXE7HxMTo8TERM2cOZNgBjRQBDMAAOBV+Qdj/+53h3T22SM0c+ZT6tatm2bOnKn4+HjNnz/f7ZqCggLdfPPNkqQDBw5o8ODBkiTDMDzCiL9JSkpSUlKSJOnLL7/UnDlzvPb75JNPPNq8ffbs7OyaLRCAXyOYAQAADxUfjL19+1nav/+v+vrrIPXseVQXXHCBPv74Y4/rvvjiCx9Xao3Fixfr+uuv93qushEzAKgKwQwAAHjw9mDsoqKOSkqapD/8IUZ9+vRxtcfHx7v1u+666/TZZ5+5tdWn0aFt27bp888/13PPPef1vMPhOO3Pu3fvXsXFxemmm27SyJEjz6RMAH6GYAYAADxU9gDsgoKTX1taWlqzxdQhhw4d0v3336+3335bhmF47bNu3TqvUxdffvllXXLJJVXev3379lqwYEFNlArAzxDMAACAh8oejN2qlfTYY4+pVatWbu2DBg1y7czocDi8BpMZM2booosuqpV6a0P5NXZhYdKdd67UF188p+TkZEVERFR63a5du6p1/9TUVDkcDtntdhUWFiohIaGGKgfgjwhmAADAQ2UPxp45c5JstklVXrt8+fLaLc4HKq6xy8uTpk79r1555R+64op2Z3z/tLQ0FRQUyDAMBQUFqWXLlgoNDT3j+wLwXwQzAADgoT49GPt0eFtjV1IyQS++KD3wgPdrli1bpilTplR53wkTJmjAgAHq3r17DVUKoL4gmAEAAK/q04OxT1Vla+wqa5ekfv36qV+/frVTEIB6j2AGAABQQWVr7MLCPNuGDx9eY++blZVVY/cC4F8CrC4AAACgrklJca6pKy842NkOALWBYAYAAFCBzSalp0vh4ZJhOF/T0xvu1E4AtY9gBgD1xMKFC60uAahXbDZp61bJ4XC+EsoA1CaCGQD4mUcffVTR0dGKjo7W5ZdfrocffliSc/ttAADgn9j8AwD8zIwZM1xff/jhh9qxY4d1xQAAgBrBiBkA+LFPPvlEgwcPtroMAABwhghmAOCnvvrqKx07dkydO3eWJDkcDsXFxemll16yuDIAAHCqmMoIAH4oLy9PiYmJyszMdLUFBARowYIF1hUFAABOGyNmAFDHZWRIERFSQIDz9dFH/6X77rtPM2fOVJs2bawuDwAA1ABGzACgDsvIkBISpMJC53FeXolef32zZs1aoAsuCK76YgAA4DcYMQOAOiwp6UQoc2qkkpInNHkyoQwAgPqEYAYAdVh+/qm1AwAA/0QwA4A6LCys+u3Z2dm1WwwAAKg1BDMAqMNSUqTgCrMWg4Od7QAAoP4gmAFAHWazSenpUni4ZBjO1/R0ZzsAAKg/2JURAOo4m40gBgBAfceIGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMWCTtbBMIwISWsk/VSuuYVpmj1+O/8HSVmmaZ5bKxUCAAAAQD130mD2m49N04wvOzAMI7vcucclHazJogAAAACgITmjqYyGYVwv6StJRyo5n2AYRq5hGLn79u07k7cCAAAAgHrrtIOZYRihkh6Q9GplfUzTTDdNM8o0zah27dqd7lsBAAAAQL12usHMkDRL0jjTNO01WA8AAAAANDinG8xMSe0lPWMYRqakLoZhzKixqgAAAACgAanu5h9DDMPILXfcrGxXRkkyDGOVaZqP1mhlAAAAANBAnDSYmaa5VVLbk/S5sqYKAgAAAICGhgdMAwAAAIDFCGYAAAAAYDGCGQAAAABYjGAGAAAAABYjmAEAAACAxQhmAAAAAGAxghkAAAAAWIxgBgAATsmiRYusLgEA6p2TPmAaAADUP0uXLlVKSookaevWrTJNU507d5YkJSYmKjY2VjExMW7XxMTEKDExUTNnztTQoUN9XjMA1GcEMwAAGqBrrrlGHTt21Mcff6zdu3erUaNGOvvsszV06FB16dLF1S87O9vCKgGg4SCYAQDQAP3zn//UL7/8oltuuUXffPON7Ha7evfurWXLlunzzz/XPffcY3WJANCgEMwAAGhgli1bpnfeeUeS9MEHH2j37t0yTVPnnnuuq0/Hjh0rvX7v3r2Ki4vTTTfdpJEjR9Z6vQDQEBDMAABoADIypKQkKT9fCgvrp5SUfrLZnOdWrlyp0tJS9e3b1+2al156yeu92rdvrwULFtRyxQDQsBDMAACo5zIypIQEqbDQeZyXJ91zz0f6298+0QUXSL/++qtM09R7770nSRo0aJCuv/56SVJqaqocDofsdrsKCwuVkJBg1ccAgHqNYAYAQD2XlHQilJUpLr5eGzdeqM6dp2r37t2SpJCQECUmJuq8886TJKWlpamgoECGYSgoKEgtW7ZUaGior8sHgAaBYAYAQD2Xn++9fefOJ3TnnX/Wn/70J0nOKY0TJkzQ/PnzJUndu3f3VYkA0OARzAAAqOfCwpzTFytq3360nn32WQUGBso0TTkcDk2YMMH3BQIAZJim6ZM3ioqKMnNzc33yXgAA4ISKa8wkKThYSk+XawMQAEDtMwxjrWmaUd7OBfi6GAAA4Fs2mzOEhYdLhuF8JZQBQN3CVEYAABoAm40gBgB1GSNmAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAqDc2bdqkjRs3Wl0GAACnjOeYAQD8zj333KP8/Hz973//0yWXXCJJys7O1pdffim73a7IyEiLKwQA4NQQzAAAfudvf/ubJOlPf/qTsrOzLa4GAIAzRzADAPitdevW6dixY9qwYYPWr1+vL774Qr1797a6LAAAThlrzAAAfmnlypVq3bq1Fi9erJCQELVt21YtWrSwuiy/c/ToUS1btqzKPvPmzdOHH37oo4oAoGEimAEA/NL06dO1cOFCvfHGG+rcubOGDBminj17Wl1WnTVhwgTFxMQoJiZG11xzjSQpNjZWhw4d0pw5c9z6xsbGuh0fPXpUR48e9VmtANAQEcwAAHVeRoYUESEFBDhfb7ttiq666ir17NlTjz32mO6++24VFRVZXWad9tJLLyk7O1v/+Mc/1Llz5yr77ty5U5L0yy+/aPfu3SooKPBFiadt3bp1Gjp0qAYMGKABAwZo6NChWrdundVlAcApYY0ZAKBOy8iQEhKkwkLncV7eEe3cKV1//XhJ0tChQxUUFEQwq6YVK1bo6quvrvT8unXrtGXLFq1Zs0Zbt27V559/rg0bNujOO+/0YZXVZ7fbde+99+pf//qXwsLCJEn5+fm68cYbtWrVKgUF8aMOAP/AiBkAoE5LSjoRypxaqKTkSSUlnWgZOHCgWrdu7ePK/NNf//pX3XLLLZKkvLw8vf32265zJSUleuaZZ7RixQpNnDhR/fr104wZM3THHXdYVe5J5efnq3v37q5QJklhYWHq3r278vPzLawMAE4NwQwAUKdV9rM1P3OfXMUpoKNGvaVBgwapefPmkqTmzZurW7dukqSCggLdfPPNGjNmjHr16qVXXnlFI0aMUKF7Kq5zwsPD9eOPP+qLL75wta1cuVI//vijwsPDLawMAE4N4/sAgDotLEzKy/PeXtGIESNqvyA/4TkF9FPNnv2J3nlnvqvP2WefrT59+igrK0utWrXSK6+8onbt2qm4uFiRkZH6+OOPZRiGRZ/Au4wM5yhqfr7z30BKSqDefPNNDRw4UJGRkTJNU5s2bdInn3yiwMBAq8sFgGpjxAwAUKelpEjBwe5twcHOdlTOfQroAUkfqrQ0U08/Xfm3/oiICP3lL3/Rf//7X0lyhbL4+Pg6EXrLwmZenmSazteEBGn58tbq16+fli5dquzsbA0YMICprQD8DsEMAFCn2WxSeroUHi4ZhvM1Pd3Zjsq5T/U8W1K6pMZ+PQXUc72h8/ill6ypBwBqElMZAQB1ns1GEDtVpzIFtKJx48bprLPOcmsbNGiQxo4dW0PVnR7PULlUUop27JC2bpWio6NdZ8pG+BITEz2eywYAdZFhmqZP3igqKsrMzc31yXsBANDQVVxjJjmngPrzaGNEhPewGR7uDGYAUNcZhrHWNM0ob+eYyggAQD1UH6eAst4QQH3GVEYAAOqp+jYFtOyzuO/KWL8+I4CGi2AGAAD8Rn0LmwBQhqmMAAAAAGAxghkAAAAAWIxgBgAAAAAWI5gBAAAAgMUIZgAAAABgMYIZAAAAAFiMYAYAAAAAFiOYAQAAAIDFCGYAAAAAYDGCGQD40MKFC2ukjyQtWrToTMsBAAB1BMEMAGpBbGys1+O0tDRX24QJExQTE6OYmBhdeumlSk5O9ugjydWn7M/UqVMlSTNnzqzNjwAAAHwoyOoCAKCheumll1xf5+TkaOXKlZX2zc7O9kVJAADAIgQzAKgFpaWleuutt9yOK/rll19UXFwsSSooKPBZbQAAoO4hmAFALTAMQxEREW7HkuRwOHTzzTcrJiZG8+fPV2RkpKvP0KFDXX3i4uLUv39/PfTQQ5W+x969exUXF6ebbrpJI0eOrJ0PAgAAfIJgBgC1ICAgQDExMa7j1NRUV/v8+fMlSfPnz9drr73m9doFCxac9D3at29frX4AAKDuI5gBQA3JyJCSkqT8fKlJE4f+/Of5uvpq5zmHw3HS603TVElJiddzqampcjgcstvtKiwsVEJCQk2WDkk7duzQrl27FBUVVWmfjRs3KiAgQF27dvVhZQCAhoBgBgA1ICNDSkiQCgudx0VFiZo1a69KS6U+faTExESPay688ELdfvvtCggIcE11vPvuuz36paWlqaCgQIZhKCgoSC1btlRoaGitfp6GIDY2VllZWa7jzZs3a+XKlYqKilJMTIzbhitlx6tWrVJQUJDXYPbGG29Ikh544IHaLx4AUO8QzACgBiQlnQhlTtequFhavFjyMltRkvTqq696bZ8yZYrbcffu3WumSLgp23ilJjgcDn322WcyDEP333+/AgJ4Gg0A4NQQzACgBuTnn1o7rGWapnJzc1VcXKwvv/xS2dnZ2rp1q7p06eLqM3HiRNfXVU1FLSws1Pjx43XvvfcqICBADzzwgFJTU9WiRYta/QwAgPqFYAYANSAsTMrL895eXnWeR1bdZ5aVn4aHU7N06VJ17NhRH374ofr166fWrVtrzZo12rFjh6vPiBEjXF+vWrXK630mT56sDRs26IknntAll1wiSQoLC1NCQoK6du2q5557rnY/CACg3iCYAUANSElxX2MmScHBznZYq/ymLGFh0uTJdr3//qv67LPPdPfddys2NlYXXXSR9u/f7xbMyj/KoDLjxo1TSEiIW9vFF1+s9957T4Xuc1sBAKgSwQwAaoDN5nwtHwBSUk60wxoVN2XJy7Prnnse0MMPj1KnTp00ZcoU3XLLLZo7d67HtWWPNZCcUx+9qRjKygsODj6z4gEADQrBDABqiM1GEKtrPDdl2anS0n768MM4/eUv0mWXXaYXXnjBtStmmYkTJ2r37t3l7pPkce9ly5Z5bNRS0YQJEzRgwIAz+QgAgAaCYAYAqLc8N18JkxTm1u7tuWXR0dEnvXe/fv3Ur1+/MykPAAAX9vMFANRbFTdfOVk7AABWMSqbN1/ToqKizNzcXJ+8FwAAkucaM8m5KUt6OtNOAQC+ZxjGWtM0PadqiBEzAEA9ZrM5Q1h4uGQYzldCGQCgLiKYncThw4e1b9++KvssWrTIR9UAAE6VzSZt3So5HM5XQhkAoC4imP3m8OHDuvXWW9W/f39FR0crJydHkpSTk6N//vOfkqSYmBi3P1OnTpUkzZw506qyAQAAANQD7Mr4m+eff1533XWXBg8erF9++UUDBgzQF1984dEvOzvbguoAAAAA1GeMmP1my5Yt6tu3rySpZcuW6tSpkwrdH34DAAAAALWCYPabm266ScnJyTp8+LBWrFihgIAAhYSEVOvavXv3Ki4uTnPmzKnlKgEAAADUR0xl/I3NZlNWVpaSk5MVFham2bNnV/va9u3ba8GCBbVWGwAAAID6rcEGs4wMKSlJys93Pmg0JUWy2WIVFBSk7t27q1mzZjpy5IhKSko0ZswY13WpqalyOByy2+0qLCxUQkKChZ8CAAAAQH3QIINZxQeO5uU5jyVp6dK5GjRokG699Vb98MMPmjVrlm655RZJUlpamgoKCmQYhoKCgtSyZUuFhoZa9CkAAAAA1BcNMpglJZ0IZWUKC6XHH/9OAwcG6v3331dkZKRmzJihs846S//+97/1pz/9Sd27d7emYAAAAAD1WoMMZvn53lq/065dkzV9eroCAwP10EMPaciQIbrhhhs0evRoBQcHKyoqytelAgAAAGgADNM0ffJGUVFRZm5urk/e62QiIpzTFysKC3MoL8+5UWVpaakCAwN9WxgAAACAesswjLWmaXod7WmQ2+WnpEjBwe5twcHSCy+c+J+DUAYAAADAVxpkMLPZpPR0KTxcMgzna3q6sx0AAAAAfK1BrjGTnCGMIAYAAACgLmiQI2YAAAAAUJcQzAAAAADAYgQzAAAAALAYwQwAAAAALEYwAwAAAACLEcwAAAAAwGIEMwAAAACwGMEMAOq5zZs3a+PGjVaXAQAAqtBgHzANAPXNpEmTtHDhQrVq1crVtmzZMq1du1ZFRUWKjIy0sDoAAFAVghkA1CNpaWnq06eP1WUAAIBTRDADgHrIbre7pi9u375dbdu2tbgiAABQFYIZANRDx44d04IFCyRJ69ev18CBA60tCAAAVIlgBgB+LCNDSkqS8vOlli0lh0Pq00dq0aKFJk6cKEnKzMxUUVGRxZUCAICqEMwAwE9lZEgJCVJhofO4oECaOnW1iop+Vd++pSoqKtIFF1xgbZEAAKBa2C4fAPxUUtKJUOZ0vUpKWuntt3do7969Ki0tVdOmTa0qDwAAnAJGzADAT+XnV2zpJamXDh2S7r77ROtXX33lw6oAAMDpYMQMAPxUWNiptQMAgLqLETMA+P/27i/07rqO4/jzBVpuMLTaMonYovWHTYrCwptsJYSruQh2IS1rkikadGEZ4YUEaiBdJCMjfq3wphT6cxEzIozKGE1cXkgzvAimjUmtEpNg0Ny7i3OGv9n+5U/Pe7/zeT7gx+98zznjvHif8/uevc7ne85Zpu6668T3mAGsXDk5f7FrrrlmtsEkSdL/zRUzSVqmtm+HhQVYuxaSye+Fhcn5kiRpeXHFTJKWse3bLWKSJM0DV8wkSZIkqZnFTJIkSZKaWcwkSZIkqZnFTJIkSZKaWcwkSZIkqZnFTJIkSZKaWcwkSZIkqZnFTJIkSZKaWcwkSZIkqZnFTJIkSZKaWcwkSZIkqdl5Z7pCknXAo8CfF529qqo2JrkN2Aq8ANxQVftflZSSJEmSNMfOWMymHqyqHcc3kjyUZDNwQVVd/qokkyRJkqRBLOVQxuuAI0keTrIryYqXXiHJDUn2Jdl3+PDhJdyUJEmSJM2vpRSz9cD+qroCeBK4+aVXqKqFqrqsqi5bs2bNEm5KkiRJkubXUopZAbunp3cDG5YeR5IkSZLGs5Ri9ghw1fT0JuDxJaeRJEmSpAGd7Yd/bEmyb9H2CuDTwH1JbgUOAte/0uEkSZIkaQRnLGZVdQBYfYqLrzrF+ZIkSZKks+QXTEuSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSs1TVbG4oOQw89TL+6Wrg769wHJ0959/L+fdy/r2cfy/n38/7oJfz7zWv819bVWtOdsHMitnLlWRfVV3WnWNUzr+X8+/l/Hs5/17Ov5/3QS/n32vE+XsooyRJkiQ1s5hJkiRJUrPlUMwWugMMzvn3cv69nH8v59/L+ffzPujl/HsNN/9z/j1mkiRJkjTvlsOKmSRJkiTNNYuZJEmSJDU7p4pZknVJDifZu+hnf5ILk/w0ya+TPJDk/O6s8+hU859edtt0e0+Sjd1Z59Hp5j+9/D1JnunMOM9Os//58HTfszfJt7pzjiLJHUl+6z5n9pJcNH2u/U2Sh5O8tTvTqJI8luSq7hyjSfKB6WN/T5KvdOcZTZJbFu3/39udZ5bO6w5wEg9W1Y7jG0keAj4L/LyqdiW5E9gK/KQp37z7n/kn2QxcUFWX98Uaxske/8fdCvxz5onGcrL5PwdcWVXHkvwoyfur6tG2hANI8kHg4qr6UJJLgW8AH2uONZKVwC1VdSjJx4EvA19ozjScJNuAC7tzjGb64v/twCeq6tnuPKNJchGT/+dvAt4GfBO4ujHSTJ1TK2an8Tzw+unpNzCf3wJ+LrsOODJ99WhXkhXdgUaTZCvwGJO/Bc1QVT1WVcemm88C/+7MM4iPAvcDVNUfeXH/rxmoqkNVdWi66WO+QZJVwLXAD7qzDGgz8BRwf5JfJXlfd6DBvMCkn7wGWA0c7o0zW8ulmP0YuDbJE8A7gD3NeUazHthfVVcATwI3N+cZSpI3ATcBO7uzjCzJJ4EjVfVEd5YBvJETn4yPJlkuz1dzI8mbmayW3dMcZUQ7gTuBY2e6ol5xb2fyYtAW4HPAvb1xxlJVzwMPA38CfsZkxWwYy+WJbgHYXlUbmDxBfL03znAK2D09vRvY0JhlNAG+A3ypqo52hxlRkvOT3A1cUlVf7M4ziOeA1y3aPrZo1VIzkGQLk8O5Pr9o9UwzkGQ78LSHTLc5Cvyyqo5W1QHgWJI0ZxrG9PDp85kcxvguYOdIny2xXIrZW4C/TU8/A6zrizKkR4Djbz7eBDzeF2U4xWT14PYkDwDrk9zTG2k4dzJ5j+u3u4MM5HfANoAkG4CDvXHGkuTdwNVVdWNV/aM7z4A+BWyY7vO3AV9N8s7mTCP5PZPDGUlyMfCf8kt/Z2kt8NfpzP8FrAIu6I00O+fUF0wnWQfsAw4sOnsFcD1wN5PjTgu4qaqenHW+eXea+V8J3MfkD+MgcH1VHZlxvLl3qvlX1cZF19nrh7C8Ok7z+IcTD6tbqKofzijWkKaHLd4LXMrkfZU3VtVfelONY/opdDt48QXRp6vqM32JxpXka8DeqvpFd5aRJLkD+AiT1bNbquoPzZGGkWQl8H3gEuC1wPeq6ru9qWbnnCpmkiRJkjSi5XIooyRJkiTNLYuZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSM4uZJEmSJDWzmEmSJElSs/8CnuwWfvHAUcMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for word_id, (x_coordinate, y_coordinate) in enumerate(pc_weight):\n",
    "    plt.scatter(x_coordinate, y_coordinate, color=\"blue\")\n",
    "    plt.annotate(i2w[word_id], (x_coordinate, y_coordinate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CBOW 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_weight = pca.fit_transform(cbow.embedding.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for word_id, (x_coordinate, y_coordinate) in enumerate(pc_weight):\n",
    "    plt.scatter(x_coordinate, y_coordinate, color=\"blue\")\n",
    "    plt.annotate(i2w[word_id], (x_coordinate, y_coordinate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. RNNs with Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'3. Deep Learning'에서 배운 Seq2Seq와 Attention에 대해서 간략하게 복습 및 보충하겠습니다. 자세한 건 '3. Deep Learning'을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Sequence to Sequecne**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4-4-1](_image/4-4-1.PNG)\n",
    "\n",
    "위 그림을 보면 알 수 있듯이 시퀀스 투 시퀀스는 입력을 받는 인코더와 출력하는 디코더로  이루어져있습니다. 그리고 인코더와 디코더는 각각의 RNN, LSTM, GRU 중 하나로 구성되어 있습니다. \n",
    "\n",
    "문장의 의미를 더욱 정확하게 파악하기 위해서 양방향 RNN을 사용할 수도 있습니다. 문장을 순방향으로 읽는 RNN과 역방향으로 읽는 RNN을 이용해 나온 최종 은닉 상태를 합하여 사용합니다. 이때 디코더는 순방향으로 하나씩 출력해야하므로 디코더에선 양방향을 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2 Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq는 큰 문제점을 하나 가지고 있었습니다. 마지막 은닉 상태가 문장의 모든 의미를 함축해야 하는데 문장의 길이가 길어질수록 그것이 불가능하다는 것입니다. 즉, 앞쪽의 의미는 잊어버리게 됩니다. 이를 방지하기 위해 우리는 Attention이란 방법을 도입했었습니다.\n",
    "\n",
    "간단하게 말하면 인코더에서 구한 은닉 상태의 결과들을 디코더가 필요한 결과들을 위주로 사용하는 방법이었습니다. 예를 들어 곱셈 기반의 attention을 보겠습니다.\n",
    "\n",
    "![4-4-2](_image/4-4-2.PNG)\n",
    "\n",
    "먼저 인코더에서 구해진 은닉 상태를 다 저장합니다. 이제 디코더에서 은닉 상태를 거칠 때, 인코더의 은닉 상태들과 내적으로 유사도를 구하여 소프트맥스합니다. 그리고 그 비율을 각각 인코더의 은닉 상태에 곱하여 합한 뒤, 구해진 값을 디코더의 추가 입력값으로 사용합니다.\n",
    "\n",
    "예를 들어 기계 번역에선 문장에서 나와야 할 품사가 동일할 때 가중치가 더 높게 측정되는 것입니다. \n",
    "\n",
    "단어마다 어떤 단어에 가중치가 주어졌는지 그래프로 그려보면 다음과 같습니다. 가로축은 input, 세로축은 output 단어들입니다.\n",
    "\n",
    "![4-4-3](_image/4-4-3.PNG)\n",
    "\n",
    "(a)를 보면 중간에 어순이 바뀐 것을 확인할 수 있습니다. 또한 (b)를 보면 어떤 언어에선 하나의 단어가 다른 언어에선 여러 단어로 표현되는 것을 확인할 수 있습니다. \n",
    "\n",
    "이 이외도 다른 attention 방법이 있습니다. 예를 들어 concat 기반의 어텐션이 있습니다. 이는 인코더의 각각 은닉 상태들을 디코더의 은닉 상태와 concat하여 fc를 거치게 하고 하나의 노드를 출력으로 받습니다. 모든 인코더의 은닉 상태에게 적용하여 나온 값들을 가중치로 사용하여 적용하는 방법입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Seq2Seq with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 Seq2Seq 모델을 구현하고 attention 모듈을 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Seq2Seq with toy example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src_data를 trg_data로 바꾸는 번역 task를 수행하기 위한 sample data를 준비합니다.\n",
    "\n",
    "전체 단어 수는 100개이고 다음과 같이 pad token, start, token, end token의 id도 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "pad_id = 0\n",
    "sos_id = 1 # <sos> : start of sentence\n",
    "eos_id = 2 # <eos> : end of sentnece\n",
    "\n",
    "src_data = [\n",
    "    [3, 77, 56, 26, 3, 55, 12, 36, 31],\n",
    "    [58, 20, 65, 46, 26, 10, 76, 44],\n",
    "    [58, 17, 8],\n",
    "    [59],\n",
    "    [29, 3, 52, 74, 73, 51, 39, 75, 19],\n",
    "    [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n",
    "    [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n",
    "    [75, 34, 17, 3, 86, 88],\n",
    "    [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n",
    "    [12, 40, 69, 39, 49]\n",
    "]\n",
    "\n",
    "trg_data = [\n",
    "    [75, 13, 22, 77, 89, 21, 13, 86, 95],\n",
    "    [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n",
    "    [85, 8, 50, 30],\n",
    "    [47, 30],\n",
    "    [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n",
    "    [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n",
    "    [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n",
    "    [16, 98, 68, 57, 55, 46, 66, 85, 18],\n",
    "    [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n",
    "    [37, 93, 98, 13, 45, 28, 89, 72, 70]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# target data의 각 문장의 시작과 끝에 <sos> token id와 <eos> token id를 추가합니다.\n",
    "trg_data = [[sos_id] + seq + [eos_id] for seq in tqdm(trg_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장의 길이를 동일하게 맞춰주기 위해 <pad> token id를 추가하는 padding 함수를 정의합니다.\n",
    "def padding(data):\n",
    "    max_len = len(max(data, key=len))\n",
    "    print(f\"Maximum sequence length: {max_len}\")\n",
    "    \n",
    "    valid_lens = []\n",
    "    for i, seq in enumerate(tqdm(data)):\n",
    "        valid_lens.append(len(seq))\n",
    "        if len(seq) < max_len:\n",
    "            data[i] = seq + [pad_id] * (max_len - len(seq))\n",
    "    \n",
    "    return data, valid_lens, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10017.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "src_data, src_lens, src_max_len = padding(src_data)\n",
    "trg_data, trg_lens, trg_max_len = padding(trg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 15])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 22])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# B: batch size,\n",
    "# S_L: source maximum sequence length\n",
    "# T_L: target maximum sequence length\n",
    "\n",
    "src_batch = torch.LongTensor(src_data) # (B, S_L)\n",
    "src_batch_lens = torch.LongTensor(src_lens) # (B)\n",
    "trg_batch = torch.LongTensor(trg_data) # (B, T_L)\n",
    "trg_batch_lens = torch.LongTensor(trg_lens) # (B)\n",
    "\n",
    "print(src_batch.shape)\n",
    "print(src_batch_lens.shape)\n",
    "print(trg_batch.shape)\n",
    "print(trg_batch_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99,  5],\n",
      "        [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93,  0,  0,  0,  0],\n",
      "        [63, 39,  5, 35, 67, 56, 68, 89, 55, 66,  0,  0,  0,  0,  0],\n",
      "        [ 3, 77, 56, 26,  3, 55, 12, 36, 31,  0,  0,  0,  0,  0,  0],\n",
      "        [29,  3, 52, 74, 73, 51, 39, 75, 19,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 20, 65, 46, 26, 10, 76, 44,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [75, 34, 17,  3, 86, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 40, 69, 39, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [58, 17,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n",
      "tensor([[ 1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84,  2,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18,  2,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 20, 70, 14,  6, 58, 90, 30, 17, 91, 18, 90,  2,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 75, 13, 22, 77, 89, 21, 13, 86, 95,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1,  8, 85, 87, 77, 47, 21, 23, 98, 83,  4, 47, 97, 40, 43, 70,  8, 65,\n",
      "         71, 69, 88,  2],\n",
      "        [ 1, 79, 14, 91, 41, 32, 79, 88, 34,  8, 68, 32, 77, 58,  7,  9, 87,  2,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 16, 98, 68, 57, 55, 46, 66, 85, 18,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 37, 93, 98, 13, 45, 28, 89, 72, 70,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 85,  8, 50, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [ 1, 47, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "tensor([12, 14, 13, 11, 22, 18, 11, 11,  6,  4])\n"
     ]
    }
   ],
   "source": [
    "src_batch_lens, sorted_idx = src_batch_lens.sort(descending=True)\n",
    "src_batch = src_batch[sorted_idx]\n",
    "trg_batch = trg_batch[sorted_idx]\n",
    "trg_batch_lens = trg_batch_lens[sorted_idx]\n",
    "\n",
    "print(src_batch)\n",
    "print(src_batch_lens)\n",
    "print(trg_batch)\n",
    "print(trg_batch_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder 구현\n",
    "- Embedding layer, output layer, GRU cell을 포함한 encoder 모듈을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_dirs = 2 # 2 if bidirectional=True otherwise 1\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True if num_dirs > 1 else False,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.linear = nn.Linear(num_dirs * hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, batch, batch_lens): # batch: (B, S_L), batch_lens: (B)\n",
    "        # d_w: word embedding size\n",
    "        batch_emb = self.embedding(batch) # (B, S_L, d_w)\n",
    "        batch_emb = batch_emb.transpose(0, 1) # (S_L, B, d_w)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(batch_emb, batch_lens)\n",
    "        \n",
    "        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_dirs*num_layers, B, d_h) = (4, B, d_h)\n",
    "        packed_outputs, h_n = self.gru(packed_input, h_0) # h_n: (4, B, d_h)\n",
    "        outputs = pad_packed_sequence(packed_outputs)[0] # outputs: (S_L, B, 2d_h)\n",
    "        outputs = torch.tanh(self.linear(outputs)) # (S_L, B, d_h)\n",
    "        \n",
    "        forward_hidden = h_n[-2, :, :]\n",
    "        backward_hidden = h_n[-1, :, :]\n",
    "        hidden = torch.tanh(self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1))).unsqueeze(0) # (1, B, d_h)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Dot-product Attention 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention 중 대표적 형태인 dot-product attention을 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs): # (1, B, d_h), (S_L, B, d_h)\n",
    "        query = decoder_hidden.squeeze(0) # (B, d_h)\n",
    "        key = encoder_outputs.transpose(0, 1) # (B, S_L, d_h)\n",
    "        \n",
    "        energy = torch.sum(torch.mul(key, query.unsqueeze(1)), dim=-1) # (B, S_L)\n",
    "        \n",
    "        attn_scores = F.softmax(energy, dim=-1) # (B, S_L)\n",
    "        attn_values = torch.sum(torch.mul(encoder_outputs.transpose(0, 1), attn_scores.unsqueeze(2)), dim=1) # (B, d_h)\n",
    "        \n",
    "        return attn_values, attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_attn = DotAttention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 attention 모듈을 가지는 decoder 클래스를 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "        )\n",
    "        self.output_linear = nn.Linear(2 * hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, batch, encoder_outputs, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch : (B)\n",
    "            encoder_outputs: (L, B, d_h)\n",
    "            hidden: (1, B, d_h)\n",
    "        \"\"\"\n",
    "        batch_emb = self.embedding(batch) # (B, d_w)\n",
    "        batch_emb = batch_emb.unsqueeze(0) # (1, B, d_w)\n",
    "        \n",
    "        outputs, hidden = self.rnn(batch_emb, hidden) # (1, B, d_h), (1, B, d_h)\n",
    "        attn_values, attn_scores = self.attention(hidden, encoder_outputs) # (B, d_h), (B, S_L)\n",
    "        concat_outputs = torch.cat((outputs, attn_values.unsqueeze(0)), dim=-1) # (1, B, 2d_h)\n",
    "        \n",
    "        return self.output_linear(concat_outputs).squeeze(0), hidden # (B, V), (1, B, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(dot_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Seq2Seq 모델 구축**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n",
    "        # src_batch: (B, S_L), src_batch_lens: (B), trg_batch: (B, T_L)\n",
    "        \n",
    "        # encoder_outputs: (S_L, B, d_h), hidden: (1, B, d_h)\n",
    "        encoder_outputs, hidden = self.encoder(src_batch, src_batch_lens) \n",
    "        \n",
    "        input_ids = trg_batch[:, 0] # (B)\n",
    "        batch_size = src_batch.shape[0]\n",
    "        outputs = torch.zeros(trg_max_len, batch_size, vocab_size) # (T_L, B, V)\n",
    "        \n",
    "        for t in range(1, trg_max_len):\n",
    "            # decoder_outputs: (B, V), hidden: (1, B, d_h)\n",
    "            decoder_outputs, hidden = self.decoder(input_ids, encoder_outputs, hidden)\n",
    "            \n",
    "            outputs[t] = decoder_outputs\n",
    "            _, top_ids = torch.max(decoder_outputs, dim=-1) # top_ids: (B)\n",
    "            \n",
    "            input_ids = trg_batch[:, t] if random.random() > teacher_forcing_prob else top_ids\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 모델 사용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0476, -0.0706, -0.0480,  ..., -0.0360, -0.1264, -0.1105],\n",
      "         [-0.0360, -0.0926, -0.0160,  ..., -0.0398, -0.1155, -0.0975],\n",
      "         [-0.0370, -0.0307, -0.0097,  ..., -0.0366, -0.1466, -0.0853],\n",
      "         ...,\n",
      "         [-0.0619, -0.0664, -0.0315,  ..., -0.0459, -0.1248, -0.0681],\n",
      "         [-0.0397, -0.0941, -0.0628,  ..., -0.0383, -0.1492, -0.1058],\n",
      "         [-0.0464, -0.0722, -0.0397,  ..., -0.0575, -0.1219, -0.1070]],\n",
      "\n",
      "        [[ 0.0566,  0.0247,  0.0921,  ..., -0.0740, -0.1147, -0.0941],\n",
      "         [ 0.1006, -0.1363, -0.0872,  ..., -0.0866, -0.0738, -0.0402],\n",
      "         [ 0.0830, -0.0025, -0.0901,  ..., -0.0033, -0.0938, -0.1105],\n",
      "         ...,\n",
      "         [ 0.0448,  0.0354,  0.0873,  ..., -0.0744, -0.1027, -0.0705],\n",
      "         [-0.0363,  0.0505, -0.0638,  ..., -0.1132, -0.0789, -0.0805],\n",
      "         [ 0.0252, -0.1121, -0.0074,  ..., -0.0606, -0.1374, -0.0013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0445,  0.1121,  0.1322,  ...,  0.0137, -0.0070, -0.2259],\n",
      "         [-0.0700,  0.0950,  0.0992,  ...,  0.0074,  0.0204, -0.2266],\n",
      "         [-0.0444,  0.1465,  0.1398,  ...,  0.0291,  0.0215, -0.2402],\n",
      "         ...,\n",
      "         [-0.0361,  0.1392,  0.1096,  ..., -0.0003,  0.0096, -0.2335],\n",
      "         [-0.0426,  0.1305,  0.1159,  ...,  0.0084,  0.0080, -0.2614],\n",
      "         [-0.0423,  0.1394,  0.1214,  ...,  0.0130,  0.0209, -0.2602]],\n",
      "\n",
      "        [[-0.0428,  0.1019,  0.1194,  ...,  0.0227, -0.0052, -0.2364],\n",
      "         [-0.0614,  0.0934,  0.1016,  ...,  0.0208,  0.0184, -0.2404],\n",
      "         [-0.0415,  0.1373,  0.1271,  ...,  0.0379,  0.0218, -0.2524],\n",
      "         ...,\n",
      "         [-0.0352,  0.1294,  0.0969,  ...,  0.0111,  0.0116, -0.2437],\n",
      "         [-0.0419,  0.1203,  0.1024,  ...,  0.0195,  0.0111, -0.2694],\n",
      "         [-0.0418,  0.1289,  0.1078,  ...,  0.0239,  0.0239, -0.2681]],\n",
      "\n",
      "        [[-0.0415,  0.0959,  0.1102,  ...,  0.0285, -0.0038, -0.2436],\n",
      "         [-0.0550,  0.0933,  0.1002,  ...,  0.0286,  0.0181, -0.2503],\n",
      "         [-0.0393,  0.1321,  0.1178,  ...,  0.0433,  0.0223, -0.2603],\n",
      "         ...,\n",
      "         [-0.0346,  0.1234,  0.0878,  ...,  0.0185,  0.0131, -0.2507],\n",
      "         [-0.0416,  0.1140,  0.0929,  ...,  0.0266,  0.0134, -0.2748],\n",
      "         [-0.0415,  0.1224,  0.0984,  ...,  0.0309,  0.0260, -0.2736]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "# V: vocab size\n",
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch) # (T_L, B, V)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent = [4, 10, 88, 46, 72, 34, 14, 51]\n",
    "sample_len = len(sample_sent)\n",
    "\n",
    "sample_batch = torch.LongTensor(sample_sent).unsqueeze(0) # (1, L)\n",
    "sample_batch_len = torch.LongTensor([sample_len]) # (1)\n",
    "\n",
    "encoder_output, hidden = seq2seq.encoder(sample_batch, sample_batch_len) # hidden: (4, 1, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = torch.LongTensor([sos_id]) # (1)\n",
    "output = []\n",
    "\n",
    "for t in range(1, trg_max_len):\n",
    "    # decoder_output: (1, V), hidden: (4, 1, d_h)\n",
    "    decoder_output, hidden = seq2seq.decoder(input_id, encoder_output, hidden)\n",
    "    \n",
    "    _, top_id = torch.max(decoder_output, dim=-1) # top_ids: (1)\n",
    "    \n",
    "    if top_id == eos_id:\n",
    "        break\n",
    "    else:\n",
    "        output += top_id.tolist()\n",
    "        input_id = top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31,\n",
       " 80,\n",
       " 84,\n",
       " 40,\n",
       " 95,\n",
       " 40,\n",
       " 88,\n",
       " 40,\n",
       " 65,\n",
       " 34,\n",
       " 73,\n",
       " 28,\n",
       " 10,\n",
       " 24,\n",
       " 91,\n",
       " 26,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Concat Attention 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bahdanau Attention이라고도 불리는 Concat Attention을 구현해보겠습니다.\n",
    "- self.w: concat한 query와 key 벡터를 1차적으로 linear transformation.\n",
    "- self.v: attention logit 값을 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs): # (1, B, d_h), (S_L, B, d_h)\n",
    "        src_max_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        decoder_hidden = decoder_hidden.transpose(0, 1).repeat(1, src_max_len, 1) # (B, S_L, d_h)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) # (B, S_L, d_h)\n",
    "        \n",
    "        concat_hiddens = torch.cat((decoder_hidden, encoder_outputs), dim=2) # (B, S_L, 2d_h)\n",
    "        energy = torch.tanh(self.w(concat_hiddens)) # (B, S_L, d_h)\n",
    "        \n",
    "        attn_scores = F.softmax(self.v(energy), dim=1) # (B, S_L, 1)\n",
    "        attn_values = torch.sum(torch.mul(encoder_outputs, attn_scores), dim=1) # (B, d_h)\n",
    "        \n",
    "        return attn_values, attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_attn = ConcatAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size + hidden_size,\n",
    "            hidden_size,\n",
    "        )\n",
    "        self.output_linear = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, batch, encoder_outputs, hidden): \n",
    "        # batch: (B), encoder_outputs: (S_L, B, d_h), hidden: (1, B, d_h)\n",
    "        batch_emb = self.embedding(batch) # (B, d_w)\n",
    "        batch_emb = batch_emb.unsqueeze(0) # (1, B, d_w)\n",
    "        \n",
    "        attn_values, attn_scores = self.attention(hidden, encoder_outputs) # (B, d_h), (B, S_L)\n",
    "        concat_emb = torch.cat((batch_emb, attn_values.unsqueeze(0)), dim=-1) # (1, B, d_w + d_h)\n",
    "        outputs, hidden = self.rnn(concat_emb, hidden) # (1, B, d_h), (1, B, d_h)\n",
    "        \n",
    "        return self.output_linear(outputs).squeeze(0), hidden # (B, V), (1, B, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(concat_attn)\n",
    "seq2seq = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.1234, -0.0919,  0.0954,  ...,  0.0174, -0.0957,  0.0635],\n",
      "         [ 0.0748, -0.0693,  0.0969,  ...,  0.0345, -0.0742,  0.0858],\n",
      "         [ 0.0761, -0.0433,  0.0738,  ..., -0.0406, -0.1071,  0.0789],\n",
      "         ...,\n",
      "         [ 0.0550, -0.0180,  0.0806,  ..., -0.0030, -0.0848,  0.1004],\n",
      "         [ 0.0797, -0.0439,  0.1005,  ...,  0.0147, -0.0971,  0.0638],\n",
      "         [ 0.0514, -0.0450,  0.1144,  ...,  0.0259, -0.1010,  0.0609]],\n",
      "\n",
      "        [[-0.0212,  0.0125,  0.0370,  ..., -0.0458, -0.0731, -0.0334],\n",
      "         [-0.0589,  0.0125,  0.0457,  ..., -0.0460, -0.0658, -0.0264],\n",
      "         [-0.0607,  0.0353,  0.0419,  ..., -0.0753, -0.0857, -0.0265],\n",
      "         ...,\n",
      "         [-0.0694,  0.0475,  0.0353,  ..., -0.0655, -0.0614, -0.0113],\n",
      "         [-0.0673,  0.0363,  0.0507,  ..., -0.0583, -0.0700, -0.0386],\n",
      "         [-0.0786,  0.0351,  0.0567,  ..., -0.0538, -0.0697, -0.0344]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1755,  0.1572, -0.1401,  ...,  0.0178, -0.1422,  0.0904],\n",
      "         [-0.0350, -0.2412, -0.0698,  ..., -0.0938,  0.0814, -0.0316],\n",
      "         [-0.2355,  0.0217, -0.1771,  ..., -0.1213, -0.0469, -0.1071],\n",
      "         ...,\n",
      "         [-0.2572,  0.1105, -0.0361,  ..., -0.0130,  0.1346, -0.1780],\n",
      "         [-0.0286,  0.0276,  0.2028,  ...,  0.1104, -0.1056, -0.0120],\n",
      "         [-0.1494,  0.0849,  0.1229,  ..., -0.1065,  0.0329, -0.0645]],\n",
      "\n",
      "        [[-0.0428,  0.1872, -0.1489,  ..., -0.0396, -0.0277, -0.0952],\n",
      "         [-0.0054, -0.0692, -0.0783,  ..., -0.1333,  0.0268, -0.1651],\n",
      "         [-0.1482,  0.1468, -0.1828,  ..., -0.1198, -0.0458, -0.2241],\n",
      "         ...,\n",
      "         [-0.1111,  0.1853, -0.0878,  ...,  0.0039,  0.0613, -0.1889],\n",
      "         [-0.0183,  0.0920,  0.0304,  ...,  0.0139,  0.0010, -0.1439],\n",
      "         [-0.0888,  0.1568, -0.0254,  ..., -0.1437,  0.0029, -0.1730]],\n",
      "\n",
      "        [[-0.0043,  0.1780, -0.1649,  ..., -0.0872,  0.0090, -0.1809],\n",
      "         [-0.0138,  0.0235, -0.1073,  ..., -0.1672,  0.0121, -0.2183],\n",
      "         [-0.0945,  0.1763, -0.1795,  ..., -0.1487, -0.0348, -0.2644],\n",
      "         ...,\n",
      "         [-0.0561,  0.1961, -0.1283,  ..., -0.0613,  0.0306, -0.2075],\n",
      "         [-0.0152,  0.1272, -0.0532,  ..., -0.0618,  0.0340, -0.2008],\n",
      "         [-0.0664,  0.1772, -0.0980,  ..., -0.1714, -0.0078, -0.2245]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어 처리 과정의 맥락을 간단하게 살펴보면 다음과 같습니다.\n",
    "\n",
    "$$raw\\;data \\overset{pre-processing}{\\longrightarrow} pre-processed\\;data \\overset{tokenization}{\\longrightarrow} token \\; idx \\overset{input}{\\longrightarrow} output \\overset{post-processing}{\\longrightarrow} result$$\n",
    "\n",
    "#### **Normalization**\n",
    "preprocessing 과정이며 일반적으론 특정 범위에 값이 모두 들어가도록 처리하는 일련의 과정을 말합니다. nlp에선 입력받은 raw data를 가공하는 것을 말합니다. 예를 들어 문장의 좌우 공백 제거, utf-8로 변환, 온점을 문장과 뗴어놓기 등 필요에 따라 다양한 normalization을 할 수 있습니다. \n",
    "\n",
    "#### **Pre-tokenization**\n",
    "normalization을 거쳐도 바로 tokenization을 진행하기엔 무리가 있습니다. 특히 한국어는 띄어쓰기만으로 전처리를 해도 tokenization이 불가능하기에 문장을 더 작은 객체들로 나눠주는 pre-tokenization을 거쳐야합니다. \n",
    "\n",
    "#### **Tokenization**\n",
    "이제 전처리가 모두 끝난 객체(단어)들에 인덱싱하여 token으로 만들어 저장합니다. 이에 관련해선 이후 자세하게 배웁니다.\n",
    "\n",
    "#### **Post-processing**\n",
    "모델에 들어가 output이 나오면 이것을 우리가 받을 결과로 후처리하여 결과를 얻게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization은 크게 **Cleaning**과 **Normalization**으로 이루어집니다. Cleaning은 noise를 제거하는 것이고 Normalization은 단어들을 정규화하는 것입니다. 위에서 이야기했듯 정규화하는 방법과 종류는 다양합니다. \n",
    "\n",
    "#### **Cased / Uncased**\n",
    "Cased / Uncased는 대소문자를 구분할 지, 구분하지 않을지를 결정합니다. uncased를 사용해 대소문자 구분을 하지 않으면 단어의 수가 줄어들어 메모리를 확보할 수 있으나 자칫 여러 의미가 하나의 단어로 정의되어 성능이 떨어질 수 있습니다.\n",
    "\n",
    "하지만 현재 여러 언어들을 입력받아도 동작이 잘 되도록 하는 연구가 트렌드이고 단어가 많아질수록 사전의 비중이 너무 커져 막상 파라미터의 비중이 줄어드는 등의 이유로 uncased를 많이 사용합니다. 또한 두 개의 성능이 눈에 띄게 크기 않는 이유도 있습니다. 물론 어떤 목적이냐에 따라 cased가 더 효과적일 수도 있습니다. 그렇기에 두 개의 경우를 모두 확인하고 더 좋은 것을 사용하는 것이 일반적입니다.\n",
    "\n",
    "\n",
    "#### **Stemming, Lemmatization**\n",
    "Stemming은 단어들을 원형으로 바꿔주는 것을 의미합니다. 예를 들어 '먹었다'라는 과거형이 들어오면 '먹다'라는 일반형으로 바꿔준느 것입니다. 특별한 필요가 있을 때 사용하지만 대체적으로 사용하지 않습니다. 인위적으로 data를 바꾸는 것이 새로운 noise를 만들고 성능을 저하시키기 때문입니다.\n",
    "\n",
    "\n",
    "#### **불필요한 단어 제거**\n",
    "관심이 없는 단어이거나 의미가 없는 빈칸, 개별적 문자로 채워진 것들을 제거합니다.\n",
    "\n",
    "\n",
    "#### **Regular expression**\n",
    "개인 정보 등 데이터에서 공개되면 안 되는 것이 있을 때, 그것을 가리거나 제거하는 것을 말합니다. 예를 들어 신상정보가 있다면 그것을 x로 표시하거나 빈칸으로 대체하는 것을 말합니다. 이 역시 필요할 때만 사용합니다. \n",
    "\n",
    "대체적으로 파이썬의 re 패키지를 이용해 정규식으로 regular expression을 수행합니다. re 패키지를 사용할 때, 먼저 re.compile()을 사용하면 속도나 성능을 조금 끌어올릴 수 있습니다. (다른 re.함수들이 시작할 때마다 compile을 불러오지 않아도 됨으로) 다른 방법으로 NLTK도 있으나 거의 쓰이지 않는 추세입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Pre-tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화 작업 전 데이터를 가공할 땐, 기본적으로 특수 문자 제거와 공백에 따른 분리를 목표로 합니다. 물론 상황에 따라 안 하거나 다르게 할 수 있습니다. 예를 들어 aren't를 are not으로 바꾸는 것입니다. \n",
    "\n",
    "한국어의 경우 공백만으로 token을 나눌 수 없습니다. 그렇기에 띄어쓰기를 고치고 형태소 분석기를 사용하여 토큰화 전처리를 합니다. 지도학습 기반의 KoNLPy, Khaiii와 비지도학습 기반의 soynlp가 있습니다. 간단하게 여러 text 전처리 툴을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0) Regular Expression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규식 표현은 nlp에서 기본적으로 데이터 가공할 때 사용됩니다. \n",
    "\n",
    "> Reference: https://wikidocs.net/21703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 한 개의 문자를 나타내는 .\n",
    "r = re.compile(\"a.c\")\n",
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 2), match='c'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ? 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있는 경우\n",
    "r = re.compile(\"a?c\")\n",
    "r.search(\"bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 존재 하는 경우의 매칭\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 3), match='c'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 존재하지 않는 경우의 매칭\n",
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *은 바로 앞의 문자가 0개 이상일 경우\n",
    "r = re.compile(\"ab*c\") # b가 하나도 없거나, 여러 개인 경우\n",
    "r.search(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='ac'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='abbbbc'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + 앞의 문자가 최소 1개 이상 있을 경우\n",
    "r = re.compile(\"ab+c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='abbbc'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ 시작되는 글자를 지정함\n",
    "r = re.compile(\"^a\")\n",
    "r.search(\"bbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 해당 숫자만큼 반복해야 함.\n",
    "r = re.compile(\"ab{2}c\")\n",
    "r.search(\"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자1, 숫자2} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 숫자1 ~ 숫자2 만큼 반복해야 함\n",
    "r = re.compile(\"ab{2,8}c\") # 띄어쓰기 하면 안 됨\n",
    "r.search(\"ac\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='abbc'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.search(\"abbbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{숫자,} 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 문자를 숫자 이상만큼 반복해야 함\n",
    "r = re.compile(\"a{2,}bc\")\n",
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='aabc'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"aabc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[] 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] 안에 있는 문자들 중 한 개의 문자와 매치\n",
    "# 범위를 지정할 수도 있음. 예) a-z, A-Z, 0-9\n",
    "r = re.compile('[abc]')\n",
    "r.search(\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"adb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^문자] 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ 기호 뒤에 붙은 문자들을 제외한 모든 문자를 매치함\n",
    "r = re.compile(\"[^abc]\") # abc를 제외한 모든 문자\n",
    "r.search(\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 4), match='d'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 4), match='e'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abcedf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) KoNLPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KoNLPy](https://konlpy.org/en/latest/)는 Hannanum, Kkma, Komoran, Mecab, Okt 등 다양한 형태소 분석기를 제공합니다. 그리고 형태소로 나누는 함수, 명사만 뽑아내는 함수, 형태소와 묶어서 분리하는 함수 등 다양한 함수들이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가', '요', '?']\n",
      "['환영', '자연어', '처리', '수업']\n",
      "[('환영', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S'), ('자연어', 'N'), ('처리', 'N'), ('수업', 'N'), ('은', 'J'), ('재미있', 'P'), ('게', 'E'), ('듣', 'P'), ('고', 'E'), ('계시', 'P'), ('ㄴ가', 'E'), ('요', 'J'), ('?', 'S')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'\n",
    "print(hannanum.morphs(text))  # Parse phrase to morphemes\n",
    "print(hannanum.nouns(text))   # Noun extractors\n",
    "print(hannanum.pos(text))     # POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가요', '?']\n",
      "['환영', '자연어', '처리', '수업']\n",
      "[('환영', 'NNG'), ('하', 'XSV'), ('ㅂ니다', 'EFN'), ('!', 'SF'), ('자연어', 'NNG'), ('처리', 'NNG'), ('수업', 'NNG'), ('은', 'JX'), ('재미있', 'VA'), ('게', 'ECD'), ('듣', 'VV'), ('고', 'ECE'), ('계시', 'VXA'), ('ㄴ가요', 'EFQ'), ('?', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'\n",
    "print(kkma.morphs(text))  # Parse phrase to morphemes\n",
    "print(kkma.nouns(text))   # Noun extractors\n",
    "print(kkma.pos(text))     # POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Khaiii**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Khaiii](https://tech.kakao.com/2018/12/13/khaiii/)(Kakao Hangul Analyzer III)는 카카오의 딥러닝 기반 형태소 분석기입니다. 국립국어원에서 배포한 세종코퍼스로 학습하였습니다. 한국어에서 형태소 분석은 가장 기본적 전처리 과정으로 속도가 매우 중요하다는 판단하에 nlp에서 자주 쓰이는 LSTM이나 RNN을 제외하고 CNN을 사용하여 구현되었습니다. \n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/1oU7/image/DXlTnCNYfeYzWIR4kN428VouYKQ.png\">\n",
    "\n",
    "[Khaiii github](https://github.com/kakao/khaiii)\n",
    "\n",
    "윈도우는 지원하지 않기에 ubuntu 상에서 확인했습니다. \n",
    "\n",
    "ubuntu에서 `jupyter notebook` 명령어로 실행하여 확인하면 됩니다.\n",
    "\n",
    "[윈도우에서 khaiii 설치 방법](https://sy-log.tistory.com/55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) PyKoSpacing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyKoSpacing](https://github.com/haven-jeon/PyKoSpacing)은 띄어쓰기가 되어있지 않은 문장에 띄어쓰기를 적용해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "띄어쓰기가 없는 문장:\n",
      " 구름자연어처리전문가양성과정2기에오신여러분을환영합니다!\n",
      "정답:\n",
      " 구름 자연어 처리 전문가 양성 과정 2기에 오신 여러분을 환영합니다!\n",
      "띄어쓰기 교정 후:\n",
      " 구름자연어 처리 전문가 양성과정 2기에 오신 여러분을 환영합니다!\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "\n",
    "spacing = Spacing()\n",
    "\n",
    "sent = \"구름 자연어 처리 전문가 양성 과정 2기에 오신 여러분을 환영합니다!\"\n",
    "new_sent = sent.replace(\" \", \"\")\n",
    "kospacing_sent = spacing(new_sent)\n",
    "\n",
    "print(\"띄어쓰기가 없는 문장:\\n\", new_sent)\n",
    "print(\"정답:\\n\", sent)\n",
    "print(\"띄어쓰기 교정 후:\\n\", kospacing_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Py-Hanspell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': True,\n",
       " 'original': '안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.',\n",
       " 'checked': '안녕하세요. 저는 한국인입니다. 이 문장은 한글로 작성됐습니다.',\n",
       " 'errors': 4,\n",
       " 'words': OrderedDict([('안녕하세요.', 2),\n",
       "              ('저는', 0),\n",
       "              ('한국인입니다.', 2),\n",
       "              ('이', 2),\n",
       "              ('문장은', 2),\n",
       "              ('한글로', 0),\n",
       "              ('작성됐습니다.', 1)]),\n",
       " 'time': 0.13100790977478027}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "result = spell_checker.check(u'안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.')\n",
    "result.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지\n"
     ]
    }
   ],
   "source": [
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) soynlp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[soynlp](https://github.com/lovit/soynlp)는 한국어와 관련된 전처리 함수와 여러 함수들이 모아져있는 라이브러리입니다. 비지도학습 기반이기에 어느 정도 규모가 있는 동일한 집단 문서에서 잘 작동합니다. 예를 들어 영화댓글이나 뉴스 기사 등이 있습니다. \n",
    "\n",
    "Noun extractor, word extraction, tokenizer, part of speech tagger, vectorizer, normalizer 등의 기능을 가진 함수들이 있습니다. 밑에는 그 중 normalization의 함수를 사용한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅋㅋㅋㅜㅜㅜ\n",
      "와하하핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜ 아핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜ 123 아핫\n",
      "가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "\n",
    "print(emoticon_normalize('ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ쿠ㅜㅜㅜㅜㅜㅜ', num_repeats=3))\n",
    "\n",
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "\n",
    "print(only_hangle('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))\n",
    "\n",
    "print(only_hangle_number('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))\n",
    "\n",
    "print(only_text('가나다ㅏㅑㅓㅋㅋ쿠ㅜㅜㅜabcd123!!아핫'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 다양한 것은 각 라이브러리 홈페이지를 참고하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. 네이버 영화 감상평을 크롤링하고 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 영화 감상평을 크롤링하고 전처리 과정을 거쳐 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen # 웹서버에 접근하는 모듈\n",
    "from bs4 import BeautifulSoup # 웹페이지 내용구조를 분석하는 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 네이버 영화 감상평 크롤링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1'\n",
    "html=urlopen(url)\n",
    "html_source = BeautifulSoup(html,'html.parser',from_encoding='utf-8') # 댓글 페이지를 utf-8형식으로 html 소스가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<title>네이버 영화</title>\n",
      "<link href=\"https://ssl.pstatic.net/static/m/movie/icons/naver_movie_favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
      "<link href=\"/css/common.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\">\n",
      "<link href=\"/css/movie_tablet.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"/css/movie_end.css?20220110163618\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<script src=\"/js/deploy/movie.all.js?20220110163618\" type=\"text/javascript\"></script>\n",
      "</link></head>\n",
      "<body>\n",
      "<!-- content -->\n",
      "<input id=\"movieCode\" name=\"movieCode\" type=\"hidden\" value=\"187348\"/>\n",
      "<input id=\"onlyActualPointYn\" name=\"onlyActualPointYn\" type=\"hidden\" value=\"N\"/>\n",
      "<input id=\"includeSpoilerYn\" name=\"includeSpoilerYn\" type=\"hidden\" value=\"N\"/>\n",
      "<input id=\"order\" name=\"order\" type=\"hidden\" value=\"sympathyScore\"/>\n",
      "<input id=\"page\" name=\"page\" type=\"hidden\" value=\"1\"/>\n",
      "<div class=\"ifr_area basic_ifr\">\n",
      "<div class=\"input_netizen \">\n",
      "<!-- [D] 관람객 평점 작성 완료 -->\n",
      "<div class=\"ly_viewer\" id=\"actualPointWriteExecuteLayer\" style=\"display:none\">\n",
      "<h4>관람객 평점 작성 완료 안내</h4>\n",
      "<p>관람객 평점이 등록되었습니다.<br/><em>네이버페이 포인트 500원</em>이 적립되었습니다.<br/><em>7일 이후</em> 확인 가능합니다.</p>\n",
      "<p>(평점 삭제시, 적립된 포인트는 회수됩니다.)</p>\n",
      "<div class=\"btn\">\n",
      "<a class=\"ok\" href=\"#\" id=\"actualPointWriteExecuteLayerOkButton\">확인</a>\n",
      "<a class=\"close\" href=\"#\" id=\"actualPointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //관람객 평점 작성 완료 -->\n",
      "<!-- [D] 관람객 평점 작성 완료2 -->\n",
      "<div class=\"ly_viewer\" id=\"pointWriteExecuteLayer\" style=\"display:none\">\n",
      "<h4>관람객 평점 작성 완료 안내</h4>\n",
      "<p class=\"msg1\">관람객 평점이 등록되었습니다.</p>\n",
      "<div class=\"btn\">\n",
      "<a class=\"ok\" href=\"#\" id=\"pointWriteExecuteLayerOkButton\">확인</a>\n",
      "<a class=\"close\" href=\"#\" id=\"pointWriteExecuteLayerCloseButton\" title=\"닫기\">관람객 평점 작성 완료 안내 레이어 닫기</a>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //관람객 평점 작성 완료2 -->\n",
      "<div class=\"score_total\">\n",
      "<strong class=\"total\">관람객 평점 <em>9,035</em>건<button class=\"btn_review\" id=\"open-form-btn\">내 평점 등록</button></strong>\n",
      "</div>\n",
      "<div class=\"top_behavior\" id=\"orderCheckbox\">\n",
      "<ul class=\"sorting_list\">\n",
      "<li class=\"on\"><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.bysym', '', '', event); dislplayOrder('sympathyScore');\">공감순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.byrct', '', '', event); dislplayOrder('newest');\">최신순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.high', '', '', event); dislplayOrder('highest');\">평점 높은 순</a></li>\n",
      "<li><a href=\"#\" onclick=\"parent.clickcr(this, 'ara.low', '', '', event); dislplayOrder('lowest');\">평점 낮은 순</a></li>\n",
      "</ul>\n",
      "<ul class=\"quarter_mode\">\n",
      "<li>\n",
      "<input class=\"blind \" id=\"spoilerYnCheckBox\" name=\"spilerViewer\" onclick=\"parent.clickcr(this,'','','',event); return false;\" title=\"스포일러 보기\" type=\"checkbox\"/>\n",
      "<label class=\"label_viewer\" for=\"spoilerYnCheckBox\" id=\"spoilerYnLable\">스포일러 보기</label>\n",
      "</li>\n",
      "<li>\n",
      "<input class=\"blind \" id=\"actualYnCheckBox\" name=\"viewer\" onclick=\"parent.clickcr(this,'ura.mgs','','',event); return false;\" title=\"관람객 평점만 보기\" type=\"checkbox\"/>\n",
      "<label class=\"label_viewer\" for=\"actualYnCheckBox\" id=\"actualYnLable\">관람객 평점만 보기</label>\n",
      "<a class=\"help _actualPointHelp\" href=\"#\" id=\"actualPointHelpButton\" title=\"도움말\">관람객 평점만 보기 도움말</a>\n",
      "<div class=\"ly_help _actualPointHelp\" id=\"actualPointHelp\" style=\"display:none\">\n",
      "<h5>관람객평점만 보기 안내 레이어</h5>\n",
      "<div class=\"ly_cont _actualPointHelp\">\n",
      "<p>네이버 영화에서 예매하신 고객님들이<br/> 영화 관람 후 등록해주신 평점입니다.</p>\n",
      "</div>\n",
      "<button class=\"btn_close _actualPointHelp\" id=\"actualPointHelpCloseButton\" title=\"닫기\" type=\"button\"><span class=\"blind\">관람객 평점만 보기 안내 레이어 닫기</span></button>\n",
      "<span class=\"arr _actualPointHelp\"></span>\n",
      "</div>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"score_result\">\n",
      "<ul>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683851, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>유한솔(u_hs****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 23:12</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','u_hs****', '5yeZlbUoM83MSnyA4B69g2/9Kp6/vWUPiWtbjRDZ/Ic=', '17683851', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683851\">3530</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683851\">999</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_1\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment1\">\n",
      "<a data-src=\"자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 무조건 힙하지? 우리 중국 문화야 ㅋ 구미호, 기린, 용은 우리 문화다. 사람 죽으면 물에 연등 띄우는 거? 우리 중국 문화다. 동북공정 영화입니다. 영화는 자세히 보세요. 의도가 있습니다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17684413, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>다른별명(quda****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.02 09:07</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','quda****', 'yDhDuoAGvFlSapTkwfceEoomxBNCGqOlYHBXUhATmZs=', '17684413', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17684413\">2452</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17684413\">765</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:10.0%\"></span></span><em>1</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_2\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 중국산 D-War \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683609, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>eodb****</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 21:52</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','eodb****', 'tREtwejBYWKbW6jlqJ1pIjGadMB7X8Mut/wC4lCPwbg=', '17683609', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683609\">1672</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683609\">524</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:50.0%\"></span></span><em>5</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_3\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment3\">\n",
      "<a data-src=\"세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 감정기복 너무 심해서 공감도 안가고, 사건들이 빌드업도 없이 무지성으로 튀어나오니까 몰입도 안 됨. 배우가 너무 아깝다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17682177, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>멍멍(mild****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 11:21</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','mild****', 'ojMhodyJCw+vC49FARXW6LajOidxylKbd4sd7FWy2YM=', '17682177', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17682177\">1632</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17682177\">502</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:50.0%\"></span></span><em>5</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_4\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17684461, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>삼생삼세(lexp****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.02 10:25</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','lexp****', 'R9qgmU3/u5wIhbcc9qwxbAqnEQDmQoQBBGF+r/BIDoM=', '17684461', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17684461\">1200</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17684461\">260</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:10.0%\"></span></span><em>1</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_5\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t하 정말 재미없네요.. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683742, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>LEEE(oh1m****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 22:30</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','oh1m****', 'ILR9piLlT+GT5bopI6SQwT5g/ONv1kL+aNF8BR9L6GI=', '17683742', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683742\">1242</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683742\">441</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:80.0%\"></span></span><em>8</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_6\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라.... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683773, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>아오이키(akpl****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 22:41</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','akpl****', '7VcZSNARn0DmciXUgvpCdhpWhySrrgIlUvXk9ThEANs=', '17683773', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683773\">904</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683773\">175</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:100.0%\"></span></span><em>10</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_7\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 새로운 시작이다… 재밌어요 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17682380, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>서울자취생(osan****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 12:57</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','osan****', '/nJNfnEViK1sAU2EfhMyhySFZOOvQGfkPEf8vne0pEU=', '17682380', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17682380\">704</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17682380\">162</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li>\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span class=\"text_spo _text_spo\" id=\"_text_spo_8\">스포일러가 포함된 감상평입니다. <a class=\"btn_more\" href=\"javascript:void(0);\" onclick=\"showMovieReview('8');\" role=\"button\">감상평 보기</a></span>\n",
      "<span id=\"_filtered_ment_8\" style=\"display:none;\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17683572, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>척설오추(jagi****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.01 21:42</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','jagi****', 'A6a4XYMPqy60LytWz0YbOrrZvTCupul3o2z1kR64W5M=', '17683572', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17683572\">590</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17683572\">117</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "<li class=\"last\">\n",
      "<div class=\"star_score\">\n",
      "<span class=\"st_off\"><span class=\"st_on\" style=\"width:60.0%\"></span></span><em>6</em>\n",
      "</div>\n",
      "<div class=\"score_reple\">\n",
      "<p>\n",
      "<span class=\"ico_viewer\">관람객</span>\n",
      "<!-- 스포일러 컨텐츠로 처리되는지 여부 -->\n",
      "<span id=\"_filtered_ment_9\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블영화보면서 처음으로 졸았습니다 ㅜㅜ \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "</p>\n",
      "<dl>\n",
      "<dt>\n",
      "<em>\n",
      "<a href=\"#\" onclick=\"javascript:showPointListByNid(17686410, 'after');parent.clickcr(this, 'ara.uid', '', '', event); return false;\" target=\"_top\">\n",
      "<span>kupyt192(neid****)</span>\n",
      "</a>\n",
      "</em>\n",
      "<em>2021.09.03 11:02</em>\n",
      "</dt>\n",
      "<dd>\n",
      "<a class=\"go_report2\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.report', '', '', event); common.report('false','neid****', 'saQhtz9jiCIRvm10d92XoilJfNG9PWkYufbLt2TIid0=', '17686410', 'point_after', false);return false;\"><em>신고</em></a>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"btn_area\">\n",
      "<a class=\"_sympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.sym', '', '', event);\">\n",
      "<span class=\"ico_up\"></span>\n",
      "<span class=\"blind\">공감</span>\n",
      "<strong class=\"sympathy_17686410\">730</strong>\n",
      "</a>\n",
      "<a class=\"_notSympathyButton\" href=\"#\" onclick=\"parent.clickcr(this, 'ara.opp', '', '', event);\">\n",
      "<span class=\"ico_down\"></span>\n",
      "<span class=\"blind\">비공감</span>\n",
      "<strong class=\"notSympathy_17686410\">271</strong>\n",
      "</a>\n",
      "</div>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"paging\">\n",
      "<div>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=1\" id=\"pagerTagAnchor1\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span class=\"on\">1</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>2</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=3\" id=\"pagerTagAnchor3\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>3</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=4\" id=\"pagerTagAnchor4\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>4</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=5\" id=\"pagerTagAnchor5\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>5</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=6\" id=\"pagerTagAnchor6\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>6</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=7\" id=\"pagerTagAnchor7\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>7</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=8\" id=\"pagerTagAnchor8\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>8</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=9\" id=\"pagerTagAnchor9\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>9</span></a>\n",
      "<a href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=10\" id=\"pagerTagAnchor10\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\"><span>10</span></a>\n",
      "<a class=\"pg_next\" href=\"/movie/bi/mi/pointWriteFormList.naver?code=187348&amp;type=after&amp;isActualPointWriteExecute=false&amp;isMileageSubscriptionAlready=false&amp;isMileageSubscriptionReject=false&amp;page=2\" id=\"pagerTagAnchor2\" onclick=\"parent.clickcr(this, 'ara.page', '', '', event);\" title=\"다음\"><em>다음</em></a>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<!-- //content -->\n",
      "<form accept-charset=\"utf-8\" id=\"reportForm\" method=\"POST\" name=\"reportForm1\"></form>\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "\n",
      "if (false == false && \"after\" == \"after\" && false) {\n",
      "\tif (true && false) {\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").show();\n",
      "\t} else if (false && true) {\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").show();\n",
      "\t}\n",
      "}\n",
      "\n",
      "var oElActualPointWriteExecuteLayer = jindo.$Element(\"actualPointWriteExecuteLayer\");\n",
      "\n",
      "if (oElActualPointWriteExecuteLayer != null && oElActualPointWriteExecuteLayer != \"undefined\") {\n",
      "\n",
      "\t\n",
      "\tjindo.$Element(\"actualPointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tjindo.$Element(\"actualPointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"actualPointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "}\n",
      "\n",
      "var oElPointWriteExecuteLayer = jindo.$Element(\"pointWriteExecuteLayer\");\n",
      "\n",
      "if (oElPointWriteExecuteLayer != null && oElPointWriteExecuteLayer != \"undefined\") {\n",
      "\t\n",
      "\tjindo.$Element(\"pointWriteExecuteLayerOkButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tjindo.$Element(\"pointWriteExecuteLayerCloseButton\").attach(\"click\", function(e){\n",
      "\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\tjindo.$Element(\"pointWriteExecuteLayer\").hide();\n",
      "\t\trefreshPage();\n",
      "\t});\n",
      "\t\n",
      "}\n",
      "\n",
      "jindo.$Fn(function () {\n",
      "\n",
      "  function checkboxHandlerFactory(isActualYn, isLabel) {\n",
      "    return function() {\n",
      "      var actualYnChecked = jindo.$(\"actualYnCheckBox\").checked;\n",
      "      var spoilerYnChecked = jindo.$(\"spoilerYnCheckBox\").checked;\n",
      "\n",
      "      // convert\n",
      "      actualYnChecked = (isActualYn && isLabel)? !actualYnChecked : actualYnChecked;\n",
      "      spoilerYnChecked = (!isActualYn && isLabel)? !spoilerYnChecked : spoilerYnChecked;\n",
      "\n",
      "      location.href = \"/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&onlyActualPointYn=\" + (actualYnChecked? \"Y\" : \"N\")  + \"&onlySpoilerPointYn=\" + (spoilerYnChecked? \"Y\" : \"N\") + \"&order=sympathyScore\";\n",
      "    };\n",
      "  }\n",
      "\n",
      "\t\n",
      "\tif (jindo.$(\"actualYnCheckBox\") != null) {\n",
      "\t\tjindo.$Fn(checkboxHandlerFactory(true, false), this).attach(jindo.$(\"actualYnCheckBox\"), 'click');\n",
      "\t}\n",
      "\n",
      "\tif (jindo.$(\"actualYnLable\") != null) {\n",
      "\t    jindo.$Fn(checkboxHandlerFactory(true, true), this).attach(jindo.$(\"actualYnLable\"), 'click');\n",
      "\t}\n",
      "\n",
      "\t\n",
      "    if (jindo.$(\"spoilerYnCheckBox\") != null) {\n",
      "    jindo.$Fn(checkboxHandlerFactory(false, false), this).attach(jindo.$(\"spoilerYnCheckBox\"), 'click');\n",
      "  }\n",
      "\n",
      "  if (jindo.$(\"spoilerYnLable\") != null) {\n",
      "    jindo.$Fn(checkboxHandlerFactory(false, true), this).attach(jindo.$(\"spoilerYnLable\"), 'click');\n",
      "  }\n",
      "\t\n",
      "\t\n",
      "\tif (jindo.$Element(\"actualPointHelp\") != null && jindo.$Element(\"actualPointHelp\") != \"undefined\") {\n",
      "\t\tactualPointHelpLayerToggle = function() {\n",
      "\t\t\tsetTimeout( function() {\n",
      "\t\t\t\tif (document.activeElement != null) {\n",
      "\t\t\t\t\tvar focusedEl = jindo.$Element(document.activeElement);\n",
      "\t\t\t\t\tif (focusedEl != null) {\n",
      "\t\t\t\t\t\tif ( !focusedEl.hasClass(\"_actualPointHelp\") ) {\n",
      "\t\t\t\t\t\t\t jindo.$Element(\"actualPointHelp\").hide();\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}, 100);\n",
      "\t\t};\n",
      "\n",
      "\t\tnew jindo.LayerManager(\"actualPointHelp\", {\n",
      "\t\t\tsCheckEvent : \"click\",\n",
      "\t\t\tnHideDelay : 0\n",
      "\t\t}).link(jindo.$(\"actualPointHelp\"), jindo.$(\"actualPointHelpButton\"));\n",
      "\n",
      "\t\tjindo.$Element(\"actualPointHelpButton\").attach(\"click\", function(e){\n",
      "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
      "\t\t});\n",
      "\n",
      "\t\tjindo.$Element(\"actualPointHelpCloseButton\").attach(\"click\", function(e){\n",
      "\t\t\te.stop(jindo.$Event.CANCEL_DEFAULT);\n",
      "\t\t\tjindo.$Element(\"actualPointHelp\").toggle();\n",
      "\t\t});\n",
      "\n",
      "\t\t\n",
      "\t\tvar waelActualPointHelp = jindo.$ElementList('._actualPointHelp');\n",
      "\n",
      "\t\tjindo.$A(waelActualPointHelp.$value()).forEach(function(value, index, array) {\n",
      "\t\t\tjindo.$Fn(actualPointHelpLayerToggle, this).attach(value, \"blur\");\n",
      "\t\t});\n",
      "\t}\n",
      "\n",
      "\tparent.setParamForPointAfterList('N', 'sympathyScore', '1');\n",
      "\tparent.resizePointAfterListIframe(0);\n",
      "\n",
      "\t// 최소 높이 270px 지정\n",
      "\tvar frameHeight = eval(jindo.$Document().scrollSize().height);\n",
      "\n",
      "\tparent.resizePointAfterListIframe(frameHeight);\n",
      "\tparent.isPointAfterListLoad = true;\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "  var isCheckPointExist = false;\n",
      "  // TODO: fix below condition\n",
      "  if (false) {\n",
      "    if(jindo.$Element(\"open-form-btn\")) {\n",
      "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function(e) {\n",
      "\t\t  \t\n",
      "\t\t  \t\n",
      "\t\t\t\n",
      "\t\t  if (true && false && isCheckPointExist == false) {\n",
      "\t\t\tparent.point.checkPointAfterExistAndMileageSubscriptionType();\n",
      "\t\t  }\n",
      "\t\t  isCheckPointExist = true;\n",
      "\t\t  parent.openPointWriteForm();\n",
      "\t\t});\n",
      "    }\n",
      "  } else {\n",
      "    if (jindo.$Element(\"open-form-btn\")) {\n",
      "\t\tjindo.$Element(\"open-form-btn\").attach(\"click\", function (e) {\n",
      "\t\t  common.checkLogin(false);\n",
      "\t\t});\n",
      "    }\n",
      "  }\n",
      "\n",
      "  var isHide = true;\n",
      "\n",
      "  if(jindo.$Element(\"eval-edit\")) {\n",
      "    jindo.$Element(\"eval-edit\").attach(\"click\", function() {\n",
      "\t\t  var edit = jindo.$Element(\"ly-edit\");\n",
      "\t  \tisHide ? edit.show() : edit.hide();\n",
      "      \tisHide = !isHide;\n",
      "    })\n",
      "  }\n",
      "  parent.resizePointAfterListIframeOnLoad();\n",
      "}, this).attach(this, 'load');\n",
      "\n",
      "var point = {\n",
      "\t\tcheckLoginWithMessage : function(login, loginMessage, notLoginMessage) {\n",
      "\t\t\tif(login == false){\n",
      "\t\t\t\tif(confirm(message)){\n",
      "\t\t\t\t\ttop.location.href=\"https://nid.naver.com/nidlogin.login?mode=form&url=\"+encodeURIComponent(top.location.href);\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn false;\n",
      "\t\t\t}\n",
      "\t\t\treturn true;\n",
      "\t\t},\n",
      "\n",
      "\t\t\n",
      "\t\tcheckAlreadyPointAfterExist : function (nid) {\n",
      "\t\t\tvar existPointType = \"pointBefore\";\n",
      "\t\t\t\n",
      "\t\t\tif (false == false) {\n",
      "\t\t\t\tvar oAjax = new jindo.$Ajax(\"/api/internal/point/pointAfterExistJson.naver\", {\n",
      "\t\t\t    \tonload : function (oRes) {\n",
      "\t\t\t    \t\tvar resultCode = oRes.json().resultCode;\n",
      "\t\t\t    \t\t\n",
      "\t\t\t    \t\tif (resultCode == \"error\") {\t\t\t\t\t\t\t// 서버 오류\n",
      "\t\t\t    \t\t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
      "\t\t\t    \t\t\treturn false;\n",
      "\t\t\t    \t\t} else {\n",
      "\t\t\t    \t\t\texistPointType = oRes.json().existPointType;\n",
      "\t\t\t    \t\t\tpoint.del(existPointType, nid);\n",
      "\t\t\t    \t\t}\n",
      "\t\t\t    \t},\n",
      "\t\t\t\t\ttimeout : 5,\n",
      "\t\t\t    \tonerror : function (oRes) {\n",
      "\t\t\t    \t\talert(\"오류가 발생했습니다. 잠시 후 다시 시도해주세요.\");\n",
      "\t\t\t    \t\treturn false;\n",
      "\t\t\t    \t},\n",
      "\t\t\t    \tontimeout : function (oRes) {\n",
      "\t\t\t    \t\talert(\"처리가 지연되고 있습니다. 다시 시도해주세요.\");\n",
      "\t\t\t    \t\treturn false;\n",
      "\t\t\t    \t}\n",
      "\t\t\t    });\n",
      "\t\t\t    \n",
      "\t\t\t    oAjax.request({\n",
      "\t\t\t    \t\"movieCode\" : \"187348\",\n",
      "\t\t\t    \t\"isActualPoint\" : \"false\"\n",
      "\t\t\t    });\n",
      "\t\t\t} else {\n",
      "\t\t\t\tpoint.del(existPointType, nid);\n",
      "\t\t\t}\n",
      "\t\t},\n",
      "\n",
      "\t\tdel : function (existPointType, nid) {\n",
      "\t\t\tif (existPointType == \"actualPoint\") {\n",
      "\t\t\t\tif (confirm(\"관람객 평점 삭제시, 평점 작성으로 적립된 포인트는 회수됩니다. 평점을 삭제할까요?\") == false) {\n",
      "\t\t\t\t\treturn false;\n",
      "\t\t\t\t}\n",
      "\t\t\t} else {\n",
      "\t\t\t\tif (confirm(\"본인 삭제 시 복구할 수 없습니다.\\n평점을 삭제하시겠습니까?\") == false) {\n",
      "\t\t\t\t\treturn false;\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\tvar ajaxDeleteUrl = \"/api/internal/point/pointBeforeDelete.naver\";\n",
      "\t\t\tif (\"after\" == \"after\") {\n",
      "\t\t\t\tajaxDeleteUrl = \"/api/internal/point/pointAfterDelete.naver\";\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\tvar ajax = new jindo.$Ajax(ajaxDeleteUrl, { \n",
      "\t\t\t\tmethod : \"POST\",\n",
      "\t\t\t\tasync : false,\n",
      "\t\t\t\tonload : this.delCallback\n",
      "\t\t\t});\n",
      "\t\t\tajax.header(\"ajax\", \"true\");\n",
      "\t\t\tajax.request({\n",
      "\t\t\t\t\"nid\":nid\n",
      "\t\t\t});\n",
      "\t\t},\n",
      "\t\t\n",
      "\t\tdelCallback : function(req) {\n",
      "\t\t\tvar returnValue = req.text();\n",
      "\t\t\t\n",
      "\t\t\tif(returnValue != \"success\"){\n",
      "\t\t\t\talert(returnValue);\n",
      "\t\t\t\treturn false;\n",
      "\t\t\t}\n",
      "\t\t\t\n",
      "\t\t\ttop.location.href = '/movie/bi/mi/point.naver?code=187348#pointAfterTab';\n",
      "\t\t\ttop.location.reload(true);\n",
      "\t\t}\n",
      "};\n",
      "\n",
      "function dislplayOrder(order) {\n",
      "\tvar url = \"/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after\";\n",
      "\t\n",
      "\tvar onlyActualPointYnValue = jindo.$(\"onlyActualPointYn\").value;\n",
      "  \tvar includeSpoilerYnValue = jindo.$(\"includeSpoilerYn\").value;\n",
      "\n",
      "\tif (onlyActualPointYnValue != \"\") {\n",
      "\t\turl = url + \"&onlyActualPointYn=\" + onlyActualPointYnValue;\n",
      "\t}\n",
      "\n",
      "\tif (includeSpoilerYnValue != \"\") {\n",
      "      url = url + \"&onlySpoilerPointYn=\" + includeSpoilerYnValue;\n",
      "    }\n",
      "\t\n",
      "\turl = url + \"&order=\" + order;\n",
      "\t\n",
      "\tlocation.href = document.location.protocol + \"//\" + document.domain + url;\n",
      "}\n",
      "\n",
      "function showPointListByNid(nid, target){\n",
      "\tif (target == 'after') {\n",
      "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.naver?st=nickname&target=after&sword=\"+nid;\n",
      "\t} else {\n",
      "\t\ttop.location.href = top.location.protocol + \"//\" + top.location.hostname + \"/movie/point/af/list.naver?st=nickname_before&target=before&sword=\"+nid;\n",
      "\t}\n",
      "}\n",
      "\n",
      "function refreshPage() {\n",
      "\t \n",
      "\ttop.location.href = '/movie/bi/mi/point.naver?code=187348#pointAfterTab';\n",
      "}\n",
      "\n",
      "// 스포일러 감상평 내용 보기\n",
      "function showMovieReview(rvwIdx) {\n",
      "    jindo.$Element('_text_spo_' + rvwIdx).css('display', 'none');\n",
      "    jindo.$Element('_filtered_ment_' + rvwIdx).css('display', 'block');\n",
      "    parent.resizePointAfterListIframeOnLoad();\n",
      "}\n",
      "\n",
      "// 감상평 펼쳐보기\n",
      "function unfoldPointMent(obj) {\n",
      "    var fullMent = jindo.$Element(obj).attr(\"data-src\");\n",
      "    jindo.$Element(obj).parent().html(fullMent);\n",
      "    parent.resizePointAfterListIframeOnLoad();\n",
      "}\n",
      "\n",
      "\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "\tvar sympathy = new Sympathy(\"187348\", \"after\");\n",
      "</script>\n",
      "<script type=\"text/javascript\">\n",
      "            jindo.$Fn(function() {\n",
      "                try{ lcs_do(); } catch(e){}\n",
      "            }).attach(window, \"pageshow\");\n",
      "\t\t</script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(html_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "댓글 부분에 해당하는 요소를 확인하고 내용을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 리뷰\n",
    "html_reviews = html_source.find('span', {'id': '_filtered_ment_0'})\n",
    "print(html_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span id=\"_filtered_ment_0\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_1\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment1\">\n",
      "<a data-src=\"자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 무조건 힙하지? 우리 중국 문화야 ㅋ 구미호, 기린, 용은 우리 문화다. 사람 죽으면 물에 연등 띄우는 거? 우리 중국 문화다. 동북공정 영화입니다. 영화는 자세히 보세요. 의도가 있습니다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "<span id=\"_filtered_ment_2\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 중국산 D-War \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_3\">\n",
      "<span class=\"_unfold_ment\" id=\"_unfold_ment3\">\n",
      "<a data-src=\"세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 감정기복 너무 심해서 공감도 안가고, 사건들이 빌드업도 없이 무지성으로 튀어나오니까 몰입도 안 됨. 배우가 너무 아깝다. \" href=\"javascript:void(0);\" onclick=\"unfoldPointMent(this);\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n",
      "</span>\n",
      "</span>\n",
      "<span id=\"_filtered_ment_4\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_5\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t하 정말 재미없네요.. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_6\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라.... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_7\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블의 새로운 시작이다… 재밌어요 \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_8\" style=\"display:none;\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이... \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n",
      "<span id=\"_filtered_ment_9\">\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t마블영화보면서 처음으로 졸았습니다 ㅜㅜ \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t</span>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    html_reviews = html_source.find('span', {'id': '_filtered_ment_' + str(i)})\n",
    "    print(html_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다\n",
      "자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\n",
      "마블의 중국산 D-War\n",
      "세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\n",
      "마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지...\n",
      "하 정말 재미없네요..\n",
      "마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라....\n",
      "마블의 새로운 시작이다… 재밌어요\n",
      "아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이...\n",
      "마블영화보면서 처음으로 졸았습니다 ㅜㅜ\n"
     ]
    }
   ],
   "source": [
    "# 10명 리뷰 확인, 불필요한 HTML 태그 제거\n",
    "for i in range(10):\n",
    "    html_reviews = html_source.find('span', {'id': '_filtered_ment_' + str(i)})\n",
    "    print(html_reviews.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10페이지에 대해 댓글 수집\n",
    "reviews_list = []\n",
    "for j in range(1, 11):\n",
    "    url='https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=187348&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='+str(j)\n",
    "    html = urlopen(url)\n",
    "    html_source = BeautifulSoup(html, 'html.parser', from_encoding='utf-8') # 댓글 페이지를 utf-8 형식으로 html 소스 가져오기\n",
    "    \n",
    "    for i in range(10):\n",
    "        html_reviews = html_source.find('span', {'id':'_filtered_ment_' + str(i)})\n",
    "        reviews_list.append(html_reviews.text.strip())\n",
    "\n",
    "file = open('data/reviews.txt', 'w', encoding='utf-8')\n",
    "for review in reviews_list: # 요소를 1개의 행으로 저장되도록 개행문자 추가\n",
    "    file.write(review + '\\n') # 개행 문자 추가 --> Enter, 줄바꿈 효과\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 크롤링한 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reviews.txt', 'r', encoding='utf-8') as f:\n",
    "    review_data = f.readlines()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['명품 브랜드라 믿고 샀는데 안에 made in china가 적혀있었다\\n',\n",
       " '자세히 보면 중국 문화 올려치는 영화입니다. 초반부터 똥양계는 무조건 한국인 취급하는데 우리는 당당히 중국인이다. ㅇㅈㄹ하고요. 깊고 정통한 중국 문화는 대를 이어서 간다. 마카오에서 K-POP 댄스 추는 거 보고 ...\\n',\n",
       " '마블의 중국산 D-War\\n',\n",
       " '세계관이나 설정들이 너무 붕 떠있고 개연성은 밥말아 먹어놓고 억지 신파 끼워넣기에 주인공은 무색무취 아무 매력 없음. 10초전 까지 죽일듯이 싸우던 애들이 갑자기 우리 함께 싸우자 ㅇㅈㄹ 하질 않나. 아부지 행동들 ...\\n',\n",
       " '마블의 탈을 쓴 중국 무협영화. 중국 시장과 자본을 지나치게 의식한 디즈니의 연이은 헛발질. CG 범벅에 협소한 공간에서 몇 안되는 인원들의 액션 등 스케일마저 왜 이리 작아진 건지...\\n',\n",
       " '하 정말 재미없네요..\\n',\n",
       " '마블 영화를 본 건지 중국 영화를 본 건지 모르겠지만 양조위는 너무 멋있더라....\\n',\n",
       " '마블의 새로운 시작이다… 재밌어요\\n',\n",
       " '아부지를 왜케 미워하는거지 훈련빡시케 시켰다고 그러는건가아부지를 죽인댔다가 갑자기 필요하다하고 개연성이 좀 부족..텐링즈의 전설이란 제목도 뭐 굳이...\\n',\n",
       " '마블영화보면서 처음으로 졸았습니다 ㅜㅜ\\n',\n",
       " '일라오이 VS 사일러스\\n',\n",
       " '진짜 개노잼이다 와 이렇게 재미없는 마블영화도 첨\\n',\n",
       " '마블 영화라 믿기지 않을 정도로 지루해.. 졸려 죽는 줄 알았다ㅠ\\n',\n",
       " '노잼, 개연성 제로, 중국산 웹툰 느낌\\n',\n",
       " '이게뭐냐 진짜 마블 실망\\n',\n",
       " '전형적인 서양에서 생각하는 온갖 동양 클리셰는 몽따 넣은 영화 .. 보면서 불편\\n',\n",
       " '보는내내ㅠ드는 생각....왜 총안씀...?\\n',\n",
       " '솔직히 샹치 캐릭터의 매력이 뭔지 잘모르겠고 용타고 날라다닐땐 마블이 왜 저러나싶음...샹치 표정연기 못해서 캐릭터 몰입안됨..미스캐스팅....연기도 별로...캐릭들의 감정 이입도 어색하고(양조위 제외) 진행 전개도...\\n',\n",
       " '자기 어머니를 죽인 집단을, 다시 복수하는건데, 그걸 굳이 아버지를 미워하게 되는 관점이 좀 웃기긴함. 훈련과정속에서는 딱히 미워할요소가 없는데. 그리고 젤 황당했던게, 천년간 텐링즈끼고 잘 살아왔는데 난데없이 싸우...\\n',\n",
       " '마블에서 디워를 만들면 이렇겠구나\\n',\n",
       " '보지마.... 그냥 길에 돈과 시간을 버리자\\n',\n",
       " '마블을 기대하고 갔다가 추억의 중국무술영화 보고옴. 중국무술영화 좋아하던 분들은 재밌겠네. 난 뭘 보고온거지....\\n',\n",
       " '뛰쳐나갈뻔 개인적으로 구데기\\n',\n",
       " '마블빠돌인데 난 왤캐 별로였지...중국권문화라 거부감이 들어서인가? 그냥 그 마을 들어갈때부터 뭔가 이상했음양조위는 진짜 잘생겼고 여지껏 마블에서 볼수없었던 액션이기에 신선했음.암튼 샹치데뷔를 축하합니다\\n',\n",
       " '영상미나 액션은 정말 좋았는데 뭔가 내용 전개자체는 마블답지 못한느낌이였음 중국산무협느낌은 있을수밖에 없다고 쳐도 수룡과 괴물의 싸움은 뭔가 좀 이질감드는느낌이였고 수룡얼굴이 너무 귀여웠음 디지니 애니메이션에 나올것...\\n',\n",
       " '영상미 이런건 좋앗지만 그냥 중국영화 보는느낌이엿습니다,\\n',\n",
       " '액션은 확실히 엄청났다.하지만 영화는 액션이 전부가 아니다스토리가 어설프니 개연성이 부족하고, 개연성이 부족하니 영화에 몰입할 수 없다.이는 곧 영화가 노잼이라는 걸 의미한다.감상포인트를 하나 강제로 선택해야 하기에...\\n',\n",
       " '마블영화맞냐 넷플로 출시해도 볼까말까한 전형적인 짱깨영화\\n',\n",
       " '개인적으로 초반 30분은 신선했으나 이후부터는 흔한 쿵푸액션. 오그라들까말까 뜬금없을까말까 아슬아슬하게 선타기하는 신파와 스토리진행. cg와 영상미는 너무 좋았음\\n',\n",
       " 'ㅋㅋㅋ 아니 왜ㅋㅋㅋ 나는 재밋었는데 ㅋ디워보다는 솔직히 낫ㅈㅣ ㅋ\\n',\n",
       " '양조위와 나머지의 전설...\\n',\n",
       " '개연성 부족, 떡밥 회수 부족, 텐링즈 설명 부족\\n',\n",
       " '진짜 재밌어? 진짜???\\n',\n",
       " '그냥저냥 짱캐풍 오락영화\\n',\n",
       " '제발 악플 쓸거면 제대로 알고 등록합시다. 중국 자본 1도 안 들어간 영화고 중국에서 상영 금지된 영화입니다. 주인공 배우도 중국인 아니고 캐나다 국적의 배우입니다. 후반부의 플롯은 살짝 아쉬웠지만 영화 자체의 영상...\\n',\n",
       " '전혀 웃기지 않은 개그. 실제로 보면 민폐일것 같은 여친. 중국풍 CG 덩어리. 모든게 마블 답지 않았다. CG로 된 짜치는 용이 나온 순간 영화 자체가 그냥 흔한 중국 영화가 되어버렸다. 뜬금없는 중국속 구미호, ...\\n',\n",
       " '음 그냥 중국영화 딱 중국영화 그이상도 그이하도 아니다 중화 사상은 없는데 어디서 많이 본듯한 중국 무렵 영화 장면을 그대로 보는 듯 하고 발전이 없다. 영화 유투버들이 호들갑 떨면서 중국 느낌 없다고 해서 봤지만 ...\\n',\n",
       " '샹치와 아콰피나 친구컨셉으로 가자,러브라인으로 가면 못보겠슴\\n',\n",
       " '정말 마블의 영웅 서사는 기본기가 좋네요. 양조위는 신의 한 수!\\n',\n",
       " '중국영화에 마블스티커\\n',\n",
       " '와 액션 존윅급 꼭 강추 홀리몰리\\n',\n",
       " '그냥 중국 무협지 한편 봤다...중국영화 좋아하면 추천...아니면 노...\\n',\n",
       " '개인적으로 마블 영화의 강점은 확고한 그들만의 세계관과 그에따른 설득력이라 생각했는데. 샹치. 마블 히어로가 맞는가? 좀 더 완성도 있게 만든 중국무협영화 아니고? 천하의 마블이 양조위  포스에 묻어가려는 판이라니....\\n',\n",
       " '시사회를 보고 온 사람으로 말씀드리지만 절대로 중국을 위한 영화가 아닌 그냥 마블 영화입니다. 중국투자를 받지 않았고, 양조위씨와 양자경씨는 중국 블랙리스트 배우들인데 중국을 위한 영화였다면 왜 이들을 썼을까요? 제...\\n',\n",
       " '양조위가 너무 연기 잘함.  샹치보다 더 뇌리에 남음.  무술은 최고점!!!\\n',\n",
       " '그냥 중국영화 줫노잼 스킵해도 됨\\n',\n",
       " '마블 영화라고 너무 기대함\\n',\n",
       " '마블 계급장 떼고 봐도 이건 진짜 역대급 영화임.. 스토리 좋았고 특히나 영상미는 미친 퀄리티임 진짜.\\n',\n",
       " '지루한 서사.. 갑자기 초인적 능력이 생기는게 이해가 안됨. 굳이 샹치 솔로무비가 필요했나 싶음. 솔로 없이 자연스레 마블에 합류했어도 될 것 같았음. 갠적으로 마블이 버리는 카드가 아닌가 싶었음.\\n',\n",
       " '모자란 개연성에 인공호흡하는 양조위의 연기만 남은 영화\\n',\n",
       " '디워의 재림이란 말이 괜히 나온게 아니네  동양판타지 요소를 너무 과하게 넣음.. 특히 마지막 진 보스와 쫄따구 디자인은 어거지로 급하게 만들어 넣은느낌\\n',\n",
       " '양조위 말고는 딱히 남는 게 없는\\n',\n",
       " '여기 댓글창 무슨일? 다들 샹치가 중국현지 개봉 및 홍보 금지처분 받은건 알고 말하는건가 감독님은 하와이안이고 케이티역인 아콰피나는 한국계 미국인이고 심지어 샹치 역을 맡은 시무리우 배우는 캐나다 이민 출신인데 할머...\\n',\n",
       " '다른 건 모르겠고 양조위 형님 얼굴에 주름 생긴 거 보니 가슴이 아파온다.\\n',\n",
       " '미친 액션.. 진짜 화려해요양조위님은.. 늙지도 않으시고 너무 멋지고 애잔한 연기 좋아요\\n',\n",
       " '마지막 10분 정도만 존재감이 나타나는 주인공과 왠지 모르게 웃음이 나오는 액션씬. 디워와 쿵푸 팬더를 합쳐놓은 듯하다.\\n',\n",
       " '아니 마블 원작은 알고서 사람들이 욕을 하는건지 애초에 샹치라는 캐릭터 자체가 중국계 캐릭터고 마블에 이미 예전부터 샹치를 다루는 영화를 만들거라고 마블의 새로운 액션을 시도하겠다고 오래전부터 예고하고 있었는데무작정...\\n',\n",
       " '막 재밌다는건 아니고 쓰읍 하 아 뭐랄까 그냥 중국??\\n',\n",
       " '이게 슈X 드래곤볼이지 마블이아?\\n',\n",
       " '액션 ok 근데 이야기의 큰 줄기가 없다. 그냥 개연성이 부족한 오락영화\\n',\n",
       " '양조위 진짜 미쳤다 액션 눈빛 영어 다 대대대대존멋ㅠㅠ 액션 스케일도 쩔고 재밌는데 기승전 양조위 진짜 미쳤음\\n',\n",
       " '크게 기대는 안했지만 마블영화같지도않고 기대치보다도 낮네요.마블영화인데 보다가 졸았습니다.\\n',\n",
       " '이건 너무 충격적이다..마블 ㅂㄷ\\n',\n",
       " '영화관을 나오는데...장어먹고 싶드라..\\n',\n",
       " '마블 팬이라면 볼만하다는 댓글이 있는데 무슨소리인지 모르겠다. VOD로도 진짜 보기 아깝다.\\n',\n",
       " '용이랑 괴물이 싸우는 장면에서 b급 중국영화 느낌이 나서 아쉬웠음\\n',\n",
       " '마블답지 않은 전개에요\\n',\n",
       " '마블 껍데기 쓴 뻔한 중국 영화\\n',\n",
       " '너무 여러 가지 요소들을 짬뽕시켜놔서 좀 뜬금없는 느낌이 있었음\\n',\n",
       " '역시 cg처리를 비롯한 영상미는 끝내줬어요. 근데 너무나도 중국중국중국,, 언어만 영어를 사용할 뿐 언어를 제외한 영화의 모든게 중국!!! 내용도 뻔하고,,, 마블처돌이는 샹치를 보고 웁니다 ㅜㅅㅜ\\n',\n",
       " '마블을 보는건지, 중국영화를 보는건지...용 나올땐 어이가 없더라구요.영화전개도 별로고 마음에 드는게 하나도없었네요 ㅜ 영화보다가 잘뻔.\\n',\n",
       " '양조위씨 아버지의 애증연기가  다했습니다\\n',\n",
       " '뒷부분 하이라이트보다 앞부분 버스 씬이 더 샹치스러웠다\\n',\n",
       " '양조위와 텐 링즈의 전설\\n',\n",
       " '갠적으루 웬우 서사가 샹치 서사보다 더 좋았다ㅎㅎㅎ\\n',\n",
       " '와...나 양조위 좋아하네\\n',\n",
       " '초중반까지 분위기 좋다가 갑자기 중국전통 판타지 무협영화가 되버려서 아쉬웠네요.\\n',\n",
       " '뭐 액션은 말이 필요없는 수준이고 마지막 클라이맥스 씬에서 스케일이나 영상미가 예술이었음ㅋㅋㅋ  페이즈 4에서 아주 중요한 영화인 듯하니 아이맥스로 꼭 보시길!\\n',\n",
       " '양조위만 남았다..\\n',\n",
       " '중국풍이 넘 강해서 생각만큼 재밌진 않음 그냥 마블이라서 봄\\n',\n",
       " '액션에 공들인 게 확연히 느껴진다. 여느 슈퍼히어로 영화들과 같이 스토리 자체는 지극히 평범했다. 예상했던 대로 할리우드 특유의 오리엔탈리즘도 부각되었다. 이러한 점들을 감안해도 이 정도 완성도를 뽑아냈다는 것에 만...\\n',\n",
       " '세상에 존재하는 클리셰는 다 집어넣은듯ㅋㅋㅋ 액션 많은건 좋은데 싸우다가 왜 죽는거 구경만 하는거에 답답함을 느낌\\n',\n",
       " '쿠키영상이 다했다 내용도 뻔한 클리셰지만 마블답게 잘 풀어낸거같음\\n',\n",
       " '마블영화라는 프레임에 속지마세요~\\n',\n",
       " \"호불호가 많이 갈리네요 전 '호'였습니다\\n\",\n",
       " '아버지를 저렇게까지 미워하는 게 좀 공감이 안갔다.\\n',\n",
       " '머리는 샹치 응원하는데,, 마음은 양조위 응원함,, 명불허전 양조위ㅠㅠ\\n',\n",
       " '편의점 집 아들이 많이 컸네\\n',\n",
       " '중국맛이랑 헐리우드맛이랑 잘 섞어놨다고 생각하고, 나는 뭐 영화보는데 불편하지 않았고 액션 좋고 재밌었다.\\n',\n",
       " '마블 영화 중에 제일 재미없게 봤음ㅠㅠ\\n',\n",
       " '이번건 마블영화야 중화사상 영화가 아니라고..\\n',\n",
       " '오랜만에 잘잤다 덕분에 꿀잠\\n',\n",
       " '진심 중국은 마블 내에서도 민폐네요 중국산은 어떻게든 위상 높일려고 안달난 느낌 올림픽이든 뭐든 다 발악하겠지만 아무도 인정 안해줍니다\\n',\n",
       " '마블 영화 중 최악ㅎㅎㅋㅋ\\n',\n",
       " '재미도 없고 그냥 다 별로..\\n',\n",
       " '양조위는 항상 옳다\\n',\n",
       " '샹치의 매력은 잘 모르겠으나 양조위는 좋았음\\n',\n",
       " '진짜 댓글 수준 와……아직 보지도 않았는데 봤다고 하는 사람도 있고, 여기서 쓸데없는 얘기하는 사람들도 있고ㅋㅋㅋ\\n',\n",
       " '샹치배우 최선이었나\\n',\n",
       " '쿠키 외엔 액션 합 정도만 볼만한 영화. 그나마 양조위 아저씨는 개멋지긴 하다.토르2 이후로 처음으로 영화보다 잠들어 버림\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 한글만 남기고 다른 글자 제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를왜케미워하는거지훈련빡시케시켰다고그러는건가아부지를죽인댔다가갑자기필요하다하고개연성이좀부족텐링즈의전설이란제목도뭐굳이\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tmp = re.sub('[^가-힣]', '', review_data[8])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를왜케미워하는거지훈련빡시케시켰다고그러는건가아부지를죽인댔다가갑자기필요하다하고개연성이좀부족텐링즈의전설이란제목도뭐굳이\n"
     ]
    }
   ],
   "source": [
    "tmp = re.sub(' +', ' ', tmp)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아부지를 왜 케미워하는 거지 훈련 빡시케시켰다고 그러는 건가 아부지를 죽인 댔다가 갑자기 필요하다 하고 개연성이 좀 부족텐링즈의 전설이란 제목도 뭐 굳이\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(tmp)\n",
    "\n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아버지를 왜 게 미워하는 거지 훈련 빡세 케시 켰다고 그러는 건가 아버지를 죽인 댔다가 갑자기 필요하다 하고 개연성이 좀 부족텐링즈의 전설이란 제목도 뭐 굳이\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "spelled_sent = spell_checker.check(kospacing_sent)\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Intro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer는 2017년 구글이 발표한 논문인 [Attention is all you need](https://arxiv.org/abs/1706.03762)에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더의 구조는 따르면서 attention만으로 구현한 모델입니다. 이 모델은 RNN을 사용하지 않았음에도 RNN보다 더 좋은 성능을 보여줍니다. \n",
    "\n",
    "시작에 앞서 트랜스포머의 하이퍼파라미터를 정의하겠습니다. 하이퍼파라미터에 대한 설명은 뒤에 이어 나오고 여기선 정의만 먼저 하겠습니다. 수치는 논문에서 제의한 수치이고 사용자가 임의로 변경할 수 잇는 값들입니다.\n",
    "\n",
    "* $d_{model}$ = 512  \n",
    "트랜스포머의 인코더와 디코더에서 정해진 입력과 출력의 크기를 의미합니다. 임베딩 벡터의 차원 또한 $d_{model}$이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 차원을 유지합니다. 논문에선 512로 정의했습니다.  \n",
    "\n",
    "$$ $$\n",
    "\n",
    "* num_layers = 6  \n",
    "트랜스포머에서 하나의 인코더와 디코더를 층으로 생각했을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는지를 의미합니다. 논문에선 6으로 정의했습니다.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "* num_heads = 8  \n",
    "트랜스포머에선 어텐션을 병령로 수행하는데 이때 병렬의 개수를 의미합니다. 논문에선 8로 정의했습니다.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "* $d_{ff}$ = 2048  \n",
    "트랜스포머 내부에는 피드 포워드 신경망이 존재하며 해당 신경망의 은닉층의 크기를 의미합니다. 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://jalammar.github.io/images/t/The_transformer_encoders_decoders.png\">\n",
    "\n",
    "트랜스포머는 RNN을 사용하지 않지만 기존 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있습니다. 이전 seq2seq 구조에서 인코더와 디코더가 각각 하나의 RNN이 t개의 시점을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조입니다. 논문은 각각 6개로 설정했습니다.\n",
    "\n",
    "<img src = \"http://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\">\n",
    "\n",
    "위 그림이 인코더와 디코더가 6개씩 존재하는 트랜스포머의 구조를 보여줍니다. \n",
    "\n",
    "![transformer](_image/4-6-1.PNG)\n",
    "\n",
    "트랜스포머의 전체적 구조는 위와 같습니다. 복잡하고 어려운 것들이 많아 보이지만 하나씩 뜯어가며 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.3 Positional Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트랜스포머의 내부를 보기 전에 입력을 먼저 알아보겠습니다. RNN은 단어의 위치에 따라 순차적으로 입력을 받기에 자연스레 위치 정보를 가질 수 있다는 장점이 있었습니다. \n",
    "\n",
    "하지만 트랜스포머는 단어의 입력을 순차적으로 받지 않기에 위치 정보를 저장하지 못합니다. 그렇기에 포지셔널 인코딩(positional encoding)을 통해 위치 정보를 더하여 입력으로 사용하게 됩니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_vectors.png\">\n",
    "\n",
    "위 그림을 보면 입력이 들어가기 전에 입력값인 임베딩 벡터에 포지셔널 인코딩이 더해지는 것을 볼 수 있습니다. \n",
    "\n",
    "만약 임베딩 크기가 4라고 가정한다면, 실제로 각 위치에서 따른 포지녀설 인코딩은 아래와 같이 계산됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_example.png\">\n",
    "\n",
    "이때 포지셔널 인코딩 벡터를 정하기 위해 아래의 두 함수를 사용합니다. (이것은 Sinusoidal Position Embedding이라고 합니다.)\n",
    "\n",
    "$$PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})$$\n",
    "$$PE_{(pos, 2i + 1)} = cos(pos/10000^{2i/d_{model}})$$\n",
    "\n",
    "sin과 cos함수의 값을 더해주므로 단어의 순서 정보를 더해주는 것입니다. 밑의 그래프는 임베딩 크기가 4일 때, 포지셔닝 인코딩을 해주기 위해 구한 사인과 코사인 함수의 그래프입니다.\n",
    "\n",
    "<img src = \"http://nlp.seas.harvard.edu/images/the-annotated-transformer_49_0.png\">\n",
    "\n",
    "위에서 x축은 단어의 순서입니다. 이를 기준으로 결정되는 4개의 값(임베딩 크기가 4이므로 그래프가 4개)으로 포지셔닝 인코딩 벡터를 만들어 더해주는 것입니다. \n",
    "\n",
    "좀 더 자세히 살펴보겠습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer7.PNG\">\n",
    "\n",
    "pos는 입력 문장에서 임베딩 벡터의 위치를 나타내며 i는 임베딩 벡터 내의 차원 인덱스를 의미합니다. 위 식을 보면 알 수 있듯 인덱스가 짝수인 곳은 sin 함수, 인덱스가 홀수인 곳은 cos 함수를 사용합니다. 또한 위 식에서 $d_{model}$은 트랜스포머의 모든 층의 출력 차원을 의미하는 하이퍼파라미터입니다. 임베딩 벡터 또한 $d_{model}$의 크기를 가지며 위 그림에선 4, 논문에선 512로 정의되어있습니다. \n",
    "\n",
    "이렇게 같은 단어가 들어와도 순서 정보가 합쳐져 다른 임베딩 벡터가 만들어지게 됩니다. 이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Implement the PE function\"\"\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x += Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1173f31f430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pe = PositionalEncoding(20, 0)\n",
    "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4, 5, 6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 임베딩 벡터의 차원 128, 문장의 길이 50\n",
    "sample_pos_encoding = PositionalEncoding(128, 0, 50)\n",
    "\n",
    "y = sample_pos_encoding.forward(Variable(torch.zeros(1, 50, 128)))\n",
    "plt.pcolormesh(y[0])\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.4 Trasformer에서 사용되는 Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/31379/attention.PNG\">\n",
    "\n",
    "트랜스포머에선 위 그림에 나타난 세 가지 어텐션을 사용합니다. 첫번째 어텐션은 인코더에서, 두번째와 세번째 어텐션은 디코더에서 사용됩니다. 셀프 어텐션은 본질적으로 쿼리(Query), 키(Key), 값(Value)가 동일한 경우(출처가 같다)를 말합니다. 그렇기에 세번째 어텐션의 경우 쿼리는 디코더의 벡터, 키와 값는 인코더의 벡터이므로 셀프 어텐션이 아닙니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer_attention_overview.PNG\">\n",
    "\n",
    "위 그림은 각각의 어텐션이 위치하는 곳을 표시한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.5 Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 인코더에 대해서 알아보겠습니다.\n",
    "\n",
    "![encoder](_image/4-6-2.PNG)\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layers(위 그림에서 N) 개수의 인코더 층을 쌓습니다. 논문은 6개의 층을 쌓았습니다. 하나의 인코더 층은 크게 attention과 feed forward 두 개의 서브층(sublayer)으로 나뉘어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Self-Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 함수는 주어진 쿼리에 대해서 모든 키와의 유사도를 구합니다. 그리고 구한 유사도를 가중치로 사용하여 키와 맵핑되어있는 각각의 값에 반영합니다. 그리고 유사도가 반영된 값을 모두 가중합하여 출력합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG\">\n",
    "\n",
    "이것이 앞서 배운 어텐션의 기본 개념입니다. 여기서 주어진 쿼리, 키, 값의 의미는 다음과 같습니다.\n",
    "\n",
    "- Q(Query): 모든 시점의 디코더 셀에서의 은닉 상태들\n",
    "- K(Keys): 모든 시점의 인코더 셀의 은닉 상태들\n",
    "- V(Values): 모든 시점의 인코더 셀의 은닉 상태들\n",
    "\n",
    "기존 어텐션은 위처럼 Q와 K가 다른 값을 가지고 있었습니다. 그러나 셀프 어텐션(self-attention)은 Q, K, V가 모두 동일합니다. 그렇기에 트랜스포머에서 Q, K, V는 다음과 같습니다.\n",
    "\n",
    "- Q(Query): 입력 문장의 모든 단어 벡터들\n",
    "- K(Keys): 입력 문장의 모든 단어 벡터들\n",
    "- V(Values): 입력 문장의 모든 단어 벡터들\n",
    "\n",
    "이를 도입한 이유는 모델이 단어들을 인코딩할 때, 다른 단어들을 보고 더 정확한 인코딩을 하도록 만들기 위함입니다. 예를 들어 \"The animal didn't cross the street because it was too tired.\"라는 문장이 있을 때, \"it\"은 무엇일까요? 사람은 \"animal\"이란 것을 알 수 있지만 기계는 \"animal\"과 \"street\" 중 쉽게 고르지 못합니다. 이를 방지하기 위해 현재 처리 중인 단어와 연관 있는 다른 단어들의 맥락을 고려하여 임베딩하는 것입니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Scaled dot-product Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q, K, V 벡터 생성**\n",
    "\n",
    "셀프 어텐션은 첫번째로 인코더에 입력된 벡터로부터 Q, K, V라는 3개의 벡터를 만들어냅니다. 이 벡터들은 입력 벡터에 대해서 세 개의 학습 가능한 행렬들을 각각 곱함으로 만들어집니다.\n",
    "\n",
    "이때 Q, K, V 벡터들은 초기 입력인 $d_{model}$보다 작은 차원을 가집니다. 논문에선 $d_{model}$이 512인데 반해 새로운 벡터들의 차원은 64입니다. 그러나 꼭 작아야하는 것은 아닙니다. 여기서 새로운 벡터들의 차원을 작게 한 이유는 multi-head attention의 계산 복잡도를 일정하게 만들기 위함일 뿐입니다.  \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self_attention_vectors.png\">\n",
    "\n",
    "위 그림에서 $x_1$에 가중치 행렬 $W_Q$를 곱하여 현재 단어와 연관된 쿼리 벡터 $q_1$을 생성합니다. 마찬가지로 다른 $q_1, \\; k_1, \\; v_1$ 벡터도 만들어집니다. 이때 각 가중치 행렬은 $d_{model} \\times (d_{model}\\;/num\\_heads)$의 크기를 가집니다. 논문과 같다면 $d_{model}=512, \\; num\\_heads=8$로 64의 크기를 가지는 $q_1, \\; k_1, \\; v_1$벡터가 만들어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**어텐션 점수 계산**\n",
    "\n",
    "두번째로 어텐션 점수를 계산합니다. 아래 예시의 첫번째 단어인 \"Thinking\"에 대해 계산한다고 하겠습니다. 그렇다면 \"Thinking\"과 입력 문장 속 다른 모든 단어들에 대해서 점수를 구해야 합니다. 이 점수가 추후 인코딩할 때, 다른 단어들에 대해 얼마나 집중해야 할 지 결정합니다.\n",
    "\n",
    "점수는 현재 단어의 쿼리 벡터와 다른 단어의 키 벡터의 내적으로 계산됩니다. 즉, 유사도와 동일합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self_attention_score.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax**\n",
    "\n",
    "이제 점수들을 키 벡터의 크기인 $d_k$의 제곱근인 $\\sqrt{d_k}$로 나눠줍니다. 이는 값들을 전체적으로 0과 가깝게 만들어줍니다. 그래서 소프트맥스의 대소 관계를 바꾸진 않지만 서로의 격차를 줄여주고 가중치가 하나로 쏠리는 현상을 막아줍니다. (더 안정적인 gradient를 가지게 만듭니다.) 그리고 이 값을 softmax 계산을 통해 각 단어의 표현이 얼마나 들어갈지 결정합니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention_softmax.png\">\n",
    "\n",
    "대부분 현재 단어의 위치가 가장 높은 점수를 받지만 가끔씩 다른 단어에 정보가 들어가는 것이 도움이 될 때도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가중합**\n",
    "\n",
    "막바지입니다. 이제 각 단어들의 V 벡터에 이 점수를 곱합니다. 즉, 가중치들을 곱해줍니다. 그리고 구해진 벡터들을 모두 합하여 출력시킵니다. 출력된 값은 Add & Norm을 거쳐 Feed Forward에 입력값으로 들어갑니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Scaled dot-product attention을 행렬 연산으로**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 계산은 각 벡터들의 계산으로 진행되었습니다. 그러나 실제 구현에서는 빠른 속도를 위해 행렬의 형태로 진행됩니다.\n",
    "\n",
    "먼저 입력 문장에 대해 Q, K, V의 행렬들을 계산합니다. 이를 위해 입력 벡터들을 하나의 행렬 X로 쌓아 올리고 그것을 우리가 학습할 $W_Q, W_K, W_V$로 곱합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-matrix-calculation.png\">\n",
    "\n",
    "그리고 이 후는 위에서 했던 것과 동일합니다. Q와 K의 전치 행렬을 곱하고 K의 차원의 제곱근으로 나눠준 뒤, 소프트맥스를 하고 V를 곱해 값을 구하는 단계를 차근차근 거치면 됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/self-attention-matrix-calculation-2.png\">\n",
    "\n",
    "이를 식으로 표현하면 다음과 같습니다. \n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\n",
    "\n",
    "이때 구해지는 행렬을 A라고 할 때, A의 크기는 (seq_len, $d_V$)가 됩니다. 여기서 seq_len은 문장의 길이입니다. Q와 K의 크기가 (seq_len, $d_K$), V의 크기가 (seq_len, $d_V$)이므로 결과적으로 위와 같은 결과가 나오는 것입니다. 단 논문에서는 $d_{model}\\;/\\;num\\_heads=d_K=d_V$로 세 행렬의 크기가 모두 같습니다. \n",
    "\n",
    "이제 이를 코드로 표현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"\"\"Compute Scaled Dot Product Attention\n",
    "\n",
    "    Args's size:\n",
    "        query: (batch_size, num_heads, query 문장 길이, d_model/num_heads(=d_k))\n",
    "        key: (batch_size, num_heads, key 문장 길이, d_model/num_heads(=d_k))\n",
    "        value: (batch_size, num_heads, value 문장 길이, d_model/num_heads(=d_k))\n",
    "        mask: (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    Returns:\n",
    "        torch.matmul(p_attn, value): attention 연산의 결과인 행렬 A\n",
    "        p_attn: attention score\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # softmax는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # p_attn: (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    \n",
    "    # torch.matmul(p_attn, value): (batch_size, num_heads, query의 문장 길이, d_model / num_heads)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수가 정상적으로 작동하는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# 소수점 첫째 자리까지 표시, 십진법으로 표현(5e+1 -> 50)\n",
    "torch.set_printoptions(precision=1, sci_mode=False)\n",
    "temp_k = torch.FloatTensor([[10, 0, 0],\n",
    "                            [0, 10, 0],\n",
    "                            [0, 0, 10],\n",
    "                            [0, 0, 10]]) # (4, 3)\n",
    "\n",
    "temp_v = torch.FloatTensor([[1, 0],\n",
    "                            [10, 0],\n",
    "                            [100, 5],\n",
    "                            [1000, 6]]) # (4, 2)\n",
    "\n",
    "temp_q = torch.FloatTensor([[0, 10, 0]]) # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 주목할 것은 쿼리의 값이 키의 두번째 행과 일치한다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0]], dtype=torch.int32)\n",
      "tensor([[10,  0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn.type(torch.IntTensor)) # attention score\n",
    "print(temp_out.type(torch.IntTensor)) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q는 4개의 키 값 중 두번째 값과 일치하므로 점수 역시 [0, 1, 0, 0]임을 볼 수 있습니다. 그리고 그 결과로 V의 두번째 값인 [10, 0]이 나오는 것을 확인할 수 있습니다. \n",
    "\n",
    "이번엔 Q를 바꿔 다시 실행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.00,     0.00,     0.50,     0.50]])\n",
      "tensor([[550.00,   5.50]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.FloatTensor([[0, 0, 10]])\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn) # attention score\n",
    "print(temp_out) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점수가 [0, 0, 0.5, 0.5]가 나온 것은 세번째 값과 네번째 값 두 개의 값이 유사하다는 의미입니다. 그렇기에 결과적으로 나온 [550, 0.5]는 V의 세번째 값 [100, 5] * 0.5과 네번째 값 [1000, 6] * 0.5를 합친 값입니다. \n",
    "\n",
    "이번에는 3개의 Q 값을 입력으로 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.00,     0.00,     0.50,     0.50],\n",
      "        [    0.00,     1.00,     0.00,     0.00],\n",
      "        [    0.50,     0.50,     0.00,     0.00]])\n",
      "tensor([[  550.00,     5.50],\n",
      "        [   10.00,     0.00],\n",
      "        [    5.50,     0.00]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.FloatTensor([[0, 0, 10], [0, 10, 0], [10, 10, 0]])\n",
    "temp_out, temp_attn = attention(temp_q, temp_k, temp_v)\n",
    "print(temp_attn) # attention score\n",
    "print(temp_out) # attention output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention의 구조를 나타내면 다음과 같습니다.\n",
    "\n",
    "![sdpa](_image/4-6-3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) Multi-head Attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mha](_image/4-6-4.PNG)\n",
    "\n",
    "위 그림처럼 Multi-head Attention은 scaled dot-product attention을 병렬적으로 풀어 계산한 뒤 합치는 것을 의미합니다. 이는 $W_Q, W_V, W_K$을 여러 개 가지는 것입니다. 논문에서 정의한 num_heads가 바로 병렬의 개수를 지정하는 것으로 논문은 8로 정의했습니다. 이는 각각 독립적으로 학습되고 각 목적에 맞게 투영시킵니다. 다른 시각으로 단어들의 관계들을 살펴보고 그것을 종합하여 사용하는 것입니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_qkv.png\">\n",
    "\n",
    "앞서 이야기했듯이 각 attention head마다 $W_Q, W_V, W_K$을 가집니다. 그렇기에 Q, V, K 행렬도 각 head마다 생성됩니다. 각 head마다 self-attention 과정을 거치면 head 개수만큼 결과가 나옵니다. 이를 feed-forward layer로 보내기 위해선 이를 하나의 행렬로 합쳐야 합니다. \n",
    "\n",
    "이를 위해 일단 모두 이어 붙여서 하나의 행렬로 만들어줍니다. 그리고 output을 위한 또다른 가중치 행렬 $W_O$를 곱해버립니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_weight_matrix_o.png\">\n",
    "\n",
    "이제 인코더의 과정을 한 눈으로 보겠습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_multi-headed_self-attention-recap.png\">\n",
    "\n",
    "여기서 최종 결과물인 Z는 입력값인 X와 크기가 동일한 것을 알 수 있습니다. 이는 사실 당연한데 다음 인코더에 들어가기 위해서 크기가 유지되야 합니다. \n",
    "\n",
    "이제 예제 문장을 이용해 동작 결과를 보겠습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization_2.png\">\n",
    "\n",
    "\"it\"이라는 단어에 대해 인코딩할 때, 주황색의 attention head는 \"The\", \"animal\"에 가장 집중하고 있는 반면 초록색의 attention head는 \"tire\"에 집중하고 있는 것을 볼 수 있습니다. 이렇게 두 단어의 representation을 \"it\"의 representation에 포함시킬 수 있습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_self-attention_visualization_3.png\">\n",
    "\n",
    "그러나 위처럼 모든 attention head를 하나로 표시하면 알아보기가 너무 어려워집니다.\n",
    "\n",
    "이제, Multi-head Attention 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"\"\"Take in model size and number of heads\"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        \n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"Implements Figure 2\"\"\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for l, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5) Padding Mask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 구현 코드들을 보면 mask라는 인자가 계속 주어집니다. 이 연산은 입력 문장에 \\<PAD> 토큰이 있을 경우 어텐션에서 제외하기 위한 연산입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/pad_masking2.PNG\">\n",
    "\n",
    "마스킹을 하는 방법은 마스킹 위치에 매우 작은 음수값($-\\infty$와 가까운 수)을 넣어주는 것입니다. 현재 어텐션 스코어 행렬은 소프트맥스를 지나지 않은 상태입니다. 그렇기에 소프트맥스를 지나며 0이 되고 단어 간 유사도를 구하는데 반영되지 않게 됩니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/softmax.PNG\">\n",
    "\n",
    "위 그림은 소프트맥스를 지난 후입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.6 Common sublayer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더와 디코더에 동일하게 적용되는 sublayer들도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Feed Forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward(혹은 Position-wise FFNN)층은 인코더뿐만 아니라 디코더에도 존재합니다. 이를 쉽게 이야기하면 FC를 해주는 것입니다.\n",
    "\n",
    "$$FFNN(x) = MAX(0, xW_1+b_1)W_2 + b_2$$\n",
    "\n",
    "이를 그림으로 표현하면 다음과 같습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/positionwiseffnn.PNG\">\n",
    "\n",
    "여기서 x는 멀티 헤드 어텐션의 결과로 나온 (seq_len, $d_{model}$)의 크기를 가지는 행렬을 말합니다. 가중치 행렬 $W_1$은 ($d_{model}$, $d_{ff}$)의 크기를 가지고, 가중치 행렬 $W_2$는 ($d_{ff}, d_{model}$)의 크기를 가집니다. 논문에선 $d_{ff}$를 2048로 정의했습니다. \n",
    "\n",
    "여기서 매개변수 $W_1, b_1, W_2, b_2$는 하나의 인코더 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하게 사용됩니다. 하지만 인코더 층마다는 다른 값을 가집니다. \n",
    "\n",
    "이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) The Residuals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구조를 보면 각 층 사이에 Add & Normalize가 있는 것을 확인할 수 있습니다. 여기서 Add는 residual connection을 의미하고 Norm은 layer normalization을 의미합니다. \n",
    "\n",
    "먼저 residual connection을 보겠습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/transformer22.PNG\">\n",
    "\n",
    "위에서 볼 수 있듯이 residual connection은 어떠한 층의 입력값과 출력값을 더하는 것을 말합니다. 이는 주로 컴퓨터 비전 분야에서 모델의 학습을 돕기 위해 사용되는 기법입니다. 이를 통해 역전파가 잘 수행되고 layer를 거칠 필요가 없는 벡터들은 0으로 만들고 입력값만 가져가도록(skip connection) 만들 수도 있습니다.\n",
    "\n",
    "residual connection이 끝나면 이어서 layer normalization을 진행합니다. Layer normalization은 텐서의 마지막 차원(즉 여기선 $d_{model}$)에 대해서 평균($\\mu$)은 0, 분산($\\sigma^2$)은 1이 되도록 정규화해주는 것입니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/31379/layer_norm_new_1_final.PNG\">\n",
    "\n",
    "정규화 수식은 간단하게 확인만 하겠습니다.\n",
    "\n",
    "$$\\hat{x}_{i, k} = \\frac{x_{i,k}-\\mu_i}{\\sqrt{\\sigma_i^2+\\epsilon}}$$\n",
    "\n",
    "$\\epsilon$은 분모가 0이 되는 것을 방지합니다. \n",
    "\n",
    "이제 $\\gamma$와 $\\beta$라는 벡터를 준비합니다. 이들의 초기값은 각각 1과 0으로만 이루어집니다. \n",
    "\n",
    "$$ln_i = \\gamma \\hat{x}_i + \\beta = LayerNorm(x_i)$$\n",
    "\n",
    "이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 과정을 합치면 다음과 같습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_resideual_layer_norm_2.png\">\n",
    "\n",
    "이것은 디코더에서도 동일하게 적용됩니다. 만약 2개의 인코더와 디코더로 이루어진 단순한 형태의 트랜스포머를 생각하면 밑의 그림과 같습니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_resideual_layer_norm_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Encoder 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 동작을 확인해봤습니다. 이제 인코더를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.7 Decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoding_1.gif\">\n",
    "\n",
    "인코더 과정이 끝나면 디코더 과정이 시작됩니다. 디코딩 과정은 디코더가 출력을 완료했다는 \\<end of sentence>를 출력할 때까지 반복됩니다. 각 스텝마다 출력된 단어는 다음 스텝의 디코더 가장 아래로 들어가고 인코더와 마찬가지로 몇 개의 디코더를 거쳐 올라갑니다. 이때 인코더의 입력과 동일하게 포지셔닝 인코딩을 추가하여 디코더에게도 위치 정보를 저장합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoding_2.gif\">\n",
    "\n",
    "디코더는 크게 3개의 sublayer가 있습니다. 그 중 첫 번째 층인 maked multi-head attention은 기존의 multi-head attention에 mask가 추가된 것입니다. 이는 디코더가 출력하는 과정에서 다음 단어를 미리 참조하지 못하도록 막는 역할을 합니다. \n",
    "\n",
    "![masked](_image/4-6-5.PNG)\n",
    "\n",
    "masked가 끝나면 re-normalization을 해줍니다. \n",
    "\n",
    "다른 두 개의 sublayer는 기본적으론 인코더의 sublayer와 동일합니다. 그러나 한 가지 차이점이 두 번째 multi-head attention에 있습니다. 그것은 바로 입력값입니다.\n",
    "\n",
    "![transformer](_image/4-6-6.PNG)\n",
    "\n",
    "다시 트랜스포머의 구조를 보겠습니다. 보면 Q는 디코더에서 올라오지만 K, V는 인코더에서 넘어오는 것을 확인할 수 있습니다. 이외에는 같은 동작을 합니다.\n",
    "\n",
    "논문에선 인코더 층의 마지막 output의 K, V를 모든 디코더 층의 입력으로 사용합니다.\n",
    "\n",
    "이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1176fc0bdf0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAE5CAYAAAAQtqIuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXLklEQVR4nO3df7BkZX3n8fdnsm6kYJnhx05QqA2LVIEGsj+QXTEQJiKJlQQcEWMoIwT+2FKpJLUJ4i+IA6IpE61AYqqiGxMIsYQiiggOBSwwAlbG0oirgI6IZAICovMLQSQM890/um9ybfre2/e5p/vemft+VXWde59zntPf7ur5zHN+9HNTVUiS5mfFYhcgSbsjw1OSGhiektTA8JSkBnt0eCbZnGTzYtchafczV35kT77anmQXEGDHYtciabezEqiqGjrIXBbhuXLf+Q+wn3rip7ovSNJuYyfPwizh+e+6fsIk+wAfAN4ArALuBS6uqs+O0PclwIeBX6J3SuFO4Lyquq+xnCdW7rti5dZNh82746+8+L82PqWkPcGGuo6dPPvETOvHcc7zWuBNwAXArwH3Adcm+dXZOiVZTS8sDwXOAs4A9gc+n+SQMdQpSc06HXn2A/LVwGlVdW2/7XbgMHojyvWzdD8P2A94eVU90u/7D8CDwHuAt3ZZqyQtRNcjz9fRuzhz3VRD9U6qXgEcmeRlc/S9ZSo4+323ANcDp3VcpyQtSNfheRRwX1XtGmj/2rT1z5NkL+AlwD1DVn8NWN0/rB/st322B72rZZLUua7D8wBg65D2rdPWD7MfvVuKWvpK0sR1frUdmO3ep7nui5pX36paNdvOHH1KGpeuR55bGD5C3L+/HDayBNhGLxxb+krSxHUdnvcCL00yuN+j+8th5zSpqqeB7zD8nOjRwPer6vHOqpSkBeo6PK+ld2P8KQPtZwKb5rjZ/Vrg5CQHTTUk2b+/r093XKckLUjX4bkeuB34eJJzkvxSksuB44G3T22UZEOSwXOYH6J3m9P6JK9N8mvA54Cd9L6xJElLRqfh2b+ncy1wFb3AuxH4eXo3zV8/R9/vAScADwFXAlcD24FfrKp/7rJOSVqoPX1ikO2t321v4ffhpT1H/7vtO2a6q2ePns9TksbF8JSkBoanJDUwPCWpgeEpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JanBOP4Mx7J10yNfbernhCLS7seRpyQ1MDwlqYHhKUkNDE9JamB4SlIDw1OSGhiektTA8JSkBp2GZ5KTklyeZFOSHyV5OMmnkxw9Qt91SWrI47Eua5SkLnT9DaO3AAcAfwp8A/gZ4HzgS0nWVNXGEfZxMvDktN//peMaJWnBug7Pc6vq8ekNSW4GHgTeDrx+hH18uaq2d1yXJHWq08P2weDst20H7gcO6fK5JGkxjf2CUZL/CBwF3DNil28keS7Jo0n+T5LVs+x7+2wPYGUHL0GSnmessyolCfAxeiH9oTk2fwB4N3A3vfOcv0DvfOlJSY6pqm3jrHUxtczG5ExM0uIa95R0fwKsBc6uqm/MtmFVXTnQdFuSjcDNwLnAJUP6rJptn44+JY3L2A7bk7wf+APg96rq8pZ9VNUtwKPAcR2WJkkLNpbwTHIxvUPw86vqzxa4uxXAroVXJUnd6Tw8k7wXuBC4sKr+ZIH7+mV694qOcn+oJE1Mp+c8k/wBsA64Afi/SV4xbfUzVXV3f7sNwIlVlWl97wb+FtgEPAu8EjgP+DbwF13WKUkL1fUFo1P6y1/vP6bbDBw6S99vAm8DXgy8AHgI+Cvgfd40L2mp6TQ8q2pN63ZVdUaXtUjSODmrkiQ1MDwlqYHhKUkNDE9JamB4SlKDcX+3XWPSMpkIOKGI1BVHnpLUwPCUpAaGpyQ1MDwlqYHhKUkNDE9JamB4SlIDw1OSGhiektTA8JSkBoanJDUwPCWpgeEpSQ2cVWmZcTYmqRuOPCWpQafhmWRNkprhceQI/V+S5DNJdiT5YZL1SV7WZY2S1IVxHba/A7hjoO2fZuuQZDVwJ/A4cBawE7gA+HyS/1ZVD4+hTklqMq7w/FZVbZxnn/OA/YCXV9UjAEn+AXgQeA/w1m5LlKR2S+mc5+uAW6aCE6CqtgDXA6ctWlWSNMS4wvOjSXb2z13ekOSY2TZOshfwEuCeIau/BqzuH9YP9ts+2wNY2cWLkaRBXYfnDuBS4H8BvwS8HXgZ8IUk/3OWfvsBAbYOWTfVdkB3ZUrSwnR6zrOq7gbuntZ0Z5LP0htRvh949Vy7mM+6qlo1284cfUoal7Gf86yqx4CbgVfMstk2euE4bHS5f385bFQqSYtiUheMVjDLqLKqnga+Axw1ZPXRwPer6vEx1SZJ8zb28ExyEHAyMNetS9cCJ/e3n+q7P3AK8OnxVShJ89fpOc8kn6A3gvwKvUPxI+ndML8X8K5p220ATqyqTOv+IeDNwPokF/FvN8nvBD7QZZ2StFBd3yT/deA3gd8B9ga2ABuAS6pq2G1I/6qqvpfkBHoheiW9UfGdwC9W1T93XKckLUiqZrvAvXtLsn3lvitWbt102GKXsiw5E5N2ZxvqOnby7I6Z7upZSt8wkqTdhuEpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JamB4SlJDQxPSWpgeEpSg3H96WGJmx75alM/JxTR7sCRpyQ1MDwlqYHhKUkNDE9JamB4SlIDw1OSGhiektTA8JSkBp2GZ5LLk9Qsj4Nm6btuhj6PdVmjJHWh628YvQ/4y4G2FwA3AV+rqlGC8GTgyWm//0tHtUlSZzoNz6p6AHhgeluS04C9gI+PuJsvV9X2LuuSpK5N4pznOcCPgKsn8FySNBFjnRgkyYuA1wCfqKonRuz2jSSrgceBG4D3VNXjM+x/+xz7WjlqrZI0H+OeVeks4KcY7ZD9AeDdwN30znP+AnA+cFKSY6pq29iq1JLSMhuTMzFp0sYdnr8NfLuq7phrw6q6cqDptiQbgZuBc4FLhvRZNds++yNTR5+SOje2c55JjgeOAP6mdR9VdQvwKHBcV3VJUhfGecHoHOA54IoF7mcFsGvh5UhSd8YSnkn2Bt4A3FRV313Afn4Z+BlgY1e1SVIXxnXO843APsBfD1uZZANwYlVlWtvdwN8Cm4BngVcC5wHfBv5iTHVKUpNxhefZwA+Az86jzzeBtwEvpvetpIeAvwLe503zkpaasYRnVZ0wx/o1Q9rOGEctkjQOzqokSQ0MT0lqYHhKUgPDU5IaGJ6S1GDc322XJqJlMhFwQhG1c+QpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JamB4SlJDQxPSWpgeEpSA8NTkhoYnpLUwFmVtKw5G5NaOfKUpAYjhWeSQ5JcluSuJE8mqSRrZtj25CQbkzyd5PEkH02yatSCkvxukm8leSbJA0nOT2LIS1pSRg2lw4EzgCeBW2faqB+o6+n9zfVTgPOAU4HPjRKASS4A/hS4CvgV4OPA+4EPjFinJE3EqOc876iq1QBJ1tILxGH+GLgHeGNV7epv/yhwM/AG4OqZniDJAcB7gI9U1R/2mzck2Rs4P8lHqurhEeuVpLEaaeQ5FYSzSXIwcCxw5fTtq+oW4LvA6+fYxWuAFwJXDLRfTi/kZwpsSZq4Lq+2H9Vf3jNk3denrZ+tfwH3Tm+sqvuTPD2sf5Ltc+xz5RzrJalJlxdiDugvtw5Zt3Xa+tn6/6iqnhmybtsI/SVpYsZxn2fNs33UbZ63rqpWzbaz/sjU0aekznU58tzSXw4bIe7P8BHpYP+9k/z0kHX7jdBfkiamy/CcOlc57Nzm0Qw/FzrYP8DPTW9Mcjiw1wj9JWliOgvP/m1EXwbeNP2eziQnAQcDn55jFzcCzwBvHmg/C9gJXN9VrZK0UCOf80xyev/HY/vLE5McCDxVVTf2295B757OTyb5GPBi4IPAF4Frpu1rDXA7cFFVrQOoqi1J/gi4MMmO/vrj+vu8tKoeanmBkjQO87lgdM3A7+v6y83AoQBVdVuSXwcuAj4H/BD4DHB+VT03wnNcDOwAzgXeBTwCvJdeAEvSkpGqUS6C756SbF+574qVWzcdttilSM7EtJvZUNexk2d3zHRXjxNuSFIDw1OSGhiektTA8JSkBoanJDUwPCWpgeEpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQG4/gzHJKGuOmRrzb1c0KRpcmRpyQ1MDwlqYHhKUkNDE9JamB4SlIDw1OSGhiektTA8JSkBiOFZ5JDklyW5K4kTyap/t9en77NvkkuSPL5JN/rb/f/kvzvJP9+xOepGR5vmf9Lk6TxGfUbRocDZwBfAW4FTh2yzX8Cfg+4Evgw8CTwKnp/c/1EYO2Iz3U1cOlA23dG7CtJEzFqeN5RVasBkqxleHg+CBxaVU9Na7stybPAuiRHV9XXR3iux6pq44h1SdKiGOmwvap2jbDNUwPBOeVL/eUh8ylMkpaySVwwehVQwH0jbn9mkqeT/DjJF5P8xkwbJtk+2wNY2UH9kvQ8Y51VKcn/AH4HuLKqNo/Q5RPAeuAh4EXA24Crk7yoqi4bX6XS0tUyG5MzMY3f2MIzyeHAZ4Fv0gvQOVXVbw3s4++BDcAlST5WVU8PbL9qjhq24+hT0hiM5bA9yWHA7cA24OSqeqJlP/1zrX8H7AMc1V2FkrQwnYdnkv9MLzh/DJxUVY8vcJdTNc550UqSJqXT8Ezys/SC8zngVVX1yAL3twJ4E/BD4N6FVyhJ3Rj5nGeS0/s/HttfnpjkQOCpqroxyWrgNmA1cA5wcJKDp+3igar6fn9fa+iF7EVVta7fdh5wRH8fjwIHAW8FjgfOraoft7xASRqH+Vwwumbg93X95WbgUOBlwGH9tk8O6X82cPks+98EvJbeN5FWAU8B/wicWlXXz6NOSRq7kcOzqjLH+g3ArNvMtm0/IA1JSbsFZ1WSpAaGpyQ1MDwlqYHhKUkNDE9JajDWiUEkLY6WyUTACUXmw5GnJDUwPCWpgeEpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JamB4SlJDQxPSWpgeEpSA2dVkvSvnI1pdI48JanBSOGZ5JAklyW5K8mTSar/t9cHt9vQXzf4uGrUgpL8bpJvJXkmyQNJzk9iyEtaUkY9bD8cOAP4CnArcOos294PnDnQ9oNRniTJBcBFwPuB24BX9n/eH3jniLVK0tiNGp53VNVqgCRrmT08f1RVG+dbSJIDgPcAH6mqP+w3b0iyN3B+ko9U1cPz3a8kjcNIh8NVtWvchQCvAV4IXDHQfjm9kJ8tsCVposZxtf2IJNuA/wA8SC8MP1hVz87R7yiggHunN1bV/Ume7q//CUm2z7HPlaMWLUnz0XV43glcBXwT2AdYC1wMHAO8bo6+B9A75H9myLpt/fWStCR0Gp5VdeFA0w1Jvge8O8nxVXXXXLuYz7qqWjXbzvojU0efkjo3iVuAps5hHjfHdluAvZP89JB1+wFbO61KkhZgEuE59RxzXXS6Fwjwc9MbkxwO7AXc031pktRmEuE5dc/nXLcv3Qg8A7x5oP0sYCdwfcd1SVKzkc95Jjm9/+Ox/eWJSQ4EnqqqG5OcQO9G9k8Bm4G9gdcCZwPXVNUXpu1rDXA7cFFVrQOoqi1J/gi4MMmO/vrjgHcAl1bVQ60vUpK6Np8LRtcM/L6uv9wMHAo82v/9YuBAeofpm4DfB/58xOe4GNgBnAu8C3gEeC/wwXnUKUljl6rZLnDv3pJsX7nvipVbNx222KVIGrDUZ2LaUNexk2d3zHRXjxNuSFIDw1OSGhiektTA8JSkBoanJDUwPCWpgeEpSQ0MT0lqYHhKUgPDU5IaGJ6S1MDwlKQG4/gDcJI0p5se+WpTv6UyoYgjT0lqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JamB4SlJDUYKzySHJLksyV1JnkxS/b+9Pn2bQ/vtMz3+coTnmanvW9peniSNx6jfMDocOAP4CnArcOqQbR4FjhvSfhbwFuAzIz7X1cClA23fGbGvJE3EqOF5R1WtBkiyliHhWVXPABsH25N8FHgYuHnE53qsqp63H0laSkY6bK+qXS07T/Jy4OeBy1v3IUlL0bgvGJ0DFPA38+hzZpKnk/w4yReT/MZMGybZPtsDWLnA+iVpqLHNqpTkhfTOk26oqlHPWX4CWA88BLwIeBtwdZIXVdVl46lU0u6kZTamcczENM4p6U4DVgF/PWqHqvqt6b8n+XtgA3BJko9V1dMD26+abX+OPiWNyzgP288BdgCfat1B/zzp3wH7AEd1VJckLdhYwjPJzwKvAj45OFpsMFWjF5wkLRnjGnmeDYR5HLIPk2QF8Cbgh8C9HdQlSZ0Y+ZxnktP7Px7bX56Y5EDgqaq6cdp2oXdj/D1V9aUZ9rUGuB24qKrW9dvOA44AbqN3w/1BwFuB44Fzq+rHI78qSRqz+Vwwumbg93X95Wbg0Gntr+r//vvzrGUT8FpgLb0LTU8B/wicWlXXz3NfkjRWI4dnVWXE7W6ld8g+2zYbBrfpB6QhKWm34KxKktTA8JSkBoanJDUwPCWpgeEpSQ3G+d12SVoSWiYT2f+I59jxxMzrHXlKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JamB4SlJDQxPSWpgeEpSA8NTkhoYnpLUwPCUpAapqsWuYWyS7AKycl//j5A0Pzue2AVQVTU0QPb08NxJb3Q9bG6Ulf3ljslVtKT5fvwk34+ftBzfj32BXVU1dPa5PTo8Z5NkO0BVrVrcSpYG34+f5Pvxk3w/ns/jWUlqYHhKUgPDU5IaGJ6S1MDwlKQGhqckNTA8JanBsr3PU5IWwpGnJDUwPCWpgeEpSQ0MT0lqsOzCM8k+Sf4syaNJnk7y5SSnLnZdiyHJmiQ1w+PIxa5vnJIckuSyJHclebL/mtfMsO3JSTb2Py+PJ/loklUTLXjMRn0/kmyY4fNy1eSrXlxDp1raw10L/HfgfOBB4LeBa5OcUlXrF7OwRfQO4I6Btn9ahDom6XDgDOArwK3A0P9A+wGyHvgMcAHwYuCDwFFJTqiqXROodRJGej/67gfOHGj7wZjqWrKWVXgm+VXg1cBpVXVtv+124DDgw/T+kSxH36qqjYtdxITdUVWrAZKsZeaw+GPgHuCNU0GZ5FHgZuANwNXjL3UiRn0/AH60DD8vz7PcDttfR28y1+umGqp3o+sVwJFJXrZYhWmyRhkxJjkYOBa4cvr2VXUL8F3g9eOrcLL2oBH0xCy38DwKuG/IB+Vr09YvRx9NsjPJjiQ3JDlmsQtaIqY+D/cMWfd1lu/n5Ygk2/qfmfuTXJDkBYtd1KQtq8N24ADgW0Pat05bv5zsAC4FNtB7D14KvBP4QpITq+qLi1fakjD1edg6ZN1WeufOl5s7gauAbwL7AGuBi4Fj6B3ZLRvLLTwBZvs+6rL6rmpV3Q3cPa3pziSfpTfSej+988Oa+XOxrD4vAFV14UDTDUm+B7w7yfFVdddi1LUYltth+xaGjy737y+HjTCWlap6jN7FkFcsdi1LwJb+cqbPzLL/vPRd0V8et6hVTNhyC897gZcmGXzdR/eXw85tLUcrWIajqiHu7S+Hnds8Gj8vU6b+PS2ri07LLTyvBVYBpwy0nwlsqqr7Jl7REpPkIOBkYNnfilJVDwNfBt40/T/cJCcBBwOfXqzalpipez6X1WdmuZ3zXA/cDnw8yQH0bpI/CzgeeO1iFrYYknwC+A69G6O3AUfSu2F+L+Bdi1jaRCQ5vf/jsf3liUkOBJ6qqhv7be+gdxrjk0k+xr/dJP9F4JpJ1jtuc70fSU6gd0HxU8BmYG96/27OBq6pqi9MuubFtOzm80yyL/AB4HR6o9D7gIur6jOLWNaiSPJO4DeBQ+n9Q9hC78r7JVW1xx+SJpnpw7+5qg6dtt1rgIuA/wL8kN63jc6vqm3jrnGS5no/khwOXEbvfTiQ3mH6JnrnPP+8qp6bTKVLw7ILT0nqwnI75ylJnTA8JamB4SlJDQxPSWpgeEpSA8NTkhoYnpLUwPCUpAb/HxB/OYWTdCr9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(20)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.8 마지막 Linear Layer와 Softmax Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 디코더를 거치고 나온 후에는 소수로 이루어진 벡터가 남습니다. 이를 단어로 바꾸기 위해 마지막으로 linear layer와 softmax를 거칩니다. \n",
    "\n",
    "linear layer는 FC 신경망으로 디코더가 마지막으로 출력한 벡터를 그보다 훨씬 더 큰 사이즈의 벡터인 logits 벡터로 투영시킵니다. 이때 logits 벡터의 크기는 우리가 가진 사전의 크기, 즉 모델이 학습한 단어의 총 개수가 됩니다. 각 인덱스마다 단어에 대한 점수가 매겨집니다.\n",
    "\n",
    "이를 바탕으로 softmax를 통해 확률로 변환해주고 가장 높은 확률을 가진 단어를 출력하게 됩니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_decoder_output_softmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.9 전체적인 학습 과정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트랜스포머에 대해 순차적으로 알아봤습니다. 이제 이를 어떻게 학습시키는지 알아보겠습니다.\n",
    "\n",
    "### **1) Pre-processing**\n",
    "\n",
    "먼저 학습 시작 전에 output vocabulary가 있어야 합니다. 6단어만 있다고 가정하겠습니다. 그리고 이 사전을 이용해 각 단어에 매칭되는 원-핫 벡터를 만들 수 있습니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/one-hot-vocabulary-example.png\">\n",
    "\n",
    "### **2) Loss Function**\n",
    "\n",
    "모델을 학습하는 가장 첫번째 단계라고 가정합시다. 그리고 학습을 위해 \"merci\"라는 프랑스어를 \"thanks\"로 번역하는 간단한 예시를 생각하겠습니다. 즉, 모델의 출력은 \"thanks\"라는 단어를 가리키는 확률 벡터라는 의미입니다. 그러나 모델이 학습되지 않았기에 출력이 제대로 나올 확률은 희박합니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/transformer_logits_output_and_label.png\">\n",
    "\n",
    "학습이 시작될 때, 모델의 parameter(가중치 행렬 등)이 무작위로 값이 부여되기에 그저 임의의 값만 출력할 뿐입니다. 이 출력된 값을 실제 값과 비교하면서 얻은 차이와 역전파 알고리즘을 이용해 현재 모델의 가중치들을 조절해 원하는 출력값에 가까워지도록 만듭니다. \n",
    "\n",
    "두 확률 벡터를 비교할 때는 cross-entropy나 Kullback-Leibler divergence를 이용합니다.\n",
    "\n",
    "하지만 주의해야 할 것은 예제가 지나치게 단순하다는 것입니다. 현실적인 예제는 한 단어보다 긴 문장을 이용하겠습니다. 입력은 “je suis étudiant”이며 바라는 출력은 “i am a student”입니다. \n",
    "\n",
    "- 각 단어에 대한 확률 분포는 output vocabulary의 크기를 가집니다. \n",
    "- decoder가 첫번째로 출력하는 확률 분포는 \"i\"라는 단어와 연관이 있는 cell에 가장 높은 확률을 줘야 합니다.\n",
    "- 두번째로 출력하는 확률 분포는 \"am\"이라는 단어와 연관이 있는 cell에 가장 높은 확률을 줘야 합니다.\n",
    "- 이와 동일하게 마지막 \"\\<end of sentence>\"를 나타내는 다섯번째 출력까지 이 과정은 반복됩니다. \n",
    "- 이때 \\<eos> 또한 그에 해당하는 cell을 벡터에서 가집니다. \n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/output_target_probability_distributions.png\">\n",
    "\n",
    "위 그림은 학습에서 목표로 하는 확률 분포를 나타낸 것입니다. \n",
    "\n",
    "모델을 큰 사이즈의 데이터 셋에서 충분히 학습시키고 나면, 그 결과로 생성되는 확률 분포들은 다음과 같아질 것입니다.\n",
    "\n",
    "<img src = \"https://nlpinkorean.github.io/images/transformer/output_trained_model_probability_distributions.png\">\n",
    "\n",
    "학습 과정 후, 모델은 정확한 번역을 출력할 것입니다. \n",
    "\n",
    "여기서 특이한 점 하나는 아무리 다른 단어들이 최종 출력될 확률이 거의 없다 해도 0보다는 조금 큰 값을 가진다는 것입니다. 이는 softmax layer의 유용한 성질입니다. \n",
    "\n",
    "모델은 한 스텝 당 확률이 가장 높은 단어 하나를 출력하기에 다른 단어는 버린다고 생각하기 쉽습니다. 그러나 그것은 `greedy decoding`이라는 한가지 방법에 불과하며 다른 방법들도 존재합니다. 예를 들어 가장 확률이 높은 두 개의 단어를 저장할 수 있습니다. (위 예시로 보자면 \"i\"와 \"student\") 그렇다면 우리는 모델을 두 번 돌리게 됩니다. 한 번은 출력이 'i'라고 가정하고 두번째는 출력이 'student'라고 가정하는 것입니다. 이렇게 나온 결과에서 첫번째 출력 단어와 두번째 출력 단어를 동시에 고려했을 때, 더 낮은 에러를 보이는 결과의 첫번째 단어가 실제 출력으로 선택됩니다. 이를 마지막 단계까지 반복합니다. 이러한 방법을 `beam search`라고 부르며, 고려하는 단어의 수를 beam size, 고려하는 미래 출력 개수를 top_beam이라고 합니다. 우리의 예제에서는 두 개의 단어를 저장했으므로 beam size는 2이며 두번째 단계까지 고려했으므로 top_beam 역시 2입니다. 이때 beam size와 top_beam은 우리가 지정할 수 있는 하이퍼파라미터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.10 모델 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://wikidocs.net/31379\n",
    "- http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "- https://nlpinkorean.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization은 NLP 전처리에 해당하는 과정으로 text를 여러 개의 token으로 나누는 것을 말합니다. 어떤 기준으로 나누는지에 따라 크게 3개의 방법으로 나뉩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.1 Word-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wbt](_image/4-7-1.PNG)\n",
    "\n",
    "위 그림처럼 단어로 나누는 것이 Word-absed Tokenizer입니다. 영어의 경우, 띄어쓰기로 대부분 tokenization이 끝나기에 간단합니다. \n",
    "\n",
    "그러나 단어 기반의 tokenizer는 필연적으로 OOV(Out-of-Vocabulart) 문제를 가져옵니다. 이는 세상의 단어가 너무 많기에 그 단어를 모두 저장하고 임베딩하려면 전체 모델 메모리에서 차지하는 비중이 기하급수적으로(거의 90% 이상의) 증가하기에 정작 모델의 파라미터에 큰 비중을 쓰지 못합니다. 또한 아무리 많은 단어를 저장해도 세상의 모든 단어를 저장할 수 없다는 단점이 있습니다. \n",
    "\n",
    "단어를 줄인다 하여도 모르는 단어가 많아져 \\<unk> 토큰이 많아지고 이는 성능의 저하로 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.2 Chracter-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cbt](_image/4-7-2.PNG)\n",
    "\n",
    "이름 그대로 철자로 쪼개는 방식의 tokenizer입니다. 영어의 경우 알파벳, 한글의 경우 음절로 나누기에 워드 임베딩의 크기가 크게 줄어듭니다. \n",
    "\n",
    "그러나 철자 하나가 가져야하는 정보가 너무 많아지고 길이가 너무 길어지게 됩니다. 이는 필연적으로 성능 저하를 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.3 Subword-based Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 두 가지 방법은 너무 뚜렷한 단점을 가지고 있습니다. 그렇기에 대부분 subword-based tokenizer를 많이 사용합니다.\n",
    "\n",
    "![sbt](_image/4-7-3.PNG)\n",
    "\n",
    "위 그림처럼 단어와 철자 사이의 subword를 토큰으로 사용합니다. 접두사, 접미사, 어근 등도 토큰으로 사용됩니다. 이를 기반으로 BPE, WordPiece, Unigram, SentencePiece 등이 있으며 현재는 WordPiece와 SentencePiece가 많이 쓰이는 추세입니다.\n",
    "\n",
    "먼저 간단하게 살펴보겠습니다.\n",
    "\n",
    "- BPE(Byte-pair Encoding): 통계적 방법, GPT 등이 이 방법을 사용\n",
    "- WordPiece: BERT 등 트랜스포머 기반의 모델에서 사용, P('ug') / P('u' then 'g')와 같이 간단한 알고리즘은 공개되었으나 모든 알고리즘이 공개되어있지 않다.\n",
    "- Unigram: 가장 많이 사용된 단어들과 substring들을 다듬으며 시작\n",
    "- SentencePiece: 공백도 토큰으로 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1. Subword tokenization의 필요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) Intro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\delphinus\\\\Desktop\\\\Workspace\\\\Python\\\\goorm\\\\AI기술 자연어 처리 전문가 양성 과정'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# 데이터가 저장된 드라이브를 마운트하여 데이터를 불러올 수 있는 경로를 준비합니다.\n",
    "#from google.colab import drive\n",
    "#dirve.mount('/content/drive')\n",
    "\n",
    "PATH = os.getcwd() # 현재 경로\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 실습은 Subword tokenization의 필요성을 확인하는 것이 목적입니다.\n",
    "- Subword tokenization 기반 language model을 구현하면서 이전 과제의 Word-level language model과 비교해보겠습니다.\n",
    "- Subword-level language model을 구현하고, 주어진 데이터를 가공하여 모델을 학습한 후, 학습된 언어 모델을 이용해 문장을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Subword tokenization이 필요한 이유**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word tokenization 코드를 불러와 subword의 필요성을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {'<unk>': 0}\n",
    "        self.idx2word = ['<unk>']\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        \"\"\"Tokenizes a text file\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        \n",
    "        # Add words to the dictionary\n",
    "        with open(os.path.join(path, 'train.txt'), 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "        \n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "    \n",
    "    def tokenize(self, path):\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    try:\n",
    "                        ids.append(self.dictionary.word2idx[word])\n",
    "                    except:\n",
    "                        print(word)\n",
    "                        ids.append(0)\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "        \n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module and a decoder\"\"\"\n",
    "    \n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.ntoken = ntoken\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {\"RNN_TANH\": \"tanh\", \"RNN_RELU\": \"relu\"}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError(\"\"\"An invalid option for '--model' was supplied,\n",
    "                                options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.weight)\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output)\n",
    "        decoded = decoded.view(-1, self.ntoken)\n",
    "        return F.log_softmax(decoded, dim=1), hidden\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
    "        else:\n",
    "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"data\"    : './data/wikitext-2',    # location of the data corpus\n",
    "    \"model\"   : 'RNN_TANH',             # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU)\n",
    "    \"emsize\"  : 200,                    # size of word embeddings\n",
    "    \"nhid\"    : 512,                    # number of hidden units per layer\n",
    "    \"nlayers\" : 2,                      # number of layers\n",
    "    \"lr\"      : 20,                     # initial learning rate\n",
    "    \"clip\"    : 0.25,                   # gradient clipping\n",
    "    \"epochs\"  : 6,                      # upper epoch limit\n",
    "    \"batch_size\": 20,                   # batch size\n",
    "    \"bptt\"    : 35,                     # sequence length\n",
    "    \"dropout\" : 0.2,                    # dropout applied to layers (0 = no dropout)\n",
    "    \"seed\"    : 1111,                   # random seed\n",
    "    \"cuda\"    : False,                  # unuse CUDA\n",
    "    \"log_interval\": 200,                # report interval\n",
    "    \"save\"    : 'model.pt',             # path to save the final model\n",
    "    \"dry_run\" : True,                   # verify the code and the model\n",
    "\n",
    "})\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.txt의 문장들을 word tokenization 해보고 단어들의 개수를 세어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33278\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('./data/wikitext-2')\n",
    "ntokens = len(corpus.dictionary)\n",
    "print(ntokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 실습에 사용된 embedding dimension의 크기가 200이므로 word embedding에 사용된 parameter의 수는 33278 x 200 (= 6,655,600개)입니다.\n",
    "\n",
    "그렇다면 RNN 모델에 사용되는 weight의 paramter 개수는 몇 개인지 간단한 함수를 이용해 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter 개수: 6655600\n",
      "RNN parameter 개수: 890880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word embedding parameter 개수: {count_parameters(model.encoder)}\")\n",
    "print(f\"RNN parameter 개수: {count_parameters(model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN parameter, Word embedding parameter 개수를 비교해보면 word embedding parameter의 개수가 RNN 모델의 paramter의 개수보다 압도적으로 많습니다. word embedding을 사용하는 경우 training에 사용되는 text file의 크기가 커질수록 word embedding paramter는 더 커지게 되고 전체 parameter 대비 word embedding이 차지하는 비중이 매우 커집니다. \n",
    "\n",
    "이런 paramter 비중의 비대칭성을 해결하기 위해 처음에는 charater-based tokenization 방법을 주목했습니다. 그러나 앞서 살펴봤듯, 여러 이유로 성능 저하를 보였고 subword를 사용하게 됩니다.\n",
    "\n",
    "그럼 이제부터 BERT 모델에서 사용한 subword tokenization algorithm을 이용해 language modeling task를 수행해보겠습니다. subword tokenizer는 transformers 라이브러리를 통해 쉽게 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 208k/208k [00:00<00:00, 350kB/s]  \n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 14.4kB/s]\n",
      "Downloading: 100%|██████████| 426k/426k [00:01<00:00, 424kB/s]  \n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'expert', 'training', 'course']\n",
      "['Go', '##orm', 'X', 'K', '##A', '##IS', '##T']\n"
     ]
    }
   ],
   "source": [
    "# subword tokenization 예시\n",
    "print(tokenizer.tokenize('Natural language expert training course'))\n",
    "print(tokenizer.tokenize('Goorm X KAIST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    ids.append(self.dictionary.word2idx[word])\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면 이제 모델을 다시 선언하고 paramter의 개수를 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "subword_corpus = Corpus('./data/wikitext-2')\n",
    "ntokens = len(subword_corpus.dictionary)\n",
    "subwordmodel = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter 개수: 4619000\n",
      "RNN parameter 개수: 890880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word embedding parameter 개수: {count_parameters(subwordmodel.encoder)}\")\n",
    "print(f\"RNN parameter 개수: {count_parameters(subwordmodel.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 비해 embedding parameter 개수는 확연히 줄어들었습니다.   \n",
    "6,655,600개 -> 4,619,000개\n",
    "\n",
    "그러면 이제 subword 기반의 언어 모델 성능을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "# Starting from sequential data, batchify arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(subword_corpus.train, args.batch_size)\n",
    "val_data = batchify(subword_corpus.valid, eval_batch_size)\n",
    "test_data = batchify(subword_corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Build the model\n",
    "###############################################################################\n",
    "\n",
    "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout).to(device)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Training code1 - define functions\n",
    "###############################################################################\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "\n",
    "# get_batch subdivides the source data into chunks of length args.bptt.\n",
    "# If source is equal to the example output of the batchify function, with\n",
    "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
    "# ┌ a g m s ┐ ┌ b h n t ┐\n",
    "# └ b h n t ┘ └ c i o u ┘\n",
    "# Note that despite the name of the function, the subdivison of data is not\n",
    "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
    "# by the batchify function. The chunks are along dimension 0, corresponding\n",
    "# to the seq_len dimension in the LSTM.\n",
    "\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    ntokens = len(subword_corpus.dictionary)\n",
    "    hidden = model.init_hidden(eval_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output, hidden = model(data, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            total_loss += len(data) * criterion(output, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(subword_corpus.dictionary)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        model.zero_grad()\n",
    "\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        output, hidden = model(data, hidden)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(p.grad, alpha=-lr)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % args.log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / args.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // args.bptt, lr,\n",
    "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        if args.dry_run:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 254.02s | valid loss  9.37 | valid ppl 11752.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 184.04s | valid loss 14.65 | valid ppl 2314637.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 190.28s | valid loss 10.87 | valid ppl 52374.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 182.13s | valid loss  9.01 | valid ppl  8167.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 170.05s | valid loss  7.81 | valid ppl  2454.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 201.61s | valid loss  7.79 | valid ppl  2413.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test loss  7.69 | test ppl  2182.13\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Training code2 - run \n",
    "###############################################################################\n",
    "\n",
    "# Loop over epochs.\n",
    "lr = args.lr\n",
    "best_val_loss = None\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                            val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            lr /= 4.0\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    # Currently, only rnn model supports flatten_parameters function.\n",
    "    if args.model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
    "        model.rnn.flatten_parameters()\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) 학습한 언어 모델로 문장 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 완료된 모델을 불러와 임의의 한 단어를 입력으로 넣어준 후, 정해진 개수의 단어를 생성합니다.\n",
    "- 생성한 문장을 decode하여 generate.txt 파일에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Generated 0/1000 words\n",
      "| Generated 100/1000 words\n",
      "| Generated 200/1000 words\n",
      "| Generated 300/1000 words\n",
      "| Generated 400/1000 words\n",
      "| Generated 500/1000 words\n",
      "| Generated 600/1000 words\n",
      "| Generated 700/1000 words\n",
      "| Generated 800/1000 words\n",
      "| Generated 900/1000 words\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Language Modeling on Wikitext-2\n",
    "#\n",
    "# This file generates new sentences sampled from the language model\n",
    "#\n",
    "###############################################################################\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model parameters.\n",
    "test_args = easydict.EasyDict({\n",
    "    \"data\"      : './data/wikitext-2',  # location of data corpus\n",
    "    \"checkpoint\": './model.pt',         # model checkpoint to use\n",
    "    \"outf\"      : 'generate.txt',       # output file for generated text\n",
    "    \"words\"     : 1000,                 # number of words to generate\n",
    "    \"seed\"      : 1111,                 # random seed\n",
    "    \"cuda\"      : False,                # unuse CUDA\n",
    "    \"temperature\": 1.0,                 # temperature - higher will increase diversity\n",
    "    \"log_interval\": 100                 # reporting interval\n",
    "})\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(test_args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not test_args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\" if test_args.cuda else \"cpu\")\n",
    "\n",
    "if test_args.temperature < 1e-3:\n",
    "    parser.error(\"--temperature has to be greater or equal 1e-3\")\n",
    "\n",
    "with open(test_args.checkpoint, 'rb') as f:\n",
    "    model = torch.load(f).to(device)\n",
    "model.eval()\n",
    "\n",
    "# corpus = Corpus(test_args.data)\n",
    "# ntokens = len(subword_corpus.dictionary)\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
    "\n",
    "with open(test_args.outf, 'w', encoding=\"UTF-8\") as outf:\n",
    "    with torch.no_grad():  # no tracking history\n",
    "        for i in range(test_args.words):\n",
    "            output, hidden = model(input, hidden)\n",
    "            word_weights = output.squeeze().div(test_args.temperature).exp().cpu()\n",
    "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "            input.fill_(word_idx)\n",
    "\n",
    "            word = subword_corpus.dictionary.idx2word[word_idx]\n",
    "\n",
    "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "\n",
    "            if i % test_args.log_interval == 0:\n",
    "                print('| Generated {}/{} words'.format(i, test_args.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[Pytorch Language Model](https://github.com/pytorch/examples/tree/master/word_language_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8. Byte-Pair Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.1 BPE 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE 알고리즘은 1994년에 제안된 데이터 압축 알고리즘입니다. 이를 후에 자연어 처리의 서브워드 분리 알고리즘으로 응용한 것입니다. 자연어 처리에서 사용되는 것을 알아보기 전에 먼저 기존의 BPE 작동 방법을 알아보겠습니다. \n",
    "\n",
    "> aaabdaaabac\n",
    "\n",
    "위와 같은 문자열이 주어졌습니다. 이때 BPE는 연속적으로 가장 많이 등장한 글자의 쌍을 찾아서 하나의 글자로 병합하는 방식을 수행합니다. 위 문자에서 가장 많이 등장한 문자의 쌍은 'aa'입니다. 이를 'Z'로 치환하겠습니다.\n",
    "\n",
    "> ZabdZabac  \n",
    "> Z = aa  \n",
    "\n",
    "치환 후, 가장 많이 등장하는 문자의 쌍은 'ab'입니다. 'ab'는 'Y'로 치환하겠습니다.\n",
    "\n",
    "> ZYdZYac  \n",
    "> Y = ab  \n",
    "> Z = aa  \n",
    "\n",
    "이번엔 'ZY'가 가장 많이 나타납니다. 이를 'X'로 치환하겠습니다.\n",
    "\n",
    "> XdXac  \n",
    "> X = ZY  \n",
    "> Y = ab  \n",
    "> Z = aa  \n",
    "\n",
    "이제 더이상 병합할 것이 없습니다. 그렇기에 위 결과를 최종 결과로 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.2 자연어 처리에서의 BPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[자연어 처리에서의 BPE](https://arxiv.org/abs/1508.07909)는 subword-based tokenizer의 일종으로 글자 단위에서 점차적으로 단어 집합을 만들어내는 bottom up 방식을 사용합니다. 우선 훈련 데이터에 있는 단어들을 모든 글자 또는 유니코드 단위로 단어 집합을 만들고 가장 많이 등장하는 유니그램을 하나의 유니그램으로 통합합니다. \n",
    "\n",
    "논문에서 나오는 코드를 조금 수정한 코드로 동작하는 과정을 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Iteration 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
      "new merge: ('e', 's')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
      "new merge: ('es', 't')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
      "new merge: ('est', '</w>')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('l', 'o')\n",
      "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('lo', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('n', 'e')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('ne', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('new', 'est</w>')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('low', '</w>')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('w', 'i')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
     ]
    }
   ],
   "source": [
    "import re, collections\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "num_merges = 10\n",
    "dictionary = {'l o w </w>' : 5,\n",
    "        'l o w e r </w>' : 2,\n",
    "        'n e w e s t </w>':6,\n",
    "        'w i d e s t </w>':3\n",
    "        }\n",
    "\n",
    "def get_stats(dictionary):\n",
    "    # 유니그램의 pair들의 빈도수를 카운트\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
    "    return pairs\n",
    "\n",
    "def merge_dictionary(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "bpe_codes = {}\n",
    "bpe_codes_reverse = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
    "    pairs = get_stats(dictionary)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    dictionary = merge_dictionary(best, dictionary)\n",
    "\n",
    "    bpe_codes[best] = i\n",
    "    bpe_codes_reverse[best[0] + best[1]] = best\n",
    "\n",
    "    print(\"new merge: {}\".format(best))\n",
    "    print(\"dictionary: {}\".format(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab은 나오는 단어들을 키, 출현 빈도수를 값으로 가지는 사전입니다. 처음 입력되는 단어들은 모두 철자입니다. `get_stats`함수를 거치면서 앞뒤로 근접한 한 쌍의 단어들의 조합 빈도수가 저장된 pairs을 리턴합니다. 예를 들어 [l o w </w>]가 들어가면 [lo], [ow], [w</w>]의 빈도수가 각각 저장되는 것입니다. 이렇게 리턴된 pairs에서 빈도수가 가장 높은 것을 `merge_dictionary`을 통해 vocab에 저장합니다. 그리고 이를 num_merges만큼 반복하는 것입니다. \n",
    "\n",
    "위 출력은 매 iteration마다 합쳐진 단어들이고 마지막은 최종 vocab입니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/22592/%EA%B7%B8%EB%A6%BC.png\">\n",
    "\n",
    "위 그림은 BPE는 OOV의 문제를 해결하는 동작 과정입니다. 모르는 단어 'lowest'가 들어왔을 때, vocab 안에 있는 두 토큰의 합으로 표현한 것을 알 수 있습니다. 이 역시 코드로 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word):\n",
    "    \"\"\"\n",
    "    Return set of symbol pairs in a word.\n",
    "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def encode(orig):\n",
    "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
    "\n",
    "    word = tuple(orig) + ('</w>',)\n",
    "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
    "\n",
    "    pairs = get_pairs(word)    \n",
    "\n",
    "    if not pairs:\n",
    "        return orig\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
    "\n",
    "        print(\"bigrams in the word: {}\".format(pairs))\n",
    "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
    "        print(\"candidate for merging: {}\".format(bigram))\n",
    "        if bigram not in bpe_codes:\n",
    "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
    "            break\n",
    "        first, second = bigram\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            try:\n",
    "                j = word.index(first, i)\n",
    "                new_word.extend(word[i:j])\n",
    "                i = j\n",
    "            except:\n",
    "                new_word.extend(word[i:])\n",
    "                break\n",
    "\n",
    "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                new_word.append(first+second)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word = tuple(new_word)\n",
    "        word = new_word\n",
    "        print(\"word after merging: {}\".format(word))\n",
    "        if len(word) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(word)\n",
    "\n",
    "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
    "    if word[-1] == '</w>':\n",
    "        word = word[:-1]\n",
    "    elif word[-1].endswith('</w>'):\n",
    "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', '</w>'), ('o', 'k'), ('k', 'i'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'k', 'i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', '</w>'), ('lo', 'k'), ('k', 'i')}\n",
      "candidate for merging: ('i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('lo', 'k', 'i')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"loki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('e', 's'), ('o', 'w'), ('s', 't'), ('w', 'e'), ('t', '</w>'), ('l', 'o')}\n",
      "candidate for merging: ('e', 's')\n",
      "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'es'), ('es', 't'), ('t', '</w>'), ('l', 'o')}\n",
      "candidate for merging: ('es', 't')\n",
      "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est'), ('l', 'o'), ('est', '</w>')}\n",
      "candidate for merging: ('est', '</w>')\n",
      "word after merging: ('l', 'o', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 4:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est</w>'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 5:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 6:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('low', 'est</w>')}\n",
      "candidate for merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'est')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단하게 BPT에 대해 보았습니다. BPT를 사용한 대표적인 모델인 GPT 등에 대해선 이후 챕터에서 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.3 Issue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE에 여러 트릭을 이용해 성능을 개선하는 방법을 적용하고 있습니다. 예를 들어 첫 시작으로 철자 단위로 나눌 때, 공백 역시 '_' 등의 문자로 치환하여 함께 토큰화 시키는 방법이 있습니다. \n",
    "\n",
    "또한 \"학교에\"라는 단어가 들어왔고 사전에 [학교, 교에, 학, 교, 에]가 있다면 어떻게 토큰화할 것인지에 대한 방법론도 있습니다. 생각만 해보면 [학, 교에], [학교, 에], [학, 교, 에] 세 가지 방법으로 토큰화시킬 수 있습니다. 마지막 방법은 토큰화의 의미가 없으니 제외하고 나머지 두 개만 살펴보겠습니다.\n",
    "\n",
    "먼저 오른쪽으로부터 탐색하는 방법입니다. 가장 오른쪽인 '에'를 보고 사전에 존재하면 이어서 '교에'를 확인합니다. 이 또한 존재하면 '학교에'를 확인합니다. 이런식으로 공백이 나올때까지 쭉 이어집니다. 위같은 예시라면 [학, 교에]라는 결과를 출력할 것입니다. \n",
    "\n",
    "위와 반대로 왼쪽부터 탐색하는 방법도 있습니다. 그렇다면 [학교, 에]라는 결과를 출력할 것입니다. 대체적으로 왼쪽부터 탐색하는 방법을 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Reference**\n",
    "\n",
    "https://wikidocs.net/22592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
